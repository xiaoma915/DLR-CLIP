2025-12-16 01:01:00 Preparing ViT-B/16 model.
2025-12-16 01:01:02 Getting cached textual weights W ...
2025-12-16 01:01:02 Initializing CMA adapter learner...
2025-12-16 01:01:02 Initializing SKD distillation...
2025-12-16 01:01:02 Preparing imagenet dataset.
2025-12-16 01:01:49 train acc=0.654, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 3.166496753692627e-08, 0.0, 1.24151611328125, 1.318084716796875, 0.6191482543945312]
2025-12-16 01:01:49 Epoch: 0, loss: 2.5658, lr: 0.00009990
2025-12-16 01:30:07 Preparing ViT-B/16 model.
2025-12-16 01:30:10 Getting cached textual weights W ...
2025-12-16 01:30:10 Initializing CMA adapter learner...
2025-12-16 01:30:10 Initializing SKD distillation...
2025-12-16 01:30:10 Preparing imagenet dataset.
2025-12-16 01:30:33 train acc=0.654, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 3.166496753692627e-08, 0.0, 1.24151611328125, 1.318084716796875, 0.6191482543945312]
2025-12-16 01:30:33 Epoch: 0, loss: 2.5658, lr: 0.00009990
2025-12-16 01:30:54 train acc=0.709, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 2.1047890186309814e-07, 0.0, 1.197235107421875, 1.1249542236328125, 0.5586776733398438]
2025-12-16 01:30:54 Epoch: 1, loss: 2.3279, lr: 0.00009961
2025-12-16 08:53:04 train acc=0.696, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 3.359653055667877e-05, 0.0, 1.2412872314453125, 1.1097412109375, 0.674774169921875]
2025-12-16 08:53:04 Epoch: 2, loss: 2.3576, lr: 0.00009911
2025-12-16 08:53:25 train acc=0.719, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0006281770765781403, 0.0, 1.2006072998046875, 1.0009765625, 0.7812957763671875]
2025-12-16 08:53:25 Epoch: 3, loss: 2.2100, lr: 0.00009843
2025-12-16 08:53:46 train acc=0.749, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0023895204067230225, 0.0, 1.2117919921875, 0.934600830078125, 0.9606781005859375]
2025-12-16 08:53:46 Epoch: 4, loss: 2.1584, lr: 0.00009755
2025-12-16 08:54:07 train acc=0.762, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004182338714599609, 0.0, 1.21038818359375, 0.8791732788085938, 1.20806884765625]
2025-12-16 08:54:07 Epoch: 5, loss: 2.1059, lr: 0.00009649
2025-12-16 08:54:28 train acc=0.79, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004833579063415527, 0.0, 1.2062225341796875, 0.8028335571289062, 1.343414306640625]
2025-12-16 08:54:28 Epoch: 6, loss: 2.0272, lr: 0.00009524
2025-12-16 08:54:49 train acc=0.798, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004326164722442627, 0.0, 1.2436065673828125, 0.7546920776367188, 1.582244873046875]
2025-12-16 08:54:49 Epoch: 7, loss: 2.0184, lr: 0.00009382
2025-12-16 08:55:11 train acc=0.832, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003972530364990234, 0.0, 1.2145843505859375, 0.6689529418945312, 1.853607177734375]
2025-12-16 08:55:11 Epoch: 8, loss: 1.9062, lr: 0.00009222
2025-12-16 08:55:34 train acc=0.842, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0041770339012146, 0.0, 1.272674560546875, 0.6097221374511719, 2.069366455078125]
2025-12-16 08:55:34 Epoch: 9, loss: 1.9071, lr: 0.00009045
2025-12-16 08:55:56 train acc=0.856, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004255950450897217, 0.0, 1.1946868896484375, 0.5317497253417969, 2.37005615234375]
2025-12-16 08:55:56 Epoch: 10, loss: 1.7545, lr: 0.00008853
2025-12-16 08:56:19 train acc=0.872, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0043021440505981445, 0.0, 1.1849517822265625, 0.4953155517578125, 2.5828857421875]
2025-12-16 08:56:19 Epoch: 11, loss: 1.7105, lr: 0.00008645
2025-12-16 08:56:41 train acc=0.889, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004844367504119873, 0.0, 1.2244415283203125, 0.4690132141113281, 2.751708984375]
2025-12-16 08:56:41 Epoch: 12, loss: 1.7258, lr: 0.00008423
2025-12-16 08:57:04 train acc=0.899, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0053632259368896484, 0.0, 1.185302734375, 0.41860198974609375, 2.9945068359375]
2025-12-16 08:57:04 Epoch: 13, loss: 1.6391, lr: 0.00008187
2025-12-16 08:57:26 train acc=0.91, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00577855110168457, 0.0, 1.2097320556640625, 0.4088630676269531, 3.14404296875]
2025-12-16 08:57:26 Epoch: 14, loss: 1.6560, lr: 0.00007939
2025-12-16 08:57:49 train acc=0.913, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.006550908088684082, 0.0, 1.194091796875, 0.3716869354248047, 3.26025390625]
2025-12-16 08:57:49 Epoch: 15, loss: 1.6048, lr: 0.00007679
2025-12-16 08:58:11 train acc=0.915, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.007329583168029785, 0.0, 1.1646270751953125, 0.3572731018066406, 3.34912109375]
2025-12-16 08:58:11 Epoch: 16, loss: 1.5628, lr: 0.00007409
2025-12-16 08:58:34 train acc=0.92, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008360505104064941, 0.0, 1.180908203125, 0.3488044738769531, 3.43896484375]
2025-12-16 08:58:34 Epoch: 17, loss: 1.5725, lr: 0.00007129
2025-12-16 08:58:56 train acc=0.925, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.009242773056030273, 0.0, 1.2053985595703125, 0.3342933654785156, 3.55133056640625]
2025-12-16 08:58:56 Epoch: 18, loss: 1.5845, lr: 0.00006841
2025-12-16 08:59:19 train acc=0.93, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.010242938995361328, 0.0, 1.16156005859375, 0.3308982849121094, 3.65045166015625]
2025-12-16 08:59:19 Epoch: 19, loss: 1.5393, lr: 0.00006545
2025-12-16 08:59:42 train acc=0.939, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.010998964309692383, 0.0, 1.1533355712890625, 0.29851531982421875, 3.65478515625]
2025-12-16 08:59:42 Epoch: 20, loss: 1.4993, lr: 0.00006243
2025-12-16 09:00:05 train acc=0.946, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01204061508178711, 0.0, 1.1513824462890625, 0.29665374755859375, 3.72491455078125]
2025-12-16 09:00:05 Epoch: 21, loss: 1.4975, lr: 0.00005937
2025-12-16 09:00:27 train acc=0.939, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012978076934814453, 0.0, 1.1898040771484375, 0.3004913330078125, 3.82415771484375]
2025-12-16 09:00:27 Epoch: 22, loss: 1.5415, lr: 0.00005627
2025-12-16 09:00:50 train acc=0.942, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.013941287994384766, 0.0, 1.11798095703125, 0.26519203186035156, 3.83551025390625]
2025-12-16 09:00:50 Epoch: 23, loss: 1.4355, lr: 0.00005314
2025-12-16 09:01:13 train acc=0.937, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01494741439819336, 0.0, 1.13958740234375, 0.27673912048339844, 3.90252685546875]
2025-12-16 09:01:13 Epoch: 24, loss: 1.4704, lr: 0.00005000
2025-12-16 09:01:36 train acc=0.944, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.015918731689453125, 0.0, 1.15191650390625, 0.302520751953125, 3.88092041015625]
2025-12-16 09:01:36 Epoch: 25, loss: 1.5093, lr: 0.00004686
2025-12-16 09:01:59 train acc=0.947, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.016828536987304688, 0.0, 1.1324920654296875, 0.2641258239746094, 3.86004638671875]
2025-12-16 09:01:59 Epoch: 26, loss: 1.4521, lr: 0.00004373
2025-12-16 09:02:22 train acc=0.953, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01759481430053711, 0.0, 1.1196746826171875, 0.25180816650390625, 3.956298828125]
2025-12-16 09:02:22 Epoch: 27, loss: 1.4287, lr: 0.00004063
2025-12-16 09:02:45 train acc=0.948, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.018421173095703125, 0.0, 1.1156463623046875, 0.25510406494140625, 4.0140380859375]
2025-12-16 09:02:45 Epoch: 28, loss: 1.4293, lr: 0.00003757
2025-12-16 09:03:08 train acc=0.951, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.019098758697509766, 0.0, 1.0778656005859375, 0.24648475646972656, 3.98223876953125]
2025-12-16 09:03:08 Epoch: 29, loss: 1.3834, lr: 0.00003455
2025-12-16 09:03:31 train acc=0.954, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01978588104248047, 0.0, 1.0828399658203125, 0.24129295349121094, 4.003662109375]
2025-12-16 09:03:31 Epoch: 30, loss: 1.3839, lr: 0.00003159
2025-12-16 09:03:53 train acc=0.952, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.020368576049804688, 0.0, 1.113616943359375, 0.2525920867919922, 4.01434326171875]
2025-12-16 09:03:53 Epoch: 31, loss: 1.4267, lr: 0.00002871
2025-12-16 09:04:16 train acc=0.946, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02086496353149414, 0.0, 1.1038055419921875, 0.2489910125732422, 4.0245361328125]
2025-12-16 09:04:16 Epoch: 32, loss: 1.4139, lr: 0.00002591
2025-12-16 09:04:39 train acc=0.957, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.021593570709228516, 0.0, 1.050811767578125, 0.2332468032836914, 4.044677734375]
2025-12-16 09:04:39 Epoch: 33, loss: 1.3460, lr: 0.00002321
2025-12-16 09:05:02 train acc=0.953, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.021846294403076172, 0.0, 1.1135101318359375, 0.2351970672607422, 4.0224609375]
2025-12-16 09:05:02 Epoch: 34, loss: 1.4108, lr: 0.00002061
2025-12-16 09:05:25 train acc=0.959, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.022411823272705078, 0.0, 1.0717620849609375, 0.22942352294921875, 4.06005859375]
2025-12-16 09:05:25 Epoch: 35, loss: 1.3641, lr: 0.00001813
2025-12-16 09:05:47 train acc=0.954, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.022664546966552734, 0.0, 1.0846710205078125, 0.2438831329345703, 4.029052734375]
2025-12-16 09:05:47 Epoch: 36, loss: 1.3916, lr: 0.00001577
2025-12-16 09:06:10 train acc=0.957, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02297210693359375, 0.0, 1.0709991455078125, 0.23904991149902344, 4.0338134765625]
2025-12-16 09:06:10 Epoch: 37, loss: 1.3734, lr: 0.00001355
2025-12-16 09:06:33 train acc=0.953, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.023242950439453125, 0.0, 1.07440185546875, 0.24114418029785156, 4.03125]
2025-12-16 09:06:33 Epoch: 38, loss: 1.3790, lr: 0.00001147
2025-12-16 09:06:56 train acc=0.947, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.023540496826171875, 0.0, 1.067169189453125, 0.2616233825683594, 4.017333984375]
2025-12-16 09:06:56 Epoch: 39, loss: 1.3924, lr: 0.00000955
2025-12-16 09:07:19 train acc=0.959, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02374410629272461, 0.0, 1.0677490234375, 0.2283496856689453, 4.0633544921875]
2025-12-16 09:07:19 Epoch: 40, loss: 1.3605, lr: 0.00000778
2025-12-16 09:07:42 train acc=0.952, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.023851871490478516, 0.0, 1.0611534118652344, 0.23440170288085938, 4.0303955078125]
2025-12-16 09:07:42 Epoch: 41, loss: 1.3597, lr: 0.00000618
2025-12-16 09:08:04 train acc=0.96, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02392721176147461, 0.0, 1.07586669921875, 0.2228679656982422, 4.0733642578125]
2025-12-16 09:08:04 Epoch: 42, loss: 1.3635, lr: 0.00000476
2025-12-16 09:08:27 train acc=0.962, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024053573608398438, 0.0, 1.0591583251953125, 0.2325277328491211, 4.07391357421875]
2025-12-16 09:08:27 Epoch: 43, loss: 1.3564, lr: 0.00000351
2025-12-16 09:08:50 train acc=0.957, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02410602569580078, 0.0, 1.0526046752929688, 0.22348308563232422, 4.0926513671875]
2025-12-16 09:08:50 Epoch: 44, loss: 1.3411, lr: 0.00000245
2025-12-16 09:09:13 train acc=0.958, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024138927459716797, 0.0, 1.0722503662109375, 0.2511882781982422, 4.03204345703125]
2025-12-16 09:09:13 Epoch: 45, loss: 1.3880, lr: 0.00000157
2025-12-16 09:09:36 train acc=0.96, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02419567108154297, 0.0, 1.0367889404296875, 0.22042131423950195, 4.08221435546875]
2025-12-16 09:09:36 Epoch: 46, loss: 1.3221, lr: 0.00000089
2025-12-16 09:09:58 train acc=0.955, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024188995361328125, 0.0, 1.080902099609375, 0.23346519470214844, 4.04046630859375]
2025-12-16 09:09:59 Epoch: 47, loss: 1.3790, lr: 0.00000039
2025-12-16 09:10:21 train acc=0.957, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024248123168945312, 0.0, 1.107421875, 0.2317028045654297, 4.05621337890625]
2025-12-16 09:10:21 Epoch: 48, loss: 1.4039, lr: 0.00000010
2025-12-16 09:10:44 train acc=0.96, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024249553680419922, 0.0, 1.0586700439453125, 0.21779251098632812, 4.043212890625]
2025-12-16 09:10:44 Epoch: 49, loss: 1.3412, lr: 0.00000000
2025-12-16 09:50:23 {'name': 'imagenet', 'acc': [{'clip_logits': 68.77, 'cma_logits': 62.038000000000004, 'GLR_logits': 69.14200000000001, 'final_logits': 66.21000000000001, 'acc': 70.094}, {'clip_logits': 69.17999999999999, 'cma_logits': 63.18, 'GLR_logits': 69.69999999999999, 'final_logits': 66.85, 'acc': 70.53}, {'clip_logits': 48.383737153412326, 'cma_logits': 42.06017017430093, 'GLR_logits': 48.405352826740554, 'final_logits': 44.974355951187874, 'acc': 49.03613747568237}], 'detail': 'dataset_name=imagenet, shots=1, lr=0.001, seed=2024, train_epoch=50, batch_size=32, backbone=ViT-B/16, num_classes=1000, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-16 09:50:23 avg clip_logits acc=68.77
2025-12-16 09:50:23 avg cma_logits acc=62.038000000000004
2025-12-16 09:50:23 avg GLR_logits acc=69.14200000000001
2025-12-16 09:50:23 avg final_logits acc=66.21000000000001
2025-12-16 09:50:23 avg acc acc=70.094
