2025-12-18 23:14:28 Preparing ViT-B/16 model.
2025-12-18 23:14:30 Getting cached textual weights W ...
2025-12-18 23:14:30 Initializing CMA adapter learner...
2025-12-18 23:14:31 Initializing SKD distillation...
2025-12-18 23:14:31 Preparing imagenet dataset.
2025-12-18 23:16:10 train acc=0.687, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 1.1542486766028026e-07, 0.0, 1.0986328125, 1.1257052951388888, 0.5845501612103174]
2025-12-18 23:16:10 Epoch: 0, loss: 2.2303, lr: 0.00009990
2025-12-18 23:16:51 train acc=0.725, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 1.6263553074428012e-05, 0.0, 1.0981832837301588, 1.0168418278769842, 0.6468641493055556]
2025-12-18 23:16:51 Epoch: 1, loss: 2.1216, lr: 0.00009961
2025-12-18 23:17:32 train acc=0.737, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0008112617901393346, 0.0, 1.1124093191964286, 0.9709240141369048, 0.8357204861111112]
2025-12-18 23:17:32 Epoch: 2, loss: 2.0925, lr: 0.00009911
2025-12-18 23:18:13 train acc=0.7555, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0027843505617171998, 0.0, 1.0858987475198412, 0.8747713603670635, 1.1248139880952381]
2025-12-18 23:18:13 Epoch: 3, loss: 1.9748, lr: 0.00009843
2025-12-18 23:18:55 train acc=0.768, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003117092072017609, 0.0, 1.1081271701388888, 0.8265671502976191, 1.3886563740079365]
2025-12-18 23:18:55 Epoch: 4, loss: 1.9519, lr: 0.00009755
2025-12-18 23:19:36 train acc=0.7945, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0030300655062236483, 0.0, 1.0902777777777777, 0.7253069196428571, 1.723508804563492]
2025-12-18 23:19:36 Epoch: 5, loss: 1.8359, lr: 0.00009649
2025-12-18 23:20:17 train acc=0.8135, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003086816696893601, 0.0, 1.0858367435515872, 0.6722974020337301, 1.9936445932539681]
2025-12-18 23:20:17 Epoch: 6, loss: 1.7812, lr: 0.00009524
2025-12-18 23:20:58 train acc=0.838, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0033930672539605033, 0.0, 1.0896654885912698, 0.5975923084077381, 2.2743675595238093]
2025-12-18 23:20:58 Epoch: 7, loss: 1.7133, lr: 0.00009382
2025-12-18 23:21:39 train acc=0.854, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0042682526603577626, 0.0, 1.0736878410218254, 0.5296921502976191, 2.6178075396825395]
2025-12-18 23:21:39 Epoch: 8, loss: 1.6338, lr: 0.00009222
2025-12-18 23:22:20 train acc=0.8605, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0052549271356491815, 0.0, 1.0812794518849207, 0.4916178385416667, 2.8743489583333335]
2025-12-18 23:22:20 Epoch: 9, loss: 1.6068, lr: 0.00009045
2025-12-18 23:23:01 train acc=0.878, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.006843506343781002, 0.0, 1.0707116505456349, 0.4493408203125, 3.1589161706349205]
2025-12-18 23:23:01 Epoch: 10, loss: 1.5584, lr: 0.00008853
2025-12-18 23:23:43 train acc=0.9, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008319915287078374, 0.0, 1.0673091827876984, 0.400725833953373, 3.2626178075396823]
2025-12-18 23:23:43 Epoch: 11, loss: 1.5090, lr: 0.00008645
2025-12-18 23:24:24 train acc=0.914, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0103484865218874, 0.0, 1.0506184895833333, 0.3648294115823413, 3.5240575396825395]
2025-12-18 23:24:24 Epoch: 12, loss: 1.4610, lr: 0.00008423
2025-12-18 23:25:05 train acc=0.9165, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012412903800843254, 0.0, 1.0568576388888888, 0.3496675037202381, 3.6568700396825395]
2025-12-18 23:25:05 Epoch: 13, loss: 1.4555, lr: 0.00008187
2025-12-18 23:25:46 train acc=0.9305, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.014628455752418154, 0.0, 1.0275220114087302, 0.3100334046378968, 3.8794022817460316]
2025-12-18 23:25:46 Epoch: 14, loss: 1.3910, lr: 0.00007939
2025-12-18 23:26:27 train acc=0.9345, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.016916547502790178, 0.0, 1.0216858878968254, 0.28799293154761907, 3.9894593253968256]
2025-12-18 23:26:27 Epoch: 15, loss: 1.3665, lr: 0.00007679
2025-12-18 23:27:08 train acc=0.944, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01940191359747024, 0.0, 1.0155474950396826, 0.26055520678323413, 4.148685515873016]
2025-12-18 23:27:08 Epoch: 16, loss: 1.3370, lr: 0.00007409
2025-12-18 23:27:50 train acc=0.952, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.021913800920758928, 0.0, 0.9888780381944444, 0.2476128472222222, 4.217199900793651]
2025-12-18 23:27:50 Epoch: 17, loss: 1.3006, lr: 0.00007129
2025-12-18 23:28:31 train acc=0.953, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024335588727678572, 0.0, 0.9892345610119048, 0.23293050130208334, 4.317708333333333]
2025-12-18 23:28:31 Epoch: 18, loss: 1.2896, lr: 0.00006841
2025-12-18 23:29:12 train acc=0.958, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.027002485971602184, 0.0, 0.9730282738095238, 0.22772507440476192, 4.403831845238095]
2025-12-18 23:29:12 Epoch: 19, loss: 1.2719, lr: 0.00006545
2025-12-18 23:29:53 train acc=0.9575, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02959405808221726, 0.0, 0.9575156560019841, 0.2151305183531746, 4.475446428571429]
2025-12-18 23:29:53 Epoch: 20, loss: 1.2469, lr: 0.00006243
2025-12-18 23:30:35 train acc=0.963, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03209141322544643, 0.0, 0.939270988343254, 0.19994632781498015, 4.477802579365079]
2025-12-18 23:30:35 Epoch: 21, loss: 1.2161, lr: 0.00005937
2025-12-18 23:31:16 train acc=0.969, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03459579225570437, 0.0, 0.9107142857142857, 0.1844269283234127, 4.564856150793651]
2025-12-18 23:31:16 Epoch: 22, loss: 1.1754, lr: 0.00005627
2025-12-18 23:31:57 train acc=0.972, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03687831333705357, 0.0, 0.9011191716269841, 0.18105982220362102, 4.598555307539683]
2025-12-18 23:31:57 Epoch: 23, loss: 1.1650, lr: 0.00005314
2025-12-18 23:32:38 train acc=0.9705, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.039123050750248016, 0.0, 0.8895011780753969, 0.1763460673983135, 4.596726190476191]
2025-12-18 23:32:38 Epoch: 24, loss: 1.1510, lr: 0.00005000
2025-12-18 23:33:19 train acc=0.97, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04130336216517857, 0.0, 0.8739846850198413, 0.17005847749255953, 4.6510106646825395]
2025-12-18 23:33:19 Epoch: 25, loss: 1.1319, lr: 0.00004686
2025-12-18 23:34:01 train acc=0.9725, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04348173595610119, 0.0, 0.8799370659722222, 0.1723235599578373, 4.6081659226190474]
2025-12-18 23:34:01 Epoch: 26, loss: 1.1418, lr: 0.00004373
2025-12-18 23:34:42 train acc=0.9785, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04545375279017857, 0.0, 0.8660520523313492, 0.1657564677889385, 4.621589781746032]
2025-12-18 23:34:42 Epoch: 27, loss: 1.1235, lr: 0.00004063
2025-12-18 23:35:23 train acc=0.9785, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.047295464409722224, 0.0, 0.829651847718254, 0.1524202861483135, 4.662233382936508]
2025-12-18 23:35:23 Epoch: 28, loss: 1.0759, lr: 0.00003757
2025-12-18 23:36:04 train acc=0.98, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.048992338634672616, 0.0, 0.8265749007936508, 0.15184142097594247, 4.623449900793651]
2025-12-18 23:36:04 Epoch: 29, loss: 1.0737, lr: 0.00003455
2025-12-18 23:36:45 train acc=0.9805, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05054776630704365, 0.0, 0.8282606336805556, 0.15247066437251985, 4.654389880952381]
2025-12-18 23:36:45 Epoch: 30, loss: 1.0778, lr: 0.00003159
2025-12-18 23:37:27 train acc=0.9785, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05199565584697421, 0.0, 0.8080667162698413, 0.14713396344866073, 4.645523313492063]
2025-12-18 23:37:27 Epoch: 31, loss: 1.0537, lr: 0.00002871
2025-12-18 23:38:08 train acc=0.982, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05336216517857143, 0.0, 0.8024321056547619, 0.14515807136656747, 4.674975198412699]
2025-12-18 23:38:08 Epoch: 32, loss: 1.0477, lr: 0.00002591
2025-12-18 23:38:49 train acc=0.98, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05443948412698413, 0.0, 0.8008316282242064, 0.14343552362351192, 4.612847222222222]
2025-12-18 23:38:49 Epoch: 33, loss: 1.0449, lr: 0.00002321
2025-12-18 23:39:30 train acc=0.984, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05550178648933532, 0.0, 0.7853616381448413, 0.14357212611607142, 4.6946304563492065]
2025-12-18 23:39:30 Epoch: 34, loss: 1.0313, lr: 0.00002061
2025-12-18 23:40:11 train acc=0.981, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.056363060360863096, 0.0, 0.7911706349206349, 0.14618549649677579, 4.66375248015873]
2025-12-18 23:40:11 Epoch: 35, loss: 1.0403, lr: 0.00001813
2025-12-18 23:40:52 train acc=0.984, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.057152642144097224, 0.0, 0.7727167038690477, 0.14069572327628968, 4.639260912698413]
2025-12-18 23:40:52 Epoch: 36, loss: 1.0169, lr: 0.00001577
2025-12-18 23:41:34 train acc=0.981, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05782741970486111, 0.0, 0.7727554563492064, 0.14131963820684523, 4.662202380952381]
2025-12-18 23:41:34 Epoch: 37, loss: 1.0185, lr: 0.00001355
2025-12-18 23:42:15 train acc=0.982, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.058433411613343256, 0.0, 0.7691669766865079, 0.1344483390687004, 4.637183779761905]
2025-12-18 23:42:15 Epoch: 38, loss: 1.0085, lr: 0.00001147
2025-12-18 23:42:56 train acc=0.9835, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.058848063151041664, 0.0, 0.7577737475198413, 0.1346493675595238, 4.699063740079365]
2025-12-18 23:42:56 Epoch: 39, loss: 0.9984, lr: 0.00000955
2025-12-18 23:43:37 train acc=0.9875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05932229662698413, 0.0, 0.7618815104166666, 0.13243514772445436, 4.665116567460317]
2025-12-18 23:43:37 Epoch: 40, loss: 1.0003, lr: 0.00000778
2025-12-18 23:44:18 train acc=0.9835, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.059642973400297616, 0.0, 0.7488529265873016, 0.13860648018973215, 4.6842137896825395]
2025-12-18 23:44:18 Epoch: 41, loss: 0.9940, lr: 0.00000618
2025-12-18 23:45:00 train acc=0.983, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05993071056547619, 0.0, 0.7604399181547619, 0.1399511912512401, 4.645399305555555]
2025-12-18 23:45:00 Epoch: 42, loss: 1.0068, lr: 0.00000476
2025-12-18 23:45:41 train acc=0.986, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.060131254650297616, 0.0, 0.7515229724702381, 0.13541957310267858, 4.597067212301587]
2025-12-18 23:45:41 Epoch: 43, loss: 0.9931, lr: 0.00000351
2025-12-18 23:46:22 train acc=0.986, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06031387571304563, 0.0, 0.7591959635416666, 0.13458881680927579, 4.649305555555555]
2025-12-18 23:46:22 Epoch: 44, loss: 1.0005, lr: 0.00000245
2025-12-18 23:47:03 train acc=0.985, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06032695467509921, 0.0, 0.7372620597718254, 0.12786816793774802, 4.660342261904762]
2025-12-18 23:47:03 Epoch: 45, loss: 0.9720, lr: 0.00000157
2025-12-18 23:47:44 train acc=0.9845, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06042867993551587, 0.0, 0.7635401165674603, 0.13940599229600695, 4.665736607142857]
2025-12-18 23:47:44 Epoch: 46, loss: 1.0101, lr: 0.00000089
2025-12-18 23:48:26 train acc=0.9835, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06044805617559524, 0.0, 0.7579210069444444, 0.13720218718998015, 4.618706597222222]
2025-12-18 23:48:26 Epoch: 47, loss: 1.0018, lr: 0.00000039
2025-12-18 23:49:07 train acc=0.985, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.060460650731646824, 0.0, 0.7472098214285714, 0.1309964618985615, 4.646949404761905]
2025-12-18 23:49:07 Epoch: 48, loss: 0.9851, lr: 0.00000010
2025-12-18 23:49:48 train acc=0.9845, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06046646360367063, 0.0, 0.7577853732638888, 0.13462320963541666, 4.637803819444445]
2025-12-18 23:49:48 Epoch: 49, loss: 0.9993, lr: 0.00000000
2025-12-19 00:22:10 {'name': 'imagenet', 'acc': [{'clip_logits': 68.77, 'cma_logits': 63.836000000000006, 'GLR_logits': 70.074, 'final_logits': 67.866, 'acc': 71.138}, {'clip_logits': 69.17999999999999, 'cma_logits': 63.24999999999999, 'GLR_logits': 70.25, 'final_logits': 67.25999999999999, 'acc': 70.93}, {'clip_logits': 48.383737153412326, 'cma_logits': 42.50820413055867, 'GLR_logits': 48.55469747882646, 'final_logits': 44.53811236220008, 'acc': 49.2346086580597}], 'detail': 'dataset_name=imagenet, shots=2, lr=0.001, seed=2024, train_epoch=50, batch_size=32, backbone=ViT-B/16, num_classes=1000, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-19 00:22:10   ImageNet测试结果: {'clip_logits': 68.77, 'cma_logits': 63.836000000000006, 'GLR_logits': 70.074, 'final_logits': 67.866, 'acc': 71.138}
2025-12-19 00:22:10   ImageNet-V2测试结果: {'clip_logits': 69.17999999999999, 'cma_logits': 63.24999999999999, 'GLR_logits': 70.25, 'final_logits': 67.25999999999999, 'acc': 70.93}
2025-12-19 00:22:10   ImageNet-Sketch测试结果: {'clip_logits': 48.383737153412326, 'cma_logits': 42.50820413055867, 'GLR_logits': 48.55469747882646, 'final_logits': 44.53811236220008, 'acc': 49.2346086580597}
2025-12-19 00:22:10 avg clip_logits acc=62.1112457178041
2025-12-19 00:22:10 avg cma_logits acc=56.53140137685289
2025-12-19 00:22:10 avg GLR_logits acc=62.95956582627549
2025-12-19 00:22:10 avg final_logits acc=59.88803745406668
2025-12-19 00:22:10 avg acc acc=63.76753621935324
