2025-12-16 16:42:09 Preparing ViT-B/16 model.
2025-12-16 16:42:11 Getting cached textual weights W ...
2025-12-16 16:42:11 Initializing CMA adapter learner...
2025-12-16 16:42:11 Initializing SKD distillation...
2025-12-16 16:42:11 Preparing imagenet dataset.
2025-12-16 16:48:20 train acc=0.7100625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0011238837242126464, 0.0, 1.11478466796875, 1.068658203125, 0.6587216796875]
2025-12-16 16:48:20 Epoch: 0, loss: 2.1911, lr: 0.00009990
2025-12-16 16:54:00 train acc=0.725375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0021114039421081545, 0.0, 1.1193349609375, 0.994015625, 0.8285126953125]
2025-12-16 16:54:00 Epoch: 1, loss: 2.1238, lr: 0.00009961
2025-12-16 16:59:53 train acc=0.7379375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.002332688331604004, 0.0, 1.118966796875, 0.941591552734375, 0.970416015625]
2025-12-16 16:59:53 Epoch: 2, loss: 2.0726, lr: 0.00009911
2025-12-16 17:05:38 train acc=0.7510625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.002209468841552734, 0.0, 1.114478515625, 0.883158203125, 1.1661708984375]
2025-12-16 17:05:38 Epoch: 3, loss: 2.0115, lr: 0.00009843
2025-12-16 17:11:04 train acc=0.7661875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0021830663681030272, 0.0, 1.11623388671875, 0.8248466796875, 1.442958984375]
2025-12-16 17:11:04 Epoch: 4, loss: 1.9577, lr: 0.00009755
2025-12-16 17:16:31 train acc=0.7785625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0024108057022094727, 0.0, 1.1198857421875, 0.76959521484375, 1.748521484375]
2025-12-16 17:16:31 Epoch: 5, loss: 1.9094, lr: 0.00009649
2025-12-16 17:21:55 train acc=0.7951875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.002895294189453125, 0.0, 1.115109375, 0.709042236328125, 2.05155078125]
2025-12-16 17:21:55 Epoch: 6, loss: 1.8476, lr: 0.00009524
2025-12-16 17:27:20 train acc=0.8094375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0034328575134277345, 0.0, 1.1164921875, 0.6561484375, 2.3294765625]
2025-12-16 17:27:20 Epoch: 7, loss: 1.7994, lr: 0.00009382
2025-12-16 17:32:46 train acc=0.8228125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0041553001403808595, 0.0, 1.11667041015625, 0.607798583984375, 2.64825390625]
2025-12-16 17:32:46 Epoch: 8, loss: 1.7551, lr: 0.00009222
2025-12-16 17:38:11 train acc=0.8361875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0049456787109375, 0.0, 1.11236328125, 0.563760986328125, 2.9062265625]
2025-12-16 17:38:11 Epoch: 9, loss: 1.7101, lr: 0.00009045
2025-12-16 17:43:36 train acc=0.84475, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0066131210327148434, 0.0, 1.10842236328125, 0.529072265625, 3.21166015625]
2025-12-16 17:43:36 Epoch: 10, loss: 1.6763, lr: 0.00008853
2025-12-16 17:49:02 train acc=0.8535625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00861029052734375, 0.0, 1.1105, 0.501501708984375, 3.37390234375]
2025-12-16 17:49:02 Epoch: 11, loss: 1.6543, lr: 0.00008645
2025-12-16 17:54:26 train acc=0.8621875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.010322357177734375, 0.0, 1.1059599609375, 0.47065234375, 3.6220234375]
2025-12-16 17:54:26 Epoch: 12, loss: 1.6232, lr: 0.00008423
2025-12-16 17:59:51 train acc=0.87275, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012727867126464844, 0.0, 1.1023056640625, 0.44847314453125, 3.79440625]
2025-12-16 17:59:51 Epoch: 13, loss: 1.6014, lr: 0.00008187
2025-12-16 18:05:16 train acc=0.881125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.015722793579101564, 0.0, 1.09113916015625, 0.427048095703125, 3.92817578125]
2025-12-16 18:05:16 Epoch: 14, loss: 1.5732, lr: 0.00007939
2025-12-16 18:10:41 train acc=0.8844375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.018968048095703124, 0.0, 1.0881474609375, 0.411510986328125, 4.0646875]
2025-12-16 18:10:41 Epoch: 15, loss: 1.5593, lr: 0.00007679
2025-12-16 18:16:06 train acc=0.8866875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.022489166259765624, 0.0, 1.08443017578125, 0.397843505859375, 4.2342578125]
2025-12-16 18:16:06 Epoch: 16, loss: 1.5471, lr: 0.00007409
2025-12-16 18:21:32 train acc=0.893375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02589837646484375, 0.0, 1.0679130859375, 0.3774600830078125, 4.34146484375]
2025-12-16 18:21:32 Epoch: 17, loss: 1.5147, lr: 0.00007129
2025-12-16 18:26:57 train acc=0.8970625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02928668212890625, 0.0, 1.0608427734375, 0.3710850830078125, 4.44696875]
2025-12-16 18:26:57 Epoch: 18, loss: 1.5057, lr: 0.00006841
2025-12-16 18:32:22 train acc=0.9025625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03297589111328125, 0.0, 1.056705078125, 0.35852099609375, 4.5365390625]
2025-12-16 18:32:22 Epoch: 19, loss: 1.4936, lr: 0.00006545
2025-12-16 18:37:46 train acc=0.902375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0361246337890625, 0.0, 1.0522099609375, 0.350902099609375, 4.594359375]
2025-12-16 18:37:46 Epoch: 20, loss: 1.4852, lr: 0.00006243
2025-12-16 18:43:11 train acc=0.903125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.039174835205078126, 0.0, 1.0453076171875, 0.3438841552734375, 4.68976953125]
2025-12-16 18:43:11 Epoch: 21, loss: 1.4753, lr: 0.00005937
2025-12-16 18:48:36 train acc=0.9086875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0421248779296875, 0.0, 1.03226171875, 0.33247027587890626, 4.7181015625]
2025-12-16 18:48:36 Epoch: 22, loss: 1.4540, lr: 0.00005627
2025-12-16 18:54:01 train acc=0.9091875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0451090087890625, 0.0, 1.02707373046875, 0.3272181396484375, 4.75259375]
2025-12-16 18:54:01 Epoch: 23, loss: 1.4469, lr: 0.00005314
2025-12-16 18:59:25 train acc=0.911625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04752325439453125, 0.0, 1.015291015625, 0.3189471435546875, 4.85867578125]
2025-12-16 18:59:25 Epoch: 24, loss: 1.4304, lr: 0.00005000
2025-12-16 19:04:50 train acc=0.9118125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05037127685546875, 0.0, 1.01089208984375, 0.3204971923828125, 4.84774609375]
2025-12-16 19:04:50 Epoch: 25, loss: 1.4302, lr: 0.00004686
2025-12-16 19:10:14 train acc=0.9149375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05316241455078125, 0.0, 1.00477783203125, 0.3089388427734375, 4.89048828125]
2025-12-16 19:10:14 Epoch: 26, loss: 1.4158, lr: 0.00004373
2025-12-16 19:15:39 train acc=0.9148125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05533355712890625, 0.0, 0.99790087890625, 0.307724365234375, 4.9506953125]
2025-12-16 19:15:39 Epoch: 27, loss: 1.4104, lr: 0.00004063
2025-12-16 19:21:03 train acc=0.91725, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05760076904296875, 0.0, 0.9892216796875, 0.302756591796875, 4.968515625]
2025-12-16 19:21:03 Epoch: 28, loss: 1.3993, lr: 0.00003757
2025-12-16 19:26:28 train acc=0.917, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05955999755859375, 0.0, 0.98766357421875, 0.3004993896484375, 4.9534375]
2025-12-16 19:26:28 Epoch: 29, loss: 1.3973, lr: 0.00003455
2025-12-16 19:31:53 train acc=0.9198125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0612386474609375, 0.0, 0.98140576171875, 0.2975733642578125, 4.9690546875]
2025-12-16 19:31:53 Epoch: 30, loss: 1.3899, lr: 0.00003159
2025-12-16 19:37:18 train acc=0.91925, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06316552734375, 0.0, 0.97041015625, 0.29647265625, 4.97669140625]
2025-12-16 19:37:18 Epoch: 31, loss: 1.3798, lr: 0.00002871
2025-12-16 19:42:43 train acc=0.9219375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06463153076171875, 0.0, 0.968902099609375, 0.2942098388671875, 4.9785]
2025-12-16 19:42:43 Epoch: 32, loss: 1.3776, lr: 0.00002591
2025-12-16 19:48:08 train acc=0.92175, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06579156494140626, 0.0, 0.962591796875, 0.2917904052734375, 4.981578125]
2025-12-16 19:48:08 Epoch: 33, loss: 1.3700, lr: 0.00002321
2025-12-16 19:53:32 train acc=0.92325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06699224853515626, 0.0, 0.95096630859375, 0.28878759765625, 4.958625]
2025-12-16 19:53:32 Epoch: 34, loss: 1.3563, lr: 0.00002061
2025-12-16 19:58:57 train acc=0.9216875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0682567138671875, 0.0, 0.95340478515625, 0.2891494140625, 4.9517578125]
2025-12-16 19:58:57 Epoch: 35, loss: 1.3603, lr: 0.00001813
2025-12-16 20:04:22 train acc=0.9243125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06893389892578125, 0.0, 0.94707470703125, 0.286542724609375, 4.9709296875]
2025-12-16 20:04:22 Epoch: 36, loss: 1.3522, lr: 0.00001577
2025-12-16 20:09:46 train acc=0.922, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06999603271484375, 0.0, 0.9507529296875, 0.2897537841796875, 4.9646875]
2025-12-16 20:09:46 Epoch: 37, loss: 1.3601, lr: 0.00001355
2025-12-16 20:15:11 train acc=0.922375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07064105224609375, 0.0, 0.94203369140625, 0.28643109130859373, 4.95741796875]
2025-12-16 20:15:11 Epoch: 38, loss: 1.3487, lr: 0.00001147
2025-12-16 20:20:36 train acc=0.9221875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0712578125, 0.0, 0.9372216796875, 0.287961181640625, 4.9508515625]
2025-12-16 20:20:36 Epoch: 39, loss: 1.3459, lr: 0.00000955
2025-12-16 20:26:01 train acc=0.9236875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0716212158203125, 0.0, 0.936431640625, 0.284805908203125, 4.94674609375]
2025-12-16 20:26:01 Epoch: 40, loss: 1.3423, lr: 0.00000778
2025-12-16 20:31:26 train acc=0.9259375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.071909912109375, 0.0, 0.93568017578125, 0.2831439208984375, 4.93764453125]
2025-12-16 20:31:26 Epoch: 41, loss: 1.3401, lr: 0.00000618
2025-12-16 20:36:50 train acc=0.9230625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07214605712890625, 0.0, 0.93202587890625, 0.2877081298828125, 4.9440625]
2025-12-16 20:36:50 Epoch: 42, loss: 1.3413, lr: 0.00000476
2025-12-16 20:42:15 train acc=0.9245625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0724512939453125, 0.0, 0.93054150390625, 0.28428851318359377, 4.9395625]
2025-12-16 20:42:15 Epoch: 43, loss: 1.3367, lr: 0.00000351
2025-12-16 20:47:40 train acc=0.9231875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07261688232421876, 0.0, 0.933490234375, 0.2858687744140625, 4.939125]
2025-12-16 20:47:40 Epoch: 44, loss: 1.3414, lr: 0.00000245
2025-12-16 20:53:07 train acc=0.926375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0728739013671875, 0.0, 0.92708349609375, 0.2817845458984375, 4.9361796875]
2025-12-16 20:53:07 Epoch: 45, loss: 1.3311, lr: 0.00000157
2025-12-16 20:58:34 train acc=0.9265625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07277203369140625, 0.0, 0.92615625, 0.282974853515625, 4.9482890625]
2025-12-16 20:58:34 Epoch: 46, loss: 1.3314, lr: 0.00000089
2025-12-16 21:03:59 train acc=0.9244375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0728458251953125, 0.0, 0.9261279296875, 0.284219482421875, 4.9535703125]
2025-12-16 21:03:59 Epoch: 47, loss: 1.3327, lr: 0.00000039
2025-12-16 21:09:24 train acc=0.9268125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.072899658203125, 0.0, 0.92347021484375, 0.283038330078125, 4.934171875]
2025-12-16 21:09:24 Epoch: 48, loss: 1.3287, lr: 0.00000010
2025-12-16 21:14:49 train acc=0.9235, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.072916015625, 0.0, 0.9265146484375, 0.2811104736328125, 4.9382421875]
2025-12-16 21:14:49 Epoch: 49, loss: 1.3299, lr: 0.00000000
2025-12-16 21:44:37 {'name': 'imagenet', 'acc': [{'clip_logits': 68.77, 'cma_logits': 67.586, 'GLR_logits': 71.21600000000001, 'final_logits': 70.26, 'acc': 73.366}, {'clip_logits': 69.17999999999999, 'cma_logits': 66.67, 'GLR_logits': 71.17999999999999, 'final_logits': 69.21000000000001, 'acc': 72.76}, {'clip_logits': 48.383737153412326, 'cma_logits': 40.71999842795103, 'GLR_logits': 48.62740474365776, 'final_logits': 42.70078012930103, 'acc': 48.41910825522215}], 'detail': 'dataset_name=imagenet, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=32, backbone=ViT-B/16, num_classes=1000, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-16 21:44:37   ImageNet测试结果: {'clip_logits': 68.77, 'cma_logits': 67.586, 'GLR_logits': 71.21600000000001, 'final_logits': 70.26, 'acc': 73.366}
2025-12-16 21:44:37   ImageNet-V2测试结果: {'clip_logits': 69.17999999999999, 'cma_logits': 66.67, 'GLR_logits': 71.17999999999999, 'final_logits': 69.21000000000001, 'acc': 72.76}
2025-12-16 21:44:37   ImageNet-Sketch测试结果: {'clip_logits': 48.383737153412326, 'cma_logits': 40.71999842795103, 'GLR_logits': 48.62740474365776, 'final_logits': 42.70078012930103, 'acc': 48.41910825522215}
2025-12-16 21:44:37 avg clip_logits acc=62.1112457178041
2025-12-16 21:44:37 avg cma_logits acc=58.32533280931701
2025-12-16 21:44:37 avg GLR_logits acc=63.674468247885926
2025-12-16 21:44:37 avg final_logits acc=60.72359337643368
2025-12-16 21:44:37 avg acc acc=64.84836941840739
