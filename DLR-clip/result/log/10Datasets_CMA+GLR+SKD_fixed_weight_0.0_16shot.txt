2025-12-20 09:52:27 Preparing ViT-B/16 model.
2025-12-20 09:52:32 Getting cached textual weights W ...
2025-12-20 09:52:34 Initializing CMA adapter learner...
2025-12-20 09:52:34 Initializing SKD distillation...
2025-12-20 09:52:34 Preparing fgvc dataset.
2025-12-20 09:52:57 train acc=0.264375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00264229953289032, 0.0, 2.73646484375, 2.73646484375, 0.43416015625]
2025-12-20 09:52:57 Epoch: 0, loss: 5.4792, lr: 0.00009990
2025-12-20 09:53:13 train acc=0.259375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.011334571838378906, 0.0, 2.723701171875, 2.723701171875, 0.430166015625]
2025-12-20 09:53:13 Epoch: 1, loss: 5.4623, lr: 0.00009961
2025-12-20 09:53:28 train acc=0.28, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01743629455566406, 0.0, 2.701806640625, 2.701806640625, 0.43162353515625]
2025-12-20 09:53:28 Epoch: 2, loss: 5.4247, lr: 0.00009911
2025-12-20 09:53:43 train acc=0.268125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.024962921142578125, 0.0, 2.679228515625, 2.679228515625, 0.43052001953125]
2025-12-20 09:53:43 Epoch: 3, loss: 5.3875, lr: 0.00009843
2025-12-20 09:53:58 train acc=0.273125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03806121826171875, 0.0, 2.6884375, 2.6884375, 0.4252099609375]
2025-12-20 09:53:58 Epoch: 4, loss: 5.4190, lr: 0.00009755
2025-12-20 09:54:14 train acc=0.270625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05341766357421875, 0.0, 2.660927734375, 2.660927734375, 0.42768310546875]
2025-12-20 09:54:14 Epoch: 5, loss: 5.3789, lr: 0.00009649
2025-12-20 09:54:29 train acc=0.2925, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06845916748046875, 0.0, 2.617998046875, 2.617998046875, 0.42733642578125]
2025-12-20 09:54:29 Epoch: 6, loss: 5.3085, lr: 0.00009524
2025-12-20 09:54:44 train acc=0.3, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0859869384765625, 0.0, 2.5738671875, 2.5738671875, 0.4329052734375]
2025-12-20 09:54:44 Epoch: 7, loss: 5.2377, lr: 0.00009382
2025-12-20 09:54:59 train acc=0.2925, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.100457763671875, 0.0, 2.563125, 2.563125, 0.43609130859375]
2025-12-20 09:54:59 Epoch: 8, loss: 5.2308, lr: 0.00009222
2025-12-20 09:55:15 train acc=0.296875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1143890380859375, 0.0, 2.523046875, 2.523046875, 0.4422509765625]
2025-12-20 09:55:15 Epoch: 9, loss: 5.1644, lr: 0.00009045
2025-12-20 09:55:30 train acc=0.296875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.132557373046875, 0.0, 2.490498046875, 2.490498046875, 0.456630859375]
2025-12-20 09:55:30 Epoch: 10, loss: 5.1176, lr: 0.00008853
2025-12-20 09:55:45 train acc=0.319375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1476422119140625, 0.0, 2.41927734375, 2.41927734375, 0.46879638671875]
2025-12-20 09:55:45 Epoch: 11, loss: 4.9901, lr: 0.00008645
2025-12-20 09:56:00 train acc=0.324375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.16443359375, 0.0, 2.371337890625, 2.371337890625, 0.486064453125]
2025-12-20 09:56:00 Epoch: 12, loss: 4.9110, lr: 0.00008423
2025-12-20 09:56:16 train acc=0.32875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.177679443359375, 0.0, 2.340458984375, 2.340458984375, 0.506279296875]
2025-12-20 09:56:16 Epoch: 13, loss: 4.8627, lr: 0.00008187
2025-12-20 09:56:31 train acc=0.34875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.193536376953125, 0.0, 2.300771484375, 2.300771484375, 0.52319580078125]
2025-12-20 09:56:31 Epoch: 14, loss: 4.7995, lr: 0.00007939
2025-12-20 09:56:46 train acc=0.35, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20518798828125, 0.0, 2.247353515625, 2.247353515625, 0.5474658203125]
2025-12-20 09:56:46 Epoch: 15, loss: 4.7046, lr: 0.00007679
2025-12-20 09:57:02 train acc=0.3625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21822509765625, 0.0, 2.22451171875, 2.22451171875, 0.5684716796875]
2025-12-20 09:57:02 Epoch: 16, loss: 4.6721, lr: 0.00007409
2025-12-20 09:57:17 train acc=0.37875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.226248779296875, 0.0, 2.184423828125, 2.184423828125, 0.5889794921875]
2025-12-20 09:57:17 Epoch: 17, loss: 4.6007, lr: 0.00007129
2025-12-20 09:57:32 train acc=0.37875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2338232421875, 0.0, 2.174091796875, 2.174091796875, 0.6024755859375]
2025-12-20 09:57:32 Epoch: 18, loss: 4.5881, lr: 0.00006841
2025-12-20 09:57:48 train acc=0.39875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.243330078125, 0.0, 2.1169140625, 2.1169140625, 0.62540283203125]
2025-12-20 09:57:48 Epoch: 19, loss: 4.4839, lr: 0.00006545
2025-12-20 09:58:03 train acc=0.403125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.249071044921875, 0.0, 2.09130859375, 2.09130859375, 0.6395849609375]
2025-12-20 09:58:03 Epoch: 20, loss: 4.4383, lr: 0.00006243
2025-12-20 09:58:18 train acc=0.39875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.256287841796875, 0.0, 2.072822265625, 2.072822265625, 0.657724609375]
2025-12-20 09:58:18 Epoch: 21, loss: 4.4090, lr: 0.00005937
2025-12-20 09:58:34 train acc=0.413125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.26344482421875, 0.0, 2.0360546875, 2.0360546875, 0.6810693359375]
2025-12-20 09:58:34 Epoch: 22, loss: 4.3429, lr: 0.00005627
2025-12-20 09:58:49 train acc=0.42125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.268447265625, 0.0, 2.005498046875, 2.005498046875, 0.6936669921875]
2025-12-20 09:58:49 Epoch: 23, loss: 4.2864, lr: 0.00005314
2025-12-20 09:59:04 train acc=0.413125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27584228515625, 0.0, 1.989130859375, 1.989130859375, 0.710029296875]
2025-12-20 09:59:04 Epoch: 24, loss: 4.2616, lr: 0.00005000
2025-12-20 09:59:19 train acc=0.44125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27955078125, 0.0, 1.94853515625, 1.94853515625, 0.7268212890625]
2025-12-20 09:59:19 Epoch: 25, loss: 4.1843, lr: 0.00004686
2025-12-20 09:59:35 train acc=0.44625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.283876953125, 0.0, 1.94234375, 1.94234375, 0.7427685546875]
2025-12-20 09:59:35 Epoch: 26, loss: 4.1765, lr: 0.00004373
2025-12-20 09:59:50 train acc=0.468125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.29026123046875, 0.0, 1.897158203125, 1.897158203125, 0.7519287109375]
2025-12-20 09:59:50 Epoch: 27, loss: 4.0926, lr: 0.00004063
2025-12-20 10:00:05 train acc=0.461875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2920458984375, 0.0, 1.882109375, 1.882109375, 0.761796875]
2025-12-20 10:00:05 Epoch: 28, loss: 4.0643, lr: 0.00003757
2025-12-20 10:00:21 train acc=0.460625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2995166015625, 0.0, 1.86177734375, 1.86177734375, 0.7828564453125]
2025-12-20 10:00:21 Epoch: 29, loss: 4.0311, lr: 0.00003455
2025-12-20 10:00:36 train acc=0.474375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.300621337890625, 0.0, 1.855068359375, 1.855068359375, 0.7898388671875]
2025-12-20 10:00:36 Epoch: 30, loss: 4.0185, lr: 0.00003159
2025-12-20 10:00:51 train acc=0.47625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.303564453125, 0.0, 1.82783203125, 1.82783203125, 0.796748046875]
2025-12-20 10:00:51 Epoch: 31, loss: 3.9674, lr: 0.00002871
2025-12-20 10:01:06 train acc=0.500625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.30676025390625, 0.0, 1.817861328125, 1.817861328125, 0.8080908203125]
2025-12-20 10:01:06 Epoch: 32, loss: 3.9504, lr: 0.00002591
2025-12-20 10:01:22 train acc=0.485625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31098388671875, 0.0, 1.814521484375, 1.814521484375, 0.8196435546875]
2025-12-20 10:01:22 Epoch: 33, loss: 3.9483, lr: 0.00002321
2025-12-20 10:01:37 train acc=0.5025, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3108203125, 0.0, 1.780615234375, 1.780615234375, 0.8252783203125]
2025-12-20 10:01:37 Epoch: 34, loss: 3.8803, lr: 0.00002061
2025-12-20 10:01:52 train acc=0.511875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3147021484375, 0.0, 1.787353515625, 1.787353515625, 0.8279833984375]
2025-12-20 10:01:52 Epoch: 35, loss: 3.8976, lr: 0.00001813
2025-12-20 10:02:07 train acc=0.504375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31643798828125, 0.0, 1.77830078125, 1.77830078125, 0.83734375]
2025-12-20 10:02:07 Epoch: 36, loss: 3.8816, lr: 0.00001577
2025-12-20 10:02:23 train acc=0.506875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31522216796875, 0.0, 1.776904296875, 1.776904296875, 0.833330078125]
2025-12-20 10:02:23 Epoch: 37, loss: 3.8772, lr: 0.00001355
2025-12-20 10:02:38 train acc=0.5125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31821044921875, 0.0, 1.7424609375, 1.7424609375, 0.84978515625]
2025-12-20 10:02:38 Epoch: 38, loss: 3.8118, lr: 0.00001147
2025-12-20 10:02:53 train acc=0.49375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3189794921875, 0.0, 1.76923828125, 1.76923828125, 0.8497412109375]
2025-12-20 10:02:53 Epoch: 39, loss: 3.8657, lr: 0.00000955
2025-12-20 10:03:08 train acc=0.505, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.318887939453125, 0.0, 1.753994140625, 1.753994140625, 0.8512109375]
2025-12-20 10:03:08 Epoch: 40, loss: 3.8353, lr: 0.00000778
2025-12-20 10:03:24 train acc=0.529375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.32308837890625, 0.0, 1.737373046875, 1.737373046875, 0.8553564453125]
2025-12-20 10:03:24 Epoch: 41, loss: 3.8063, lr: 0.00000618
2025-12-20 10:03:39 train acc=0.513125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.321658935546875, 0.0, 1.7356103515625, 1.7356103515625, 0.860048828125]
2025-12-20 10:03:39 Epoch: 42, loss: 3.8015, lr: 0.00000476
2025-12-20 10:03:54 train acc=0.514375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3226025390625, 0.0, 1.733115234375, 1.733115234375, 0.8633544921875]
2025-12-20 10:03:54 Epoch: 43, loss: 3.7974, lr: 0.00000351
2025-12-20 10:04:10 train acc=0.514375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.324700927734375, 0.0, 1.72443359375, 1.72443359375, 0.8645263671875]
2025-12-20 10:04:10 Epoch: 44, loss: 3.7823, lr: 0.00000245
2025-12-20 10:04:25 train acc=0.53, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3252392578125, 0.0, 1.7257421875, 1.7257421875, 0.863701171875]
2025-12-20 10:04:25 Epoch: 45, loss: 3.7853, lr: 0.00000157
2025-12-20 10:04:40 train acc=0.509375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.325784912109375, 0.0, 1.73802734375, 1.73802734375, 0.8676318359375]
2025-12-20 10:04:40 Epoch: 46, loss: 3.8105, lr: 0.00000089
2025-12-20 10:04:56 train acc=0.514375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.32397216796875, 0.0, 1.73234375, 1.73234375, 0.8689404296875]
2025-12-20 10:04:56 Epoch: 47, loss: 3.7973, lr: 0.00000039
2025-12-20 10:05:11 train acc=0.515625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.323961181640625, 0.0, 1.721865234375, 1.721865234375, 0.86525390625]
2025-12-20 10:05:11 Epoch: 48, loss: 3.7763, lr: 0.00000010
2025-12-20 10:05:26 train acc=0.51125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.32359130859375, 0.0, 1.728359375, 1.728359375, 0.86455078125]
2025-12-20 10:05:26 Epoch: 49, loss: 3.7890, lr: 0.00000000
2025-12-20 10:06:58 {'name': 'fgvc', 'acc': [{'clip_logits': 24.722472247224722, 'cma_logits': 17.82178217821782, 'GLR_logits': 38.19381938193819, 'final_logits': 28.83288328832883, 'acc': 38.19381938193819}], 'detail': 'dataset_name=fgvc, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=100, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 10:06:58 Preparing ViT-B/16 model.
2025-12-20 10:07:01 Getting cached textual weights W ...
2025-12-20 10:07:02 Initializing CMA adapter learner...
2025-12-20 10:07:02 Initializing SKD distillation...
2025-12-20 10:07:02 Preparing caltech101 dataset.
2025-12-20 10:07:17 train acc=0.913125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0010596984624862671, 0.0, 0.27269424438476564, 0.27269424438476564, 0.64553955078125]
2025-12-20 10:07:17 Epoch: 0, loss: 0.5529, lr: 0.00009990
2025-12-20 10:07:32 train acc=0.9125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0031524658203125, 0.0, 0.2718827819824219, 0.2718827819824219, 0.6449658203125]
2025-12-20 10:07:32 Epoch: 1, loss: 0.5534, lr: 0.00009961
2025-12-20 10:07:47 train acc=0.910625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0030379104614257813, 0.0, 0.26778884887695314, 0.26778884887695314, 0.6456396484375]
2025-12-20 10:07:47 Epoch: 2, loss: 0.5451, lr: 0.00009911
2025-12-20 10:08:02 train acc=0.90875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0037098312377929687, 0.0, 0.28303985595703124, 0.28303985595703124, 0.64431640625]
2025-12-20 10:08:02 Epoch: 3, loss: 0.5763, lr: 0.00009843
2025-12-20 10:08:17 train acc=0.9175, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0036908721923828124, 0.0, 0.2733555603027344, 0.2733555603027344, 0.64127197265625]
2025-12-20 10:08:17 Epoch: 4, loss: 0.5568, lr: 0.00009755
2025-12-20 10:08:33 train acc=0.914375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004188117980957032, 0.0, 0.27337432861328126, 0.27337432861328126, 0.64267822265625]
2025-12-20 10:08:33 Epoch: 5, loss: 0.5574, lr: 0.00009649
2025-12-20 10:08:48 train acc=0.916875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.005347518920898437, 0.0, 0.26499252319335936, 0.26499252319335936, 0.640830078125]
2025-12-20 10:08:48 Epoch: 6, loss: 0.5417, lr: 0.00009524
2025-12-20 10:09:03 train acc=0.914375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008125038146972656, 0.0, 0.27097991943359373, 0.27097991943359373, 0.64708251953125]
2025-12-20 10:09:03 Epoch: 7, loss: 0.5566, lr: 0.00009382
2025-12-20 10:09:18 train acc=0.916875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.010777435302734374, 0.0, 0.26285568237304685, 0.26285568237304685, 0.64004638671875]
2025-12-20 10:09:18 Epoch: 8, loss: 0.5429, lr: 0.00009222
2025-12-20 10:09:33 train acc=0.92125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.013784713745117187, 0.0, 0.25825714111328124, 0.25825714111328124, 0.6443017578125]
2025-12-20 10:09:33 Epoch: 9, loss: 0.5367, lr: 0.00009045
2025-12-20 10:09:48 train acc=0.9275, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01682281494140625, 0.0, 0.25113616943359374, 0.25113616943359374, 0.64590576171875]
2025-12-20 10:09:48 Epoch: 10, loss: 0.5255, lr: 0.00008853
2025-12-20 10:10:03 train acc=0.926875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.020010986328125, 0.0, 0.2384503173828125, 0.2384503173828125, 0.646240234375]
2025-12-20 10:10:03 Epoch: 11, loss: 0.5034, lr: 0.00008645
2025-12-20 10:10:18 train acc=0.923125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.023129425048828124, 0.0, 0.25067169189453126, 0.25067169189453126, 0.6465478515625]
2025-12-20 10:10:18 Epoch: 12, loss: 0.5309, lr: 0.00008423
2025-12-20 10:10:33 train acc=0.928125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02545745849609375, 0.0, 0.2389300537109375, 0.2389300537109375, 0.64811767578125]
2025-12-20 10:10:33 Epoch: 13, loss: 0.5098, lr: 0.00008187
2025-12-20 10:10:48 train acc=0.92625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02786773681640625, 0.0, 0.24102935791015626, 0.24102935791015626, 0.65326171875]
2025-12-20 10:10:48 Epoch: 14, loss: 0.5165, lr: 0.00007939
2025-12-20 10:11:03 train acc=0.9325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0295355224609375, 0.0, 0.22734130859375, 0.22734130859375, 0.654462890625]
2025-12-20 10:11:03 Epoch: 15, loss: 0.4907, lr: 0.00007679
2025-12-20 10:11:18 train acc=0.93125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.032114410400390626, 0.0, 0.23148757934570313, 0.23148757934570313, 0.65408935546875]
2025-12-20 10:11:18 Epoch: 16, loss: 0.5016, lr: 0.00007409
2025-12-20 10:11:33 train acc=0.9325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03274810791015625, 0.0, 0.22445053100585938, 0.22445053100585938, 0.6599951171875]
2025-12-20 10:11:33 Epoch: 17, loss: 0.4883, lr: 0.00007129
2025-12-20 10:11:48 train acc=0.933125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03599761962890625, 0.0, 0.21959739685058594, 0.21959739685058594, 0.660712890625]
2025-12-20 10:11:48 Epoch: 18, loss: 0.4818, lr: 0.00006841
2025-12-20 10:12:03 train acc=0.936875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0371466064453125, 0.0, 0.22495742797851562, 0.22495742797851562, 0.662705078125]
2025-12-20 10:12:03 Epoch: 19, loss: 0.4937, lr: 0.00006545
2025-12-20 10:12:18 train acc=0.929375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03840423583984375, 0.0, 0.22013092041015625, 0.22013092041015625, 0.66333984375]
2025-12-20 10:12:18 Epoch: 20, loss: 0.4853, lr: 0.00006243
2025-12-20 10:12:33 train acc=0.931875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04037933349609375, 0.0, 0.22613784790039063, 0.22613784790039063, 0.6659765625]
2025-12-20 10:12:33 Epoch: 21, loss: 0.4993, lr: 0.00005937
2025-12-20 10:12:48 train acc=0.93625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04149627685546875, 0.0, 0.2128497314453125, 0.2128497314453125, 0.6652001953125]
2025-12-20 10:12:48 Epoch: 22, loss: 0.4739, lr: 0.00005627
2025-12-20 10:13:03 train acc=0.935625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.042523193359375, 0.0, 0.21596725463867186, 0.21596725463867186, 0.67181640625]
2025-12-20 10:13:03 Epoch: 23, loss: 0.4812, lr: 0.00005314
2025-12-20 10:13:18 train acc=0.9325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04301727294921875, 0.0, 0.20767333984375, 0.20767333984375, 0.6740966796875]
2025-12-20 10:13:18 Epoch: 24, loss: 0.4651, lr: 0.00005000
2025-12-20 10:13:34 train acc=0.936875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04468353271484375, 0.0, 0.2104058837890625, 0.2104058837890625, 0.67261474609375]
2025-12-20 10:13:34 Epoch: 25, loss: 0.4722, lr: 0.00004686
2025-12-20 10:13:49 train acc=0.938125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.045540771484375, 0.0, 0.20859344482421874, 0.20859344482421874, 0.67568115234375]
2025-12-20 10:13:49 Epoch: 26, loss: 0.4695, lr: 0.00004373
2025-12-20 10:14:04 train acc=0.939375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04619415283203125, 0.0, 0.2015264892578125, 0.2015264892578125, 0.67642822265625]
2025-12-20 10:14:04 Epoch: 27, loss: 0.4560, lr: 0.00004063
2025-12-20 10:14:19 train acc=0.939375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0467828369140625, 0.0, 0.20208892822265626, 0.20208892822265626, 0.6802490234375]
2025-12-20 10:14:19 Epoch: 28, loss: 0.4577, lr: 0.00003757
2025-12-20 10:14:34 train acc=0.93875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04784637451171875, 0.0, 0.20595596313476563, 0.20595596313476563, 0.68236572265625]
2025-12-20 10:14:34 Epoch: 29, loss: 0.4666, lr: 0.00003455
2025-12-20 10:14:49 train acc=0.94625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04868682861328125, 0.0, 0.19796096801757812, 0.19796096801757812, 0.6801220703125]
2025-12-20 10:14:49 Epoch: 30, loss: 0.4514, lr: 0.00003159
2025-12-20 10:15:04 train acc=0.945, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.049124755859375, 0.0, 0.19548538208007812, 0.19548538208007812, 0.68410888671875]
2025-12-20 10:15:04 Epoch: 31, loss: 0.4469, lr: 0.00002871
2025-12-20 10:15:19 train acc=0.941875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04934417724609375, 0.0, 0.19398239135742187, 0.19398239135742187, 0.6843115234375]
2025-12-20 10:15:19 Epoch: 32, loss: 0.4441, lr: 0.00002591
2025-12-20 10:15:34 train acc=0.943125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.049329833984375, 0.0, 0.19105880737304687, 0.19105880737304687, 0.6861669921875]
2025-12-20 10:15:34 Epoch: 33, loss: 0.4383, lr: 0.00002321
2025-12-20 10:15:49 train acc=0.943125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05095916748046875, 0.0, 0.19227645874023438, 0.19227645874023438, 0.685546875]
2025-12-20 10:15:49 Epoch: 34, loss: 0.4424, lr: 0.00002061
2025-12-20 10:16:04 train acc=0.945625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0504827880859375, 0.0, 0.19178253173828125, 0.19178253173828125, 0.6883056640625]
2025-12-20 10:16:04 Epoch: 35, loss: 0.4409, lr: 0.00001813
2025-12-20 10:16:19 train acc=0.949375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0508135986328125, 0.0, 0.18468215942382812, 0.18468215942382812, 0.68723876953125]
2025-12-20 10:16:19 Epoch: 36, loss: 0.4271, lr: 0.00001577
2025-12-20 10:16:35 train acc=0.945, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05128570556640625, 0.0, 0.19058242797851563, 0.19058242797851563, 0.68432373046875]
2025-12-20 10:16:35 Epoch: 37, loss: 0.4393, lr: 0.00001355
2025-12-20 10:16:50 train acc=0.9475, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05160858154296875, 0.0, 0.1909288787841797, 0.1909288787841797, 0.689677734375]
2025-12-20 10:16:50 Epoch: 38, loss: 0.4403, lr: 0.00001147
2025-12-20 10:17:05 train acc=0.9475, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.051700439453125, 0.0, 0.18627655029296875, 0.18627655029296875, 0.6855712890625]
2025-12-20 10:17:05 Epoch: 39, loss: 0.4311, lr: 0.00000955
2025-12-20 10:17:20 train acc=0.945625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0515997314453125, 0.0, 0.18505706787109374, 0.18505706787109374, 0.68689453125]
2025-12-20 10:17:20 Epoch: 40, loss: 0.4286, lr: 0.00000778
2025-12-20 10:17:35 train acc=0.943125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.052174072265625, 0.0, 0.19150558471679688, 0.19150558471679688, 0.6884033203125]
2025-12-20 10:17:35 Epoch: 41, loss: 0.4421, lr: 0.00000618
2025-12-20 10:17:50 train acc=0.94875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05190704345703125, 0.0, 0.18262229919433592, 0.18262229919433592, 0.6919189453125]
2025-12-20 10:17:50 Epoch: 42, loss: 0.4241, lr: 0.00000476
2025-12-20 10:18:05 train acc=0.944375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0516253662109375, 0.0, 0.1935304260253906, 0.1935304260253906, 0.6906298828125]
2025-12-20 10:18:05 Epoch: 43, loss: 0.4456, lr: 0.00000351
2025-12-20 10:18:20 train acc=0.948125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05196533203125, 0.0, 0.18835037231445312, 0.18835037231445312, 0.6923388671875]
2025-12-20 10:18:20 Epoch: 44, loss: 0.4356, lr: 0.00000245
2025-12-20 10:18:35 train acc=0.948125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0520477294921875, 0.0, 0.19163925170898438, 0.19163925170898438, 0.6904541015625]
2025-12-20 10:18:35 Epoch: 45, loss: 0.4422, lr: 0.00000157
2025-12-20 10:18:50 train acc=0.944375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05214324951171875, 0.0, 0.18411285400390626, 0.18411285400390626, 0.6903271484375]
2025-12-20 10:18:50 Epoch: 46, loss: 0.4273, lr: 0.00000089
2025-12-20 10:19:05 train acc=0.94875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05213104248046875, 0.0, 0.18633460998535156, 0.18633460998535156, 0.6928564453125]
2025-12-20 10:19:05 Epoch: 47, loss: 0.4318, lr: 0.00000039
2025-12-20 10:19:20 train acc=0.95125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.052059326171875, 0.0, 0.1778216552734375, 0.1778216552734375, 0.69308837890625]
2025-12-20 10:19:20 Epoch: 48, loss: 0.4146, lr: 0.00000010
2025-12-20 10:19:35 train acc=0.951875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05208282470703125, 0.0, 0.18317337036132814, 0.18317337036132814, 0.69365234375]
2025-12-20 10:19:35 Epoch: 49, loss: 0.4254, lr: 0.00000000
2025-12-20 10:19:56 {'name': 'caltech101', 'acc': [{'clip_logits': 92.90060851926978, 'cma_logits': 92.81947261663286, 'GLR_logits': 94.76673427991886, 'final_logits': 94.32048681541582, 'acc': 94.76673427991886}], 'detail': 'dataset_name=caltech101, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=100, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 10:19:56 Preparing ViT-B/16 model.
2025-12-20 10:20:01 Getting cached textual weights W ...
2025-12-20 10:20:03 Initializing CMA adapter learner...
2025-12-20 10:20:03 Initializing SKD distillation...
2025-12-20 10:20:03 Preparing stanford_cars dataset.
2025-12-20 10:20:43 train acc=0.6352040816326531, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0026634904194851312, 0.0, 1.0958663006218112, 1.0958663006218112, 1.532146843112245]
2025-12-20 10:20:43 Epoch: 0, loss: 2.2097, lr: 0.00009990
2025-12-20 10:21:21 train acc=0.6377551020408163, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00987124929622728, 0.0, 1.0830127949617347, 1.0830127949617347, 1.5270597496811225]
2025-12-20 10:21:21 Epoch: 1, loss: 2.1911, lr: 0.00009961
2025-12-20 10:21:59 train acc=0.6470025510204082, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.022225204779177297, 0.0, 1.0643522301498725, 1.0643522301498725, 1.5237962372448979]
2025-12-20 10:21:59 Epoch: 2, loss: 2.1661, lr: 0.00009911
2025-12-20 10:22:37 train acc=0.6654974489795918, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03828967347437022, 0.0, 1.022022480867347, 1.022022480867347, 1.5264219945790816]
2025-12-20 10:22:37 Epoch: 3, loss: 2.0976, lr: 0.00009843
2025-12-20 10:23:15 train acc=0.6785714285714286, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05478372379225128, 0.0, 0.9945666254783163, 0.9945666254783163, 1.5298150510204083]
2025-12-20 10:23:15 Epoch: 4, loss: 2.0592, lr: 0.00009755
2025-12-20 10:23:53 train acc=0.6884566326530612, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07178964420240752, 0.0, 0.9401519152582908, 0.9401519152582908, 1.549739915497449]
2025-12-20 10:23:53 Epoch: 5, loss: 1.9675, lr: 0.00009649
2025-12-20 10:24:31 train acc=0.7088647959183674, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08543115732621173, 0.0, 0.9033427335778061, 0.9033427335778061, 1.5637555803571428]
2025-12-20 10:24:31 Epoch: 6, loss: 1.9078, lr: 0.00009524
2025-12-20 10:25:09 train acc=0.7161989795918368, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09781537737165179, 0.0, 0.8781725825095663, 0.8781725825095663, 1.5807557397959184]
2025-12-20 10:25:09 Epoch: 7, loss: 1.8699, lr: 0.00009382
2025-12-20 10:25:47 train acc=0.7372448979591837, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10946281588807398, 0.0, 0.8327624262595663, 0.8327624262595663, 1.6082240513392858]
2025-12-20 10:25:47 Epoch: 8, loss: 1.7911, lr: 0.00009222
2025-12-20 10:26:25 train acc=0.7445790816326531, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.118072509765625, 0.0, 0.8004424426020408, 0.8004424426020408, 1.6261310188137754]
2025-12-20 10:26:25 Epoch: 9, loss: 1.7352, lr: 0.00009045
2025-12-20 10:27:04 train acc=0.7576530612244898, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.12852851711973853, 0.0, 0.777351223692602, 0.777351223692602, 1.6556421396683674]
2025-12-20 10:27:04 Epoch: 10, loss: 1.6998, lr: 0.00008853
2025-12-20 10:27:42 train acc=0.7710459183673469, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.13692178531568877, 0.0, 0.7511123345822704, 0.7511123345822704, 1.6742715640943877]
2025-12-20 10:27:42 Epoch: 11, loss: 1.6559, lr: 0.00008645
2025-12-20 10:28:20 train acc=0.7920918367346939, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1461555325255102, 0.0, 0.7050021424585459, 0.7050021424585459, 1.7154466278698979]
2025-12-20 10:28:20 Epoch: 12, loss: 1.5733, lr: 0.00008423
2025-12-20 10:28:58 train acc=0.7978316326530612, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.15515852947624362, 0.0, 0.6731517558195153, 0.6731517558195153, 1.7437719228316326]
2025-12-20 10:28:58 Epoch: 13, loss: 1.5188, lr: 0.00008187
2025-12-20 10:29:36 train acc=0.8086734693877551, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.16184966418207908, 0.0, 0.6559628856425382, 0.6559628856425382, 1.7759984853316326]
2025-12-20 10:29:36 Epoch: 14, loss: 1.4915, lr: 0.00007939
2025-12-20 10:30:14 train acc=0.8239795918367347, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.16963787468112246, 0.0, 0.6164849728954082, 0.6164849728954082, 1.805125956632653]
2025-12-20 10:30:14 Epoch: 15, loss: 1.4206, lr: 0.00007679
2025-12-20 10:30:52 train acc=0.8386479591836735, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.17410216039540816, 0.0, 0.5853339993223852, 0.5853339993223852, 1.8338598134566326]
2025-12-20 10:30:52 Epoch: 16, loss: 1.3631, lr: 0.00007409
2025-12-20 10:31:30 train acc=0.8408801020408163, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.18136658960459184, 0.0, 0.5782707370057398, 0.5782707370057398, 1.866619499362245]
2025-12-20 10:31:30 Epoch: 17, loss: 1.3567, lr: 0.00007129
2025-12-20 10:32:08 train acc=0.8469387755102041, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.18730381556919642, 0.0, 0.5419959243463011, 0.5419959243463011, 1.8953184789540816]
2025-12-20 10:32:08 Epoch: 18, loss: 1.2903, lr: 0.00006841
2025-12-20 10:32:46 train acc=0.8606505102040817, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1922557597257653, 0.0, 0.5272029954559949, 0.5272029954559949, 1.9325474330357142]
2025-12-20 10:32:46 Epoch: 19, loss: 1.2660, lr: 0.00006545
2025-12-20 10:33:25 train acc=0.8670280612244898, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1993389518893495, 0.0, 0.5028948102678571, 0.5028948102678571, 1.9590989716198979]
2025-12-20 10:33:25 Epoch: 20, loss: 1.2248, lr: 0.00006243
2025-12-20 10:34:03 train acc=0.8807397959183674, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20275941187021684, 0.0, 0.48106664540816324, 0.48106664540816324, 2.0034329161352042]
2025-12-20 10:34:03 Epoch: 21, loss: 1.1849, lr: 0.00005937
2025-12-20 10:34:41 train acc=0.8820153061224489, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20717013612085458, 0.0, 0.4674227967554209, 0.4674227967554209, 2.0268156090561225]
2025-12-20 10:34:41 Epoch: 22, loss: 1.1623, lr: 0.00005627
2025-12-20 10:35:19 train acc=0.892219387755102, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2098930514588648, 0.0, 0.44198421556122447, 0.44198421556122447, 2.060078523596939]
2025-12-20 10:35:19 Epoch: 23, loss: 1.1145, lr: 0.00005314
2025-12-20 10:35:57 train acc=0.8896683673469388, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21514082928093112, 0.0, 0.4329949203802615, 0.4329949203802615, 2.094826211734694]
2025-12-20 10:35:57 Epoch: 24, loss: 1.1020, lr: 0.00005000
2025-12-20 10:36:35 train acc=0.9024234693877551, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21689839265784439, 0.0, 0.41051187320631377, 0.41051187320631377, 2.118343431122449]
2025-12-20 10:36:35 Epoch: 25, loss: 1.0591, lr: 0.00004686
2025-12-20 10:37:13 train acc=0.9008290816326531, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2207454759247449, 0.0, 0.4077506551937181, 0.4077506551937181, 2.141975247130102]
2025-12-20 10:37:13 Epoch: 26, loss: 1.0577, lr: 0.00004373
2025-12-20 10:37:51 train acc=0.9100765306122449, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22290973274075254, 0.0, 0.3877395318478954, 0.3877395318478954, 2.1660853794642856]
2025-12-20 10:37:51 Epoch: 27, loss: 1.0200, lr: 0.00004063
2025-12-20 10:38:29 train acc=0.9132653061224489, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22522969148596939, 0.0, 0.37188814124282527, 0.37188814124282527, 2.1960200095663267]
2025-12-20 10:38:29 Epoch: 28, loss: 0.9910, lr: 0.00003757
2025-12-20 10:39:07 train acc=0.9135841836734694, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2277782206632653, 0.0, 0.37370580556441324, 0.37370580556441324, 2.218695192920918]
2025-12-20 10:39:07 Epoch: 29, loss: 0.9974, lr: 0.00003455
2025-12-20 10:39:45 train acc=0.9158163265306123, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22886252889827807, 0.0, 0.3618357132892219, 0.3618357132892219, 2.227588887117347]
2025-12-20 10:39:45 Epoch: 30, loss: 0.9748, lr: 0.00003159
2025-12-20 10:40:23 train acc=0.920280612244898, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23012246890943877, 0.0, 0.35392045001594385, 0.35392045001594385, 2.256153340242347]
2025-12-20 10:40:23 Epoch: 31, loss: 0.9606, lr: 0.00002871
2025-12-20 10:41:01 train acc=0.9209183673469388, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23309699856505103, 0.0, 0.34405330735809947, 0.34405330735809947, 2.2766810825892856]
2025-12-20 10:41:01 Epoch: 32, loss: 0.9440, lr: 0.00002591
2025-12-20 10:41:39 train acc=0.9247448979591837, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23294690190529338, 0.0, 0.3315846968670281, 0.3315846968670281, 2.29874342315051]
2025-12-20 10:41:39 Epoch: 33, loss: 0.9191, lr: 0.00002321
2025-12-20 10:42:17 train acc=0.9231505102040817, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23475242147640307, 0.0, 0.3308258056640625, 0.3308258056640625, 2.307293327487245]
2025-12-20 10:42:17 Epoch: 34, loss: 0.9195, lr: 0.00002061
2025-12-20 10:42:56 train acc=0.9260204081632653, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23443042988679846, 0.0, 0.3245989741111288, 0.3245989741111288, 2.318359375]
2025-12-20 10:42:56 Epoch: 35, loss: 0.9068, lr: 0.00001813
2025-12-20 10:43:34 train acc=0.9320790816326531, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23601672114158162, 0.0, 0.31743824238679846, 0.31743824238679846, 2.324348294005102]
2025-12-20 10:43:34 Epoch: 36, loss: 0.8941, lr: 0.00001577
2025-12-20 10:44:11 train acc=0.9285714285714286, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23601672114158162, 0.0, 0.3147685771085778, 0.3147685771085778, 2.3386928013392856]
2025-12-20 10:44:11 Epoch: 37, loss: 0.8890, lr: 0.00001355
2025-12-20 10:44:50 train acc=0.9295280612244898, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2375861965880102, 0.0, 0.3113095030492666, 0.3113095030492666, 2.3478854432397958]
2025-12-20 10:44:50 Epoch: 38, loss: 0.8837, lr: 0.00001147
2025-12-20 10:45:28 train acc=0.9371811224489796, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23750398596938777, 0.0, 0.2989564233896684, 0.2989564233896684, 2.3520906409438775]
2025-12-20 10:45:28 Epoch: 39, loss: 0.8589, lr: 0.00000955
2025-12-20 10:46:06 train acc=0.9336734693877551, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23747097716039542, 0.0, 0.3031226956114477, 0.3031226956114477, 2.368951291454082]
2025-12-20 10:46:06 Epoch: 40, loss: 0.8674, lr: 0.00000778
2025-12-20 10:46:44 train acc=0.9394132653061225, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23727043307557397, 0.0, 0.3012782505580357, 0.3012782505580357, 2.362872688137755]
2025-12-20 10:46:44 Epoch: 41, loss: 0.8635, lr: 0.00000618
2025-12-20 10:47:22 train acc=0.9333545918367347, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23814610072544642, 0.0, 0.29640010911591197, 0.29640010911591197, 2.3730568399234695]
2025-12-20 10:47:22 Epoch: 42, loss: 0.8547, lr: 0.00000476
2025-12-20 10:48:00 train acc=0.9381377551020408, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23779296875, 0.0, 0.2940736108896684, 0.2940736108896684, 2.3753936144770407]
2025-12-20 10:48:00 Epoch: 43, loss: 0.8497, lr: 0.00000351
2025-12-20 10:48:38 train acc=0.9368622448979592, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23840954838966838, 0.0, 0.2949078618263712, 0.2949078618263712, 2.3849848533163267]
2025-12-20 10:48:38 Epoch: 44, loss: 0.8521, lr: 0.00000245
2025-12-20 10:49:16 train acc=0.9387755102040817, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23829246053890307, 0.0, 0.2881957073600925, 0.2881957073600925, 2.382832429846939]
2025-12-20 10:49:16 Epoch: 45, loss: 0.8385, lr: 0.00000157
2025-12-20 10:49:54 train acc=0.939094387755102, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23823640784438777, 0.0, 0.29483623893893496, 0.29483623893893496, 2.3866938376913267]
2025-12-20 10:49:54 Epoch: 46, loss: 0.8518, lr: 0.00000089
2025-12-20 10:50:32 train acc=0.9352678571428571, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23793808294802296, 0.0, 0.29914793676259566, 0.29914793676259566, 2.3764897560586733]
2025-12-20 10:50:32 Epoch: 47, loss: 0.8600, lr: 0.00000039
2025-12-20 10:51:11 train acc=0.9387755102040817, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23802901287468112, 0.0, 0.2951009322185906, 0.2951009322185906, 2.3772869499362246]
2025-12-20 10:51:11 Epoch: 48, loss: 0.8520, lr: 0.00000010
2025-12-20 10:51:49 train acc=0.9378188775510204, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23852912747130103, 0.0, 0.2986045370296556, 0.2986045370296556, 2.3829071667729593]
2025-12-20 10:51:49 Epoch: 49, loss: 0.8596, lr: 0.00000000
2025-12-20 10:53:21 {'name': 'stanford_cars', 'acc': [{'clip_logits': 65.2779505036687, 'cma_logits': 55.77664469593334, 'GLR_logits': 79.67914438502673, 'final_logits': 64.66857356050242, 'acc': 79.67914438502673}], 'detail': 'dataset_name=stanford_cars, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=196, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 10:53:21 Preparing ViT-B/16 model.
2025-12-20 10:53:25 Getting cached textual weights W ...
2025-12-20 10:53:26 Initializing CMA adapter learner...
2025-12-20 10:53:26 Initializing SKD distillation...
2025-12-20 10:53:26 Preparing dtd dataset.
2025-12-20 10:53:35 train acc=0.45611702127659576, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 5.724835903086561e-05, 0.0, 2.0262425199468086, 2.0262425199468086, 0.09630568484042554]
2025-12-20 10:53:35 Epoch: 0, loss: 4.0529, lr: 0.00009990
2025-12-20 10:53:41 train acc=0.45478723404255317, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0038391072699364196, 0.0, 2.0279463098404253, 2.0279463098404253, 0.09689006399601063]
2025-12-20 10:53:41 Epoch: 1, loss: 4.0608, lr: 0.00009961
2025-12-20 10:53:47 train acc=0.4587765957446808, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.007272598591256649, 0.0, 2.0260659075797873, 2.0260659075797873, 0.09628750415558511]
2025-12-20 10:53:47 Epoch: 2, loss: 4.0599, lr: 0.00009911
2025-12-20 10:53:54 train acc=0.44813829787234044, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00808293768700133, 0.0, 2.0201961436170213, 2.0201961436170213, 0.09616932970412234]
2025-12-20 10:53:54 Epoch: 3, loss: 4.0490, lr: 0.00009843
2025-12-20 10:54:00 train acc=0.4521276595744681, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008624218879862035, 0.0, 2.0184507978723403, 2.0184507978723403, 0.09698746052194149]
2025-12-20 10:54:00 Epoch: 4, loss: 4.0462, lr: 0.00009755
2025-12-20 10:54:06 train acc=0.4574468085106383, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.010831792303856383, 0.0, 2.0196766954787235, 2.0196766954787235, 0.09622257313829788]
2025-12-20 10:54:06 Epoch: 5, loss: 4.0507, lr: 0.00009649
2025-12-20 10:54:12 train acc=0.4507978723404255, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.011286958735039893, 0.0, 2.02788397606383, 2.02788397606383, 0.0973419838763298]
2025-12-20 10:54:12 Epoch: 6, loss: 4.0677, lr: 0.00009524
2025-12-20 10:54:18 train acc=0.4507978723404255, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012780372132646276, 0.0, 1.995595079787234, 1.995595079787234, 0.09592129321808511]
2025-12-20 10:54:18 Epoch: 7, loss: 4.0046, lr: 0.00009382
2025-12-20 10:54:25 train acc=0.4587765957446808, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01603179282330452, 0.0, 2.0151678856382977, 2.0151678856382977, 0.09684980676529255]
2025-12-20 10:54:25 Epoch: 8, loss: 4.0472, lr: 0.00009222
2025-12-20 10:54:31 train acc=0.4587765957446808, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.019763865369431515, 0.0, 1.9978910405585106, 1.9978910405585106, 0.09614335729720745]
2025-12-20 10:54:31 Epoch: 9, loss: 4.0160, lr: 0.00009045
2025-12-20 10:54:37 train acc=0.4720744680851064, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.020884412400265957, 0.0, 1.9945561835106382, 1.9945561835106382, 0.09590181391289894]
2025-12-20 10:54:37 Epoch: 10, loss: 4.0103, lr: 0.00008853
2025-12-20 10:54:43 train acc=0.47074468085106386, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0261266180809508, 0.0, 1.994389960106383, 1.994389960106383, 0.09493693899601063]
2025-12-20 10:54:43 Epoch: 11, loss: 4.0151, lr: 0.00008645
2025-12-20 10:54:50 train acc=0.4640957446808511, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03468355219414894, 0.0, 1.9906291555851063, 1.9906291555851063, 0.09552001953125]
2025-12-20 10:54:50 Epoch: 12, loss: 4.0163, lr: 0.00008423
2025-12-20 10:54:56 train acc=0.4734042553191489, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0432200330369016, 0.0, 1.9649060837765957, 1.9649060837765957, 0.09603946766954788]
2025-12-20 10:54:56 Epoch: 13, loss: 3.9737, lr: 0.00008187
2025-12-20 10:55:02 train acc=0.46675531914893614, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.052758399476396274, 0.0, 1.9579247007978724, 1.9579247007978724, 0.09621348279587766]
2025-12-20 10:55:02 Epoch: 14, loss: 3.9692, lr: 0.00007939
2025-12-20 10:55:08 train acc=0.4627659574468085, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0628447837017952, 0.0, 1.9532496675531914, 1.9532496675531914, 0.0975198948636968]
2025-12-20 10:55:08 Epoch: 15, loss: 3.9703, lr: 0.00007679
2025-12-20 10:55:14 train acc=0.46675531914893614, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07119296459441489, 0.0, 1.9461851728723405, 1.9461851728723405, 0.09897954413231383]
2025-12-20 10:55:14 Epoch: 16, loss: 3.9640, lr: 0.00007409
2025-12-20 10:55:21 train acc=0.4747340425531915, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08041576628989362, 0.0, 1.9204828789893618, 1.9204828789893618, 0.1001677817486702]
2025-12-20 10:55:21 Epoch: 17, loss: 3.9224, lr: 0.00007129
2025-12-20 10:55:27 train acc=0.4734042553191489, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08828800282579788, 0.0, 1.9169090757978724, 1.9169090757978724, 0.10161314619348404]
2025-12-20 10:55:27 Epoch: 18, loss: 3.9229, lr: 0.00006841
2025-12-20 10:55:33 train acc=0.4853723404255319, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09561352019614362, 0.0, 1.8984790558510638, 1.8984790558510638, 0.1042571372174202]
2025-12-20 10:55:33 Epoch: 19, loss: 3.8933, lr: 0.00006545
2025-12-20 10:55:40 train acc=0.4867021276595745, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10283255069813829, 0.0, 1.8649227061170213, 1.8649227061170213, 0.10638817320478723]
2025-12-20 10:55:40 Epoch: 20, loss: 3.8337, lr: 0.00006243
2025-12-20 10:55:46 train acc=0.48271276595744683, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.11227741647273937, 0.0, 1.8606632313829787, 1.8606632313829787, 0.10852440367353723]
2025-12-20 10:55:46 Epoch: 21, loss: 3.8348, lr: 0.00005937
2025-12-20 10:55:52 train acc=0.4734042553191489, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1179290122174202, 0.0, 1.8417553191489362, 1.8417553191489362, 0.11099827543218085]
2025-12-20 10:55:52 Epoch: 22, loss: 3.8029, lr: 0.00005627
2025-12-20 10:55:58 train acc=0.5053191489361702, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.12590903424202127, 0.0, 1.8014149767287233, 1.8014149767287233, 0.1138396567486702]
2025-12-20 10:55:58 Epoch: 23, loss: 3.7300, lr: 0.00005314
2025-12-20 10:56:05 train acc=0.5132978723404256, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.13379685422207446, 0.0, 1.7928233045212767, 1.7928233045212767, 0.11581485829454788]
2025-12-20 10:56:05 Epoch: 24, loss: 3.7208, lr: 0.00005000
2025-12-20 10:56:11 train acc=0.5, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.13816151720412234, 0.0, 1.7801072140957446, 1.7801072140957446, 0.11840171002327128]
2025-12-20 10:56:11 Epoch: 25, loss: 3.6992, lr: 0.00004686
2025-12-20 10:56:17 train acc=0.523936170212766, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1470973238031915, 0.0, 1.7581449468085106, 1.7581449468085106, 0.12255859375]
2025-12-20 10:56:17 Epoch: 26, loss: 3.6648, lr: 0.00004373
2025-12-20 10:56:23 train acc=0.5186170212765957, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.15220869348404256, 0.0, 1.7414394946808511, 1.7414394946808511, 0.1257038522273936]
2025-12-20 10:56:23 Epoch: 27, loss: 3.6366, lr: 0.00004063
2025-12-20 10:56:30 train acc=0.5199468085106383, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.15914592337101063, 0.0, 1.7373462433510638, 1.7373462433510638, 0.12898936170212766]
2025-12-20 10:56:30 Epoch: 28, loss: 3.6354, lr: 0.00003757
2025-12-20 10:56:36 train acc=0.5226063829787234, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.16352227393617022, 0.0, 1.7190616688829787, 1.7190616688829787, 0.13093988946143617]
2025-12-20 10:56:36 Epoch: 29, loss: 3.6033, lr: 0.00003455
2025-12-20 10:56:42 train acc=0.5252659574468085, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.16914530003324468, 0.0, 1.7145216921542554, 1.7145216921542554, 0.1336488115026596]
2025-12-20 10:56:42 Epoch: 30, loss: 3.5999, lr: 0.00003159
2025-12-20 10:56:48 train acc=0.5332446808510638, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.17377358294547873, 0.0, 1.7025951628989362, 1.7025951628989362, 0.13688497340425532]
2025-12-20 10:56:48 Epoch: 31, loss: 3.5804, lr: 0.00002871
2025-12-20 10:56:55 train acc=0.5305851063829787, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.17726687167553193, 0.0, 1.683843085106383, 1.683843085106383, 0.13933546999667554]
2025-12-20 10:56:55 Epoch: 32, loss: 3.5464, lr: 0.00002591
2025-12-20 10:57:01 train acc=0.523936170212766, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.17901221742021275, 0.0, 1.689453125, 1.689453125, 0.1397237574800532]
2025-12-20 10:57:01 Epoch: 33, loss: 3.5593, lr: 0.00002321
2025-12-20 10:57:07 train acc=0.5305851063829787, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.18431318567154256, 0.0, 1.6798225565159575, 1.6798225565159575, 0.14414166389627658]
2025-12-20 10:57:07 Epoch: 34, loss: 3.5454, lr: 0.00002061
2025-12-20 10:57:14 train acc=0.5332446808510638, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.18746883311170212, 0.0, 1.6750124667553192, 1.6750124667553192, 0.14527146359707446]
2025-12-20 10:57:14 Epoch: 35, loss: 3.5389, lr: 0.00001813
2025-12-20 10:57:20 train acc=0.5478723404255319, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.18992842004654256, 0.0, 1.6677817486702127, 1.6677817486702127, 0.14628828332779256]
2025-12-20 10:57:20 Epoch: 36, loss: 3.5268, lr: 0.00001577
2025-12-20 10:57:26 train acc=0.5465425531914894, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1895777925531915, 0.0, 1.6597199135638299, 1.6597199135638299, 0.14677916181848405]
2025-12-20 10:57:26 Epoch: 37, loss: 3.5104, lr: 0.00001355
2025-12-20 10:57:32 train acc=0.535904255319149, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19307108128324468, 0.0, 1.6670752992021276, 1.6670752992021276, 0.1483128324468085]
2025-12-20 10:57:32 Epoch: 38, loss: 3.5288, lr: 0.00001147
2025-12-20 10:57:38 train acc=0.5545212765957447, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19444242436835107, 0.0, 1.655242270611702, 1.655242270611702, 0.15019842918882978]
2025-12-20 10:57:38 Epoch: 39, loss: 3.5066, lr: 0.00000955
2025-12-20 10:57:45 train acc=0.5412234042553191, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19740068151595744, 0.0, 1.6580161236702127, 1.6580161236702127, 0.15180352393617022]
2025-12-20 10:57:45 Epoch: 40, loss: 3.5149, lr: 0.00000778
2025-12-20 10:57:51 train acc=0.5545212765957447, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19647606382978725, 0.0, 1.6370719747340425, 1.6370719747340425, 0.15191780252659576]
2025-12-20 10:57:51 Epoch: 41, loss: 3.4723, lr: 0.00000618
2025-12-20 10:57:57 train acc=0.5625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19945250166223405, 0.0, 1.6355447972074468, 1.6355447972074468, 0.15345017453457446]
2025-12-20 10:57:57 Epoch: 42, loss: 3.4721, lr: 0.00000476
2025-12-20 10:58:03 train acc=0.5438829787234043, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1983902302194149, 0.0, 1.6513048537234043, 1.6513048537234043, 0.15255152925531915]
2025-12-20 10:58:03 Epoch: 43, loss: 3.5025, lr: 0.00000351
2025-12-20 10:58:10 train acc=0.5478723404255319, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19942133477393617, 0.0, 1.6475856050531914, 1.6475856050531914, 0.15424493018617022]
2025-12-20 10:58:10 Epoch: 44, loss: 3.4961, lr: 0.00000245
2025-12-20 10:58:16 train acc=0.5558510638297872, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19894084524601063, 0.0, 1.6236702127659575, 1.6236702127659575, 0.1528463160738032]
2025-12-20 10:58:16 Epoch: 45, loss: 3.4476, lr: 0.00000157
2025-12-20 10:58:22 train acc=0.5478723404255319, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19911226313164893, 0.0, 1.6452065325797873, 1.6452065325797873, 0.15303981050531915]
2025-12-20 10:58:22 Epoch: 46, loss: 3.4910, lr: 0.00000089
2025-12-20 10:58:28 train acc=0.5585106382978723, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19916680518617022, 0.0, 1.640105551861702, 1.640105551861702, 0.15350471658909576]
2025-12-20 10:58:28 Epoch: 47, loss: 3.4808, lr: 0.00000039
2025-12-20 10:58:34 train acc=0.5545212765957447, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19976157330452127, 0.0, 1.6359499667553192, 1.6359499667553192, 0.15369691240026595]
2025-12-20 10:58:34 Epoch: 48, loss: 3.4732, lr: 0.00000010
2025-12-20 10:58:41 train acc=0.550531914893617, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19954080784574468, 0.0, 1.624522107712766, 1.624522107712766, 0.1538878095910904]
2025-12-20 10:58:41 Epoch: 49, loss: 3.4502, lr: 0.00000000
2025-12-20 10:59:10 {'name': 'dtd', 'acc': [{'clip_logits': 44.50354609929078, 'cma_logits': 46.04018912529551, 'GLR_logits': 51.30023640661938, 'final_logits': 46.04018912529551, 'acc': 52.12765957446809}], 'detail': 'dataset_name=dtd, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=47, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 10:59:10 Preparing ViT-B/16 model.
2025-12-20 10:59:13 Getting cached textual weights W ...
2025-12-20 10:59:13 Initializing CMA adapter learner...
2025-12-20 10:59:13 Initializing SKD distillation...
2025-12-20 10:59:13 Preparing eurosat dataset.
2025-12-20 10:59:15 train acc=0.41875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0, 0.0, 1.47392578125, 1.47392578125, 0.08644561767578125]
2025-12-20 10:59:15 Epoch: 0, loss: 2.9485, lr: 0.00009990
2025-12-20 10:59:17 train acc=0.41875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0, 0.0, 1.51748046875, 1.51748046875, 0.08458251953125]
2025-12-20 10:59:17 Epoch: 1, loss: 3.0355, lr: 0.00009961
2025-12-20 10:59:18 train acc=0.40625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003486156463623047, 0.0, 1.5181640625, 1.5181640625, 0.086090087890625]
2025-12-20 10:59:18 Epoch: 2, loss: 3.0402, lr: 0.00009911
2025-12-20 10:59:20 train acc=0.45, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008320236206054687, 0.0, 1.46337890625, 1.46337890625, 0.084326171875]
2025-12-20 10:59:20 Epoch: 3, loss: 2.9356, lr: 0.00009843
2025-12-20 10:59:21 train acc=0.4375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01095733642578125, 0.0, 1.5314453125, 1.5314453125, 0.085504150390625]
2025-12-20 10:59:21 Epoch: 4, loss: 3.0740, lr: 0.00009755
2025-12-20 10:59:22 train acc=0.4625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0119049072265625, 0.0, 1.4609375, 1.4609375, 0.083123779296875]
2025-12-20 10:59:22 Epoch: 5, loss: 2.9346, lr: 0.00009649
2025-12-20 10:59:24 train acc=0.4375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.011084747314453126, 0.0, 1.47978515625, 1.47978515625, 0.082666015625]
2025-12-20 10:59:24 Epoch: 6, loss: 2.9709, lr: 0.00009524
2025-12-20 10:59:26 train acc=0.38125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012734222412109374, 0.0, 1.5404296875, 1.5404296875, 0.087103271484375]
2025-12-20 10:59:26 Epoch: 7, loss: 3.0939, lr: 0.00009382
2025-12-20 10:59:27 train acc=0.43125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.013866424560546875, 0.0, 1.493115234375, 1.493115234375, 0.082464599609375]
2025-12-20 10:59:27 Epoch: 8, loss: 3.0008, lr: 0.00009222
2025-12-20 10:59:28 train acc=0.4375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012960052490234375, 0.0, 1.49951171875, 1.49951171875, 0.08277587890625]
2025-12-20 10:59:28 Epoch: 9, loss: 3.0123, lr: 0.00009045
2025-12-20 10:59:30 train acc=0.4125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01243133544921875, 0.0, 1.48359375, 1.48359375, 0.0831451416015625]
2025-12-20 10:59:30 Epoch: 10, loss: 2.9797, lr: 0.00008853
2025-12-20 10:59:31 train acc=0.45625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.015546417236328125, 0.0, 1.447265625, 1.447265625, 0.08299560546875]
2025-12-20 10:59:31 Epoch: 11, loss: 2.9109, lr: 0.00008645
2025-12-20 10:59:33 train acc=0.4125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.016007232666015624, 0.0, 1.46796875, 1.46796875, 0.0838287353515625]
2025-12-20 10:59:33 Epoch: 12, loss: 2.9529, lr: 0.00008423
2025-12-20 10:59:34 train acc=0.425, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.013866424560546875, 0.0, 1.493701171875, 1.493701171875, 0.0835845947265625]
2025-12-20 10:59:34 Epoch: 13, loss: 3.0014, lr: 0.00008187
2025-12-20 10:59:36 train acc=0.44375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.018585205078125, 0.0, 1.4703125, 1.4703125, 0.08167724609375]
2025-12-20 10:59:36 Epoch: 14, loss: 2.9595, lr: 0.00007939
2025-12-20 10:59:37 train acc=0.44375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01797637939453125, 0.0, 1.480078125, 1.480078125, 0.08594970703125]
2025-12-20 10:59:37 Epoch: 15, loss: 2.9789, lr: 0.00007679
2025-12-20 10:59:38 train acc=0.41875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0183685302734375, 0.0, 1.53291015625, 1.53291015625, 0.082159423828125]
2025-12-20 10:59:38 Epoch: 16, loss: 3.0850, lr: 0.00007409
2025-12-20 10:59:40 train acc=0.43125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0201080322265625, 0.0, 1.4607421875, 1.4607421875, 0.0809906005859375]
2025-12-20 10:59:40 Epoch: 17, loss: 2.9416, lr: 0.00007129
2025-12-20 10:59:41 train acc=0.425, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02055511474609375, 0.0, 1.4703125, 1.4703125, 0.0823760986328125]
2025-12-20 10:59:41 Epoch: 18, loss: 2.9617, lr: 0.00006841
2025-12-20 10:59:43 train acc=0.4375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0208984375, 0.0, 1.4716796875, 1.4716796875, 0.081097412109375]
2025-12-20 10:59:43 Epoch: 19, loss: 2.9645, lr: 0.00006545
2025-12-20 10:59:44 train acc=0.475, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02217864990234375, 0.0, 1.450390625, 1.450390625, 0.08509521484375]
2025-12-20 10:59:44 Epoch: 20, loss: 2.9232, lr: 0.00006243
2025-12-20 10:59:46 train acc=0.45, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0248626708984375, 0.0, 1.4560546875, 1.4560546875, 0.08350830078125]
2025-12-20 10:59:46 Epoch: 21, loss: 2.9377, lr: 0.00005937
2025-12-20 10:59:47 train acc=0.4375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0240234375, 0.0, 1.456298828125, 1.456298828125, 0.085101318359375]
2025-12-20 10:59:47 Epoch: 22, loss: 2.9368, lr: 0.00005627
2025-12-20 10:59:49 train acc=0.4, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02422027587890625, 0.0, 1.5, 1.5, 0.07877197265625]
2025-12-20 10:59:49 Epoch: 23, loss: 3.0242, lr: 0.00005314
2025-12-20 10:59:50 train acc=0.45625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.026385498046875, 0.0, 1.44248046875, 1.44248046875, 0.080682373046875]
2025-12-20 10:59:50 Epoch: 24, loss: 2.9121, lr: 0.00005000
2025-12-20 10:59:52 train acc=0.44375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02638702392578125, 0.0, 1.4416015625, 1.4416015625, 0.08516845703125]
2025-12-20 10:59:52 Epoch: 25, loss: 2.9104, lr: 0.00004686
2025-12-20 10:59:53 train acc=0.45, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.027032470703125, 0.0, 1.4646484375, 1.4646484375, 0.08416748046875]
2025-12-20 10:59:53 Epoch: 26, loss: 2.9564, lr: 0.00004373
2025-12-20 10:59:55 train acc=0.43125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02781219482421875, 0.0, 1.47333984375, 1.47333984375, 0.081402587890625]
2025-12-20 10:59:55 Epoch: 27, loss: 2.9748, lr: 0.00004063
2025-12-20 10:59:56 train acc=0.425, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02961883544921875, 0.0, 1.48349609375, 1.48349609375, 0.08172607421875]
2025-12-20 10:59:56 Epoch: 28, loss: 2.9975, lr: 0.00003757
2025-12-20 10:59:57 train acc=0.45625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.031982421875, 0.0, 1.43857421875, 1.43857421875, 0.08232421875]
2025-12-20 10:59:57 Epoch: 29, loss: 2.9092, lr: 0.00003455
2025-12-20 10:59:59 train acc=0.44375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03052978515625, 0.0, 1.4744140625, 1.4744140625, 0.080792236328125]
2025-12-20 10:59:59 Epoch: 30, loss: 2.9799, lr: 0.00003159
2025-12-20 11:00:00 train acc=0.425, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03312530517578125, 0.0, 1.49580078125, 1.49580078125, 0.081695556640625]
2025-12-20 11:00:00 Epoch: 31, loss: 3.0255, lr: 0.00002871
2025-12-20 11:00:02 train acc=0.46875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03328094482421875, 0.0, 1.4697265625, 1.4697265625, 0.083154296875]
2025-12-20 11:00:02 Epoch: 32, loss: 2.9730, lr: 0.00002591
2025-12-20 11:00:03 train acc=0.4625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.035186767578125, 0.0, 1.47900390625, 1.47900390625, 0.080615234375]
2025-12-20 11:00:03 Epoch: 33, loss: 2.9939, lr: 0.00002321
2025-12-20 11:00:05 train acc=0.44375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0355621337890625, 0.0, 1.439453125, 1.439453125, 0.0821868896484375]
2025-12-20 11:00:05 Epoch: 34, loss: 2.9148, lr: 0.00002061
2025-12-20 11:00:06 train acc=0.41875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0344635009765625, 0.0, 1.4814453125, 1.4814453125, 0.083447265625]
2025-12-20 11:00:06 Epoch: 35, loss: 2.9980, lr: 0.00001813
2025-12-20 11:00:07 train acc=0.45625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03635406494140625, 0.0, 1.4341796875, 1.4341796875, 0.07921142578125]
2025-12-20 11:00:07 Epoch: 36, loss: 2.9051, lr: 0.00001577
2025-12-20 11:00:09 train acc=0.475, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03569183349609375, 0.0, 1.46376953125, 1.46376953125, 0.0815155029296875]
2025-12-20 11:00:09 Epoch: 37, loss: 2.9633, lr: 0.00001355
2025-12-20 11:00:10 train acc=0.4625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03570098876953125, 0.0, 1.43232421875, 1.43232421875, 0.080987548828125]
2025-12-20 11:00:10 Epoch: 38, loss: 2.9006, lr: 0.00001147
2025-12-20 11:00:12 train acc=0.4625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0390228271484375, 0.0, 1.4748046875, 1.4748046875, 0.08524169921875]
2025-12-20 11:00:12 Epoch: 39, loss: 2.9891, lr: 0.00000955
2025-12-20 11:00:13 train acc=0.45, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0378143310546875, 0.0, 1.47490234375, 1.47490234375, 0.080841064453125]
2025-12-20 11:00:13 Epoch: 40, loss: 2.9877, lr: 0.00000778
2025-12-20 11:00:15 train acc=0.44375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0357086181640625, 0.0, 1.4548828125, 1.4548828125, 0.0863555908203125]
2025-12-20 11:00:15 Epoch: 41, loss: 2.9459, lr: 0.00000618
2025-12-20 11:00:16 train acc=0.45625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.038006591796875, 0.0, 1.5015625, 1.5015625, 0.0812652587890625]
2025-12-20 11:00:16 Epoch: 42, loss: 3.0418, lr: 0.00000476
2025-12-20 11:00:17 train acc=0.425, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0382415771484375, 0.0, 1.439453125, 1.439453125, 0.084466552734375]
2025-12-20 11:00:17 Epoch: 43, loss: 2.9180, lr: 0.00000351
2025-12-20 11:00:19 train acc=0.425, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.038104248046875, 0.0, 1.4779296875, 1.4779296875, 0.079461669921875]
2025-12-20 11:00:19 Epoch: 44, loss: 2.9943, lr: 0.00000245
2025-12-20 11:00:20 train acc=0.4625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0386749267578125, 0.0, 1.4302734375, 1.4302734375, 0.0836212158203125]
2025-12-20 11:00:20 Epoch: 45, loss: 2.8994, lr: 0.00000157
2025-12-20 11:00:22 train acc=0.4375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0382232666015625, 0.0, 1.45400390625, 1.45400390625, 0.0833770751953125]
2025-12-20 11:00:22 Epoch: 46, loss: 2.9473, lr: 0.00000089
2025-12-20 11:00:23 train acc=0.39375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0396392822265625, 0.0, 1.49873046875, 1.49873046875, 0.081475830078125]
2025-12-20 11:00:23 Epoch: 47, loss: 3.0381, lr: 0.00000039
2025-12-20 11:00:25 train acc=0.43125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0384765625, 0.0, 1.4208984375, 1.4208984375, 0.0826171875]
2025-12-20 11:00:25 Epoch: 48, loss: 2.8811, lr: 0.00000010
2025-12-20 11:00:27 train acc=0.45, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.038568115234375, 0.0, 1.45009765625, 1.45009765625, 0.0812255859375]
2025-12-20 11:00:27 Epoch: 49, loss: 2.9387, lr: 0.00000000
2025-12-20 11:01:16 {'name': 'eurosat', 'acc': [{'clip_logits': 47.67901234567901, 'cma_logits': 42.65432098765432, 'GLR_logits': 49.333333333333336, 'final_logits': 49.32098765432099, 'acc': 49.22222222222222}], 'detail': 'dataset_name=eurosat, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=10, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 11:01:16 Preparing ViT-B/16 model.
2025-12-20 11:01:19 Getting cached textual weights W ...
2025-12-20 11:01:20 Initializing CMA adapter learner...
2025-12-20 11:01:20 Initializing SKD distillation...
2025-12-20 11:01:20 Preparing oxford_flowers dataset.
2025-12-20 11:01:36 train acc=0.6887254901960784, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0027271807193756104, 0.0, 1.3728673598345589, 1.3728673598345589, 0.65283203125]
2025-12-20 11:01:36 Epoch: 0, loss: 2.7549, lr: 0.00009990
2025-12-20 11:01:52 train acc=0.6850490196078431, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.009801528033088236, 0.0, 1.3646886488970589, 1.3646886488970589, 0.6483226102941176]
2025-12-20 11:01:52 Epoch: 1, loss: 2.7458, lr: 0.00009961
2025-12-20 11:02:07 train acc=0.7028186274509803, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.015483856201171875, 0.0, 1.3529507506127452, 1.3529507506127452, 0.6483369715073529]
2025-12-20 11:02:07 Epoch: 2, loss: 2.7279, lr: 0.00009911
2025-12-20 11:02:23 train acc=0.6948529411764706, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02410739075903799, 0.0, 1.3376584520526962, 1.3376584520526962, 0.6445886948529411]
2025-12-20 11:02:23 Epoch: 3, loss: 2.7059, lr: 0.00009843
2025-12-20 11:02:38 train acc=0.6985294117647058, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03927163516773897, 0.0, 1.2979736328125, 1.2979736328125, 0.6434900620404411]
2025-12-20 11:02:38 Epoch: 4, loss: 2.6418, lr: 0.00009755
2025-12-20 11:02:54 train acc=0.7071078431372549, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05836067947686887, 0.0, 1.2474389169730393, 1.2474389169730393, 0.6423962162990197]
2025-12-20 11:02:54 Epoch: 5, loss: 2.5597, lr: 0.00009649
2025-12-20 11:03:09 train acc=0.7242647058823529, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07993032418045343, 0.0, 1.2035079656862746, 1.2035079656862746, 0.648715150122549]
2025-12-20 11:03:09 Epoch: 6, loss: 2.4934, lr: 0.00009524
2025-12-20 11:03:25 train acc=0.7389705882352942, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10420915192248774, 0.0, 1.1340403837316178, 1.1340403837316178, 0.6564319087009803]
2025-12-20 11:03:25 Epoch: 7, loss: 2.3789, lr: 0.00009382
2025-12-20 11:03:41 train acc=0.7463235294117647, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.12577490713082107, 0.0, 1.0662937538296569, 1.0662937538296569, 0.6675905713848039]
2025-12-20 11:03:41 Epoch: 8, loss: 2.2650, lr: 0.00009222
2025-12-20 11:03:56 train acc=0.7708333333333334, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.14808924057904413, 0.0, 0.9813735064338235, 0.9813735064338235, 0.6877154181985294]
2025-12-20 11:03:56 Epoch: 9, loss: 2.1178, lr: 0.00009045
2025-12-20 11:04:12 train acc=0.7806372549019608, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.17081227022058823, 0.0, 0.9274351830575981, 0.9274351830575981, 0.7084577971813726]
2025-12-20 11:04:12 Epoch: 10, loss: 2.0327, lr: 0.00008853
2025-12-20 11:04:27 train acc=0.8088235294117647, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1905194450827206, 0.0, 0.8487728343290442, 0.8487728343290442, 0.7327713311887255]
2025-12-20 11:04:27 Epoch: 11, loss: 1.8954, lr: 0.00008645
2025-12-20 11:04:43 train acc=0.8198529411764706, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20907293581495098, 0.0, 0.7939836090686274, 0.7939836090686274, 0.7567641314338235]
2025-12-20 11:04:43 Epoch: 12, loss: 1.8047, lr: 0.00008423
2025-12-20 11:04:59 train acc=0.8388480392156863, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2249157475490196, 0.0, 0.7241246840533089, 0.7241246840533089, 0.7856205958946079]
2025-12-20 11:04:59 Epoch: 13, loss: 1.6811, lr: 0.00008187
2025-12-20 11:05:14 train acc=0.8596813725490197, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.23911180683210784, 0.0, 0.6536518171721813, 0.6536518171721813, 0.818325865502451]
2025-12-20 11:05:14 Epoch: 14, loss: 1.5546, lr: 0.00007939
2025-12-20 11:05:30 train acc=0.8780637254901961, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.24992340686274508, 0.0, 0.5992994121476716, 0.5992994121476716, 0.8500449984681373]
2025-12-20 11:05:30 Epoch: 15, loss: 1.4570, lr: 0.00007679
2025-12-20 11:05:46 train acc=0.8909313725490197, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.25722488702512253, 0.0, 0.5468546549479166, 0.5468546549479166, 0.8790019914215687]
2025-12-20 11:05:46 Epoch: 16, loss: 1.3596, lr: 0.00007409
2025-12-20 11:06:01 train acc=0.897671568627451, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.26303519454656865, 0.0, 0.506442200903799, 0.506442200903799, 0.9089403339460784]
2025-12-20 11:06:01 Epoch: 17, loss: 1.2850, lr: 0.00007129
2025-12-20 11:06:17 train acc=0.9093137254901961, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27051618987438725, 0.0, 0.47105856502757354, 0.47105856502757354, 0.9411860447303921]
2025-12-20 11:06:17 Epoch: 18, loss: 1.2221, lr: 0.00006841
2025-12-20 11:06:32 train acc=0.9191176470588235, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2733633003982843, 0.0, 0.43188297047334556, 0.43188297047334556, 0.9700377221200981]
2025-12-20 11:06:32 Epoch: 19, loss: 1.1468, lr: 0.00006545
2025-12-20 11:06:48 train acc=0.9264705882352942, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27735332414215685, 0.0, 0.40182674632352944, 0.40182674632352944, 0.9964479932598039]
2025-12-20 11:06:48 Epoch: 20, loss: 1.0910, lr: 0.00006243
2025-12-20 11:07:04 train acc=0.9405637254901961, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27883611940870096, 0.0, 0.3669116450291054, 0.3669116450291054, 1.0223987055759804]
2025-12-20 11:07:04 Epoch: 21, loss: 1.0229, lr: 0.00005937
2025-12-20 11:07:19 train acc=0.9405637254901961, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2800508386948529, 0.0, 0.3547375248927696, 0.3547375248927696, 1.0495222503063726]
2025-12-20 11:07:19 Epoch: 22, loss: 1.0001, lr: 0.00005627
2025-12-20 11:07:35 train acc=0.9473039215686274, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2812535903033088, 0.0, 0.3275601256127451, 0.3275601256127451, 1.0778617110906863]
2025-12-20 11:07:35 Epoch: 23, loss: 0.9471, lr: 0.00005314
2025-12-20 11:07:50 train acc=0.9515931372549019, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2821523628982843, 0.0, 0.312225341796875, 0.312225341796875, 1.1009449678308822]
2025-12-20 11:07:50 Epoch: 24, loss: 0.9176, lr: 0.00005000
2025-12-20 11:08:06 train acc=0.9558823529411765, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.28282614315257354, 0.0, 0.29677357393152576, 0.29677357393152576, 1.1232000612745099]
2025-12-20 11:08:06 Epoch: 25, loss: 0.8876, lr: 0.00004686
2025-12-20 11:08:21 train acc=0.9662990196078431, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.28006519990808826, 0.0, 0.28076710420496326, 0.28076710420496326, 1.1445264629289216]
2025-12-20 11:08:21 Epoch: 26, loss: 0.8530, lr: 0.00004373
2025-12-20 11:08:37 train acc=0.9571078431372549, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.28209850834865197, 0.0, 0.27422138288909315, 0.27422138288909315, 1.1670400582107843]
2025-12-20 11:08:37 Epoch: 27, loss: 0.8422, lr: 0.00004063
2025-12-20 11:08:52 train acc=0.9632352941176471, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.28081437653186275, 0.0, 0.26037777171415444, 0.26037777171415444, 1.1850011488970589]
2025-12-20 11:08:52 Epoch: 28, loss: 0.8134, lr: 0.00003757
2025-12-20 11:09:08 train acc=0.9699754901960784, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27933277803308826, 0.0, 0.24529371074601716, 0.24529371074601716, 1.1969784007352942]
2025-12-20 11:09:08 Epoch: 29, loss: 0.7819, lr: 0.00003455
2025-12-20 11:09:23 train acc=0.9675245098039216, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27914009842218135, 0.0, 0.24315508674172795, 0.24315508674172795, 1.2129432827818627]
2025-12-20 11:09:23 Epoch: 30, loss: 0.7776, lr: 0.00003159
2025-12-20 11:09:39 train acc=0.9761029411764706, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2777530445772059, 0.0, 0.22956040326286764, 0.22956040326286764, 1.2255045572916667]
2025-12-20 11:09:39 Epoch: 31, loss: 0.7492, lr: 0.00002871
2025-12-20 11:09:55 train acc=0.96875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27662209903492646, 0.0, 0.23163739372702205, 0.23163739372702205, 1.2400476792279411]
2025-12-20 11:09:55 Epoch: 32, loss: 0.7523, lr: 0.00002591
2025-12-20 11:10:10 train acc=0.9754901960784313, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27547798904718135, 0.0, 0.22389729817708334, 0.22389729817708334, 1.248568665747549]
2025-12-20 11:10:10 Epoch: 33, loss: 0.7358, lr: 0.00002321
2025-12-20 11:10:26 train acc=0.9779411764705882, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27529608034620096, 0.0, 0.21486529181985295, 0.21486529181985295, 1.2605171951593137]
2025-12-20 11:10:26 Epoch: 34, loss: 0.7176, lr: 0.00002061
2025-12-20 11:10:41 train acc=0.9742647058823529, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27469649969362747, 0.0, 0.20860679476868874, 0.20860679476868874, 1.2757448682598038]
2025-12-20 11:10:41 Epoch: 35, loss: 0.7047, lr: 0.00001813
2025-12-20 11:10:57 train acc=0.9767156862745098, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27400955499387253, 0.0, 0.21318562825520834, 0.21318562825520834, 1.2751369102328431]
2025-12-20 11:10:57 Epoch: 36, loss: 0.7131, lr: 0.00001577
2025-12-20 11:11:12 train acc=0.9754901960784313, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2757580327052696, 0.0, 0.2098406623391544, 0.2098406623391544, 1.2855870863970589]
2025-12-20 11:11:12 Epoch: 37, loss: 0.7083, lr: 0.00001355
2025-12-20 11:11:28 train acc=0.9803921568627451, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27369121476715685, 0.0, 0.20032456341911764, 0.20032456341911764, 1.2954197303921569]
2025-12-20 11:11:28 Epoch: 38, loss: 0.6873, lr: 0.00001147
2025-12-20 11:11:44 train acc=0.9767156862745098, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2728080001531863, 0.0, 0.20130531460631126, 0.20130531460631126, 1.2976122089460784]
2025-12-20 11:11:44 Epoch: 39, loss: 0.6884, lr: 0.00000955
2025-12-20 11:11:59 train acc=0.9761029411764706, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2731897690716912, 0.0, 0.20248622520297183, 0.20248622520297183, 1.299460018382353]
2025-12-20 11:11:59 Epoch: 40, loss: 0.6912, lr: 0.00000778
2025-12-20 11:12:15 train acc=0.9810049019607843, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27200975605085786, 0.0, 0.19883279239430146, 0.19883279239430146, 1.300747740502451]
2025-12-20 11:12:15 Epoch: 41, loss: 0.6827, lr: 0.00000618
2025-12-20 11:12:30 train acc=0.9761029411764706, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27283552581188725, 0.0, 0.2018743776807598, 0.2018743776807598, 1.3039694393382353]
2025-12-20 11:12:30 Epoch: 42, loss: 0.6896, lr: 0.00000476
2025-12-20 11:12:46 train acc=0.9803921568627451, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2720528396905637, 0.0, 0.20203414617800244, 0.20203414617800244, 1.3071384803921569]
2025-12-20 11:12:46 Epoch: 43, loss: 0.6892, lr: 0.00000351
2025-12-20 11:13:01 train acc=0.9779411764705882, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27267994600183826, 0.0, 0.19743377087162992, 0.19743377087162992, 1.312078737745098]
2025-12-20 11:13:01 Epoch: 44, loss: 0.6807, lr: 0.00000245
2025-12-20 11:13:17 train acc=0.9779411764705882, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27328670726102944, 0.0, 0.19783438888250612, 0.19783438888250612, 1.3176173789828431]
2025-12-20 11:13:17 Epoch: 45, loss: 0.6821, lr: 0.00000157
2025-12-20 11:13:33 train acc=0.977328431372549, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2726296817555147, 0.0, 0.19157140395220587, 0.19157140395220587, 1.3128686044730393]
2025-12-20 11:13:33 Epoch: 46, loss: 0.6689, lr: 0.00000089
2025-12-20 11:13:48 train acc=0.9791666666666666, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27259018841911764, 0.0, 0.1943060183057598, 0.1943060183057598, 1.3120978860294117]
2025-12-20 11:13:48 Epoch: 47, loss: 0.6743, lr: 0.00000039
2025-12-20 11:14:04 train acc=0.9797794117647058, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27260933670343135, 0.0, 0.19203395469515933, 0.19203395469515933, 1.3166886871936274]
2025-12-20 11:14:04 Epoch: 48, loss: 0.6698, lr: 0.00000010
2025-12-20 11:14:19 train acc=0.9791666666666666, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2724561504289216, 0.0, 0.1985338996438419, 0.1985338996438419, 1.3142185585171569]
2025-12-20 11:14:19 Epoch: 49, loss: 0.6827, lr: 0.00000000
2025-12-20 11:14:49 {'name': 'oxford_flowers', 'acc': [{'clip_logits': 71.33576938692651, 'cma_logits': 64.67722289890378, 'GLR_logits': 95.41209906617945, 'final_logits': 69.30572472594397, 'acc': 95.41209906617945}], 'detail': 'dataset_name=oxford_flowers, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=102, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 11:14:49 Preparing ViT-B/16 model.
2025-12-20 11:14:52 Getting cached textual weights W ...
2025-12-20 11:14:53 Initializing CMA adapter learner...
2025-12-20 11:14:53 Initializing SKD distillation...
2025-12-20 11:14:53 Preparing food101 dataset.
2025-12-20 11:15:13 train acc=0.864480198019802, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00045896461694547444, 0.0, 0.4794921875, 0.4794921875, 0.5941004989170792]
2025-12-20 11:15:13 Epoch: 0, loss: 0.9654, lr: 0.00009990
2025-12-20 11:15:28 train acc=0.869430693069307, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.002516477414877108, 0.0, 0.4644304030012376, 0.4644304030012376, 0.5887487430383663]
2025-12-20 11:15:28 Epoch: 1, loss: 0.9372, lr: 0.00009961
2025-12-20 11:15:44 train acc=0.8743811881188119, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003094267136979811, 0.0, 0.4668959815903465, 0.4668959815903465, 0.5891282487623762]
2025-12-20 11:15:44 Epoch: 2, loss: 0.9428, lr: 0.00009911
2025-12-20 11:15:59 train acc=0.8675742574257426, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0033405417262917696, 0.0, 0.4718283473855198, 0.4718283473855198, 0.5885094368811881]
2025-12-20 11:15:59 Epoch: 3, loss: 0.9529, lr: 0.00009843
2025-12-20 11:16:14 train acc=0.8650990099009901, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003623424190105778, 0.0, 0.47153435131110766, 0.47153435131110766, 0.5908299814356436]
2025-12-20 11:16:14 Epoch: 4, loss: 0.9526, lr: 0.00009755
2025-12-20 11:16:29 train acc=0.8650990099009901, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0038209103121615872, 0.0, 0.47574305770420794, 0.47574305770420794, 0.5903078589108911]
2025-12-20 11:16:29 Epoch: 5, loss: 0.9612, lr: 0.00009649
2025-12-20 11:16:45 train acc=0.869430693069307, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.003575882109084932, 0.0, 0.46873791383044555, 0.46873791383044555, 0.5887608292079208]
2025-12-20 11:16:45 Epoch: 6, loss: 0.9470, lr: 0.00009524
2025-12-20 11:17:00 train acc=0.8650990099009901, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004324676966903233, 0.0, 0.4753575088954208, 0.4753575088954208, 0.5924301902846535]
2025-12-20 11:17:00 Epoch: 7, loss: 0.9610, lr: 0.00009382
2025-12-20 11:17:15 train acc=0.8719059405940595, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.005431241328173344, 0.0, 0.473377794322401, 0.473377794322401, 0.5901676593440595]
2025-12-20 11:17:15 Epoch: 8, loss: 0.9581, lr: 0.00009222
2025-12-20 11:17:31 train acc=0.8638613861386139, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.007478355181099164, 0.0, 0.4730218566290223, 0.4730218566290223, 0.5867472733601485]
2025-12-20 11:17:31 Epoch: 9, loss: 0.9593, lr: 0.00009045
2025-12-20 11:17:46 train acc=0.8688118811881188, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.010185317237778465, 0.0, 0.4612677545830755, 0.4612677545830755, 0.5886617226175742]
2025-12-20 11:17:46 Epoch: 10, loss: 0.9387, lr: 0.00008853
2025-12-20 11:18:01 train acc=0.8688118811881188, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01253637937035891, 0.0, 0.4581165880259901, 0.4581165880259901, 0.5885166885829208]
2025-12-20 11:18:01 Epoch: 11, loss: 0.9346, lr: 0.00008645
2025-12-20 11:18:16 train acc=0.8743811881188119, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.015162628475982364, 0.0, 0.4554594436494431, 0.4554594436494431, 0.5861187925433168]
2025-12-20 11:18:16 Epoch: 12, loss: 0.9320, lr: 0.00008423
2025-12-20 11:18:32 train acc=0.8743811881188119, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.017191518651376858, 0.0, 0.4599068518912438, 0.4599068518912438, 0.5905616684715347]
2025-12-20 11:18:32 Epoch: 13, loss: 0.9429, lr: 0.00008187
2025-12-20 11:18:47 train acc=0.8756188118811881, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.019380172880569306, 0.0, 0.4446181495590965, 0.4446181495590965, 0.5868439627165841]
2025-12-20 11:18:47 Epoch: 14, loss: 0.9145, lr: 0.00007939
2025-12-20 11:19:02 train acc=0.8756188118811881, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.022034748946086015, 0.0, 0.44226678527227725, 0.44226678527227725, 0.5937572517017327]
2025-12-20 11:19:02 Epoch: 15, loss: 0.9125, lr: 0.00007679
2025-12-20 11:19:18 train acc=0.8731435643564357, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02377092720258354, 0.0, 0.4487721660349629, 0.4487721660349629, 0.5902063350866337]
2025-12-20 11:19:18 Epoch: 16, loss: 0.9272, lr: 0.00007409
2025-12-20 11:19:33 train acc=0.8830445544554455, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.026073795734065593, 0.0, 0.4421809734684406, 0.4421809734684406, 0.5924277730507426]
2025-12-20 11:19:33 Epoch: 17, loss: 0.9163, lr: 0.00007129
2025-12-20 11:19:48 train acc=0.8793316831683168, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02733226813892327, 0.0, 0.43493048035272275, 0.43493048035272275, 0.5911563080136139]
2025-12-20 11:19:48 Epoch: 18, loss: 0.9031, lr: 0.00006841
2025-12-20 11:20:04 train acc=0.8756188118811881, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.029066180238629332, 0.0, 0.44117419554455445, 0.44117419554455445, 0.5926985032487624]
2025-12-20 11:20:04 Epoch: 19, loss: 0.9173, lr: 0.00006545
2025-12-20 11:20:19 train acc=0.8787128712871287, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.031078074238087873, 0.0, 0.43570308874149133, 0.43570308874149133, 0.5975958191522277]
2025-12-20 11:20:19 Epoch: 20, loss: 0.9085, lr: 0.00006243
2025-12-20 11:20:34 train acc=0.8867574257425742, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03235754636254641, 0.0, 0.4208624811455755, 0.4208624811455755, 0.5959738551980198]
2025-12-20 11:20:34 Epoch: 21, loss: 0.8800, lr: 0.00005937
2025-12-20 11:20:49 train acc=0.8824257425742574, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03443213736656869, 0.0, 0.43836385896890473, 0.43836385896890473, 0.5955363358601485]
2025-12-20 11:20:49 Epoch: 22, loss: 0.9171, lr: 0.00005627
2025-12-20 11:21:05 train acc=0.8842821782178217, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.035744242148824254, 0.0, 0.4208325678759282, 0.4208325678759282, 0.5984950301670792]
2025-12-20 11:21:05 Epoch: 23, loss: 0.8834, lr: 0.00005314
2025-12-20 11:21:20 train acc=0.8836633663366337, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03750096689356436, 0.0, 0.42839307124071785, 0.42839307124071785, 0.6006028581373762]
2025-12-20 11:21:20 Epoch: 24, loss: 0.9004, lr: 0.00005000
2025-12-20 11:21:35 train acc=0.8886138613861386, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03793878838567451, 0.0, 0.423869520130724, 0.423869520130724, 0.602804958230198]
2025-12-20 11:21:35 Epoch: 25, loss: 0.8918, lr: 0.00004686
2025-12-20 11:21:51 train acc=0.8948019801980198, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04037687093904703, 0.0, 0.4265843759668936, 0.4265843759668936, 0.6007962368502475]
2025-12-20 11:21:51 Epoch: 26, loss: 0.8996, lr: 0.00004373
2025-12-20 11:22:06 train acc=0.8849009900990099, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04052492651608911, 0.0, 0.4148834530669864, 0.4148834530669864, 0.6059014348700495]
2025-12-20 11:22:06 Epoch: 27, loss: 0.8763, lr: 0.00004063
2025-12-20 11:22:21 train acc=0.8811881188118812, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04189972830290842, 0.0, 0.41618573783647894, 0.41618573783647894, 0.6056355391398515]
2025-12-20 11:22:21 Epoch: 28, loss: 0.8803, lr: 0.00003757
2025-12-20 11:22:37 train acc=0.8849009900990099, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.042413692663211634, 0.0, 0.41781434918394184, 0.41781434918394184, 0.6053599744740099]
2025-12-20 11:22:37 Epoch: 29, loss: 0.8841, lr: 0.00003455
2025-12-20 11:22:52 train acc=0.8892326732673267, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.043914794921875, 0.0, 0.40774022470606436, 0.40774022470606436, 0.6110888188428217]
2025-12-20 11:22:52 Epoch: 30, loss: 0.8655, lr: 0.00003159
2025-12-20 11:23:07 train acc=0.8886138613861386, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.044497348294399754, 0.0, 0.401539415416151, 0.401539415416151, 0.607242999690594]
2025-12-20 11:23:07 Epoch: 31, loss: 0.8537, lr: 0.00002871
2025-12-20 11:23:22 train acc=0.8811881188118812, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.045145469136757425, 0.0, 0.4193211923731436, 0.4193211923731436, 0.6078932356126238]
2025-12-20 11:23:22 Epoch: 32, loss: 0.8899, lr: 0.00002591
2025-12-20 11:23:38 train acc=0.8910891089108911, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.045723188041460396, 0.0, 0.4070824349280631, 0.4070824349280631, 0.612415880259901]
2025-12-20 11:23:38 Epoch: 33, loss: 0.8660, lr: 0.00002321
2025-12-20 11:23:53 train acc=0.8867574257425742, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04648159518100248, 0.0, 0.4086074073715965, 0.4086074073715965, 0.6128050549195545]
2025-12-20 11:23:53 Epoch: 34, loss: 0.8699, lr: 0.00002061
2025-12-20 11:24:08 train acc=0.8904702970297029, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0470714002552599, 0.0, 0.3977328763149752, 0.3977328763149752, 0.6119590230507426]
2025-12-20 11:24:08 Epoch: 35, loss: 0.8487, lr: 0.00001813
2025-12-20 11:24:24 train acc=0.8886138613861386, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04721673644415223, 0.0, 0.4154240070003094, 0.4154240070003094, 0.6105521929146039]
2025-12-20 11:24:24 Epoch: 36, loss: 0.8842, lr: 0.00001577
2025-12-20 11:24:39 train acc=0.8886138613861386, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04742552502320545, 0.0, 0.4070872693958849, 0.4070872693958849, 0.6138613861386139]
2025-12-20 11:24:39 Epoch: 37, loss: 0.8677, lr: 0.00001355
2025-12-20 11:24:54 train acc=0.8941831683168316, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04785700127629951, 0.0, 0.3984894705290842, 0.3984894705290842, 0.6147581799195545]
2025-12-20 11:24:54 Epoch: 38, loss: 0.8510, lr: 0.00001147
2025-12-20 11:25:09 train acc=0.8935643564356436, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04846614422184406, 0.0, 0.39550539526608913, 0.39550539526608913, 0.6152367922339109]
2025-12-20 11:25:09 Epoch: 39, loss: 0.8457, lr: 0.00000955
2025-12-20 11:25:25 train acc=0.8917079207920792, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.048813621596534656, 0.0, 0.4013381806930693, 0.4013381806930693, 0.6153383160581684]
2025-12-20 11:25:25 Epoch: 40, loss: 0.8577, lr: 0.00000778
2025-12-20 11:25:40 train acc=0.8898514851485149, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04891363464959777, 0.0, 0.4027147954053218, 0.4027147954053218, 0.6164405747215347]
2025-12-20 11:25:40 Epoch: 41, loss: 0.8605, lr: 0.00000618
2025-12-20 11:25:55 train acc=0.8867574257425742, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04887223951887376, 0.0, 0.4020394806814666, 0.4020394806814666, 0.6136510867883663]
2025-12-20 11:25:55 Epoch: 42, loss: 0.8591, lr: 0.00000476
2025-12-20 11:26:11 train acc=0.8917079207920792, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04921639319693688, 0.0, 0.40901652421101486, 0.40901652421101486, 0.6142433090965347]
2025-12-20 11:26:11 Epoch: 43, loss: 0.8733, lr: 0.00000351
2025-12-20 11:26:26 train acc=0.8923267326732673, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.048985547358446783, 0.0, 0.39019594098081684, 0.39019594098081684, 0.6152923886138614]
2025-12-20 11:26:26 Epoch: 44, loss: 0.8355, lr: 0.00000245
2025-12-20 11:26:41 train acc=0.8917079207920792, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04910580474551361, 0.0, 0.4063666315362005, 0.4063666315362005, 0.6153914952042079]
2025-12-20 11:26:41 Epoch: 45, loss: 0.8680, lr: 0.00000157
2025-12-20 11:26:56 train acc=0.885519801980198, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04922394705290842, 0.0, 0.4038853409266708, 0.4038853409266708, 0.6139967512376238]
2025-12-20 11:26:56 Epoch: 46, loss: 0.8631, lr: 0.00000089
2025-12-20 11:27:12 train acc=0.8991336633663366, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04925234955136139, 0.0, 0.3937628717705755, 0.3937628717705755, 0.6149612275680693]
2025-12-20 11:27:12 Epoch: 47, loss: 0.8429, lr: 0.00000039
2025-12-20 11:27:27 train acc=0.8861386138613861, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.049347528136602724, 0.0, 0.4050824760210396, 0.4050824760210396, 0.6124182974938119]
2025-12-20 11:27:27 Epoch: 48, loss: 0.8656, lr: 0.00000010
2025-12-20 11:27:42 train acc=0.8867574257425742, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04930280930925124, 0.0, 0.40061724067914606, 0.40061724067914606, 0.6136027421101485]
2025-12-20 11:27:42 Epoch: 49, loss: 0.8567, lr: 0.00000000
2025-12-20 11:34:30 {'name': 'food101', 'acc': [{'clip_logits': 86.11221122112211, 'cma_logits': 84.76237623762376, 'GLR_logits': 86.93399339933994, 'final_logits': 86.95379537953795, 'acc': 86.85808580858085}], 'detail': 'dataset_name=food101, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=101, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 11:34:30 Preparing ViT-B/16 model.
2025-12-20 11:34:34 Getting cached textual weights W ...
2025-12-20 11:34:34 Initializing CMA adapter learner...
2025-12-20 11:34:34 Initializing SKD distillation...
2025-12-20 11:34:34 Preparing oxford_pets dataset.
2025-12-20 11:34:40 train acc=0.8344594594594594, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 5.510852143571184e-05, 0.0, 0.4982514252533784, 0.4982514252533784, 1.1129909206081081]
2025-12-20 11:34:40 Epoch: 0, loss: 1.0077, lr: 0.00009990
2025-12-20 11:34:45 train acc=0.8361486486486487, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0025263992515770165, 0.0, 0.4820037016997466, 0.4820037016997466, 1.1035024282094594]
2025-12-20 11:34:45 Epoch: 1, loss: 0.9775, lr: 0.00009961
2025-12-20 11:34:50 train acc=0.831081081081081, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0039848636936497045, 0.0, 0.4902475717905405, 0.4902475717905405, 1.1161713471283783]
2025-12-20 11:34:50 Epoch: 2, loss: 0.9957, lr: 0.00009911
2025-12-20 11:34:55 train acc=0.8141891891891891, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004154772371859164, 0.0, 0.4962983002533784, 0.4962983002533784, 1.1008498733108107]
2025-12-20 11:34:55 Epoch: 3, loss: 1.0078, lr: 0.00009843
2025-12-20 11:34:59 train acc=0.8412162162162162, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004571605373073269, 0.0, 0.4839675490920608, 0.4839675490920608, 1.1130701013513513]
2025-12-20 11:34:59 Epoch: 4, loss: 0.9836, lr: 0.00009755
2025-12-20 11:35:04 train acc=0.8361486486486487, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004009246826171875, 0.0, 0.4859751108530405, 0.4859751108530405, 1.1066036739864864]
2025-12-20 11:35:04 Epoch: 5, loss: 0.9870, lr: 0.00009649
2025-12-20 11:35:09 train acc=0.8243243243243243, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0051241694269953545, 0.0, 0.49427919130067566, 0.49427919130067566, 1.1090846706081081]
2025-12-20 11:35:09 Epoch: 6, loss: 1.0048, lr: 0.00009524
2025-12-20 11:35:14 train acc=0.8277027027027027, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.005987115808435388, 0.0, 0.49456622149493246, 0.49456622149493246, 1.1126610008445945]
2025-12-20 11:35:14 Epoch: 7, loss: 1.0062, lr: 0.00009382
2025-12-20 11:35:19 train acc=0.831081081081081, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.007937250910578546, 0.0, 0.4837893924197635, 0.4837893924197635, 1.1134132179054055]
2025-12-20 11:35:19 Epoch: 8, loss: 0.9866, lr: 0.00009222
2025-12-20 11:35:23 train acc=0.8327702702702703, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008894946124102618, 0.0, 0.49728146114864863, 0.49728146114864863, 1.1066960515202702]
2025-12-20 11:35:23 Epoch: 9, loss: 1.0145, lr: 0.00009045
2025-12-20 11:35:28 train acc=0.8260135135135135, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012014956087679477, 0.0, 0.4832961623733108, 0.4832961623733108, 1.1151551942567568]
2025-12-20 11:35:28 Epoch: 10, loss: 0.9897, lr: 0.00008853
2025-12-20 11:35:33 train acc=0.8344594594594594, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01428573195998733, 0.0, 0.49029211095861486, 0.49029211095861486, 1.1128853462837838]
2025-12-20 11:35:33 Epoch: 11, loss: 1.0059, lr: 0.00008645
2025-12-20 11:35:38 train acc=0.839527027027027, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01660218109955659, 0.0, 0.47466216216216217, 0.47466216216216217, 1.1106023015202702]
2025-12-20 11:35:38 Epoch: 12, loss: 0.9771, lr: 0.00008423
2025-12-20 11:35:43 train acc=0.8361486486486487, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.018453237172719593, 0.0, 0.46160888671875, 0.46160888671875, 1.1137959248310811]
2025-12-20 11:35:43 Epoch: 13, loss: 0.9528, lr: 0.00008187
2025-12-20 11:35:48 train acc=0.8378378378378378, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.021553245750633446, 0.0, 0.4482619826858108, 0.4482619826858108, 1.1079365498310811]
2025-12-20 11:35:48 Epoch: 14, loss: 0.9291, lr: 0.00007939
2025-12-20 11:35:53 train acc=0.831081081081081, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.022307112410261825, 0.0, 0.4677387959248311, 0.4677387959248311, 1.1091374577702702]
2025-12-20 11:35:53 Epoch: 15, loss: 0.9688, lr: 0.00007679
2025-12-20 11:35:58 train acc=0.8344594594594594, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02510978080130912, 0.0, 0.4649196315456081, 0.4649196315456081, 1.1113677153716217]
2025-12-20 11:35:58 Epoch: 16, loss: 0.9660, lr: 0.00007409
2025-12-20 11:36:02 train acc=0.8277027027027027, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02661586452174831, 0.0, 0.46345148859797297, 0.46345148859797297, 1.1050200591216217]
2025-12-20 11:36:02 Epoch: 17, loss: 0.9646, lr: 0.00007129
2025-12-20 11:36:07 train acc=0.8462837837837838, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02902881519214527, 0.0, 0.4510564030827703, 0.4510564030827703, 1.114917652027027]
2025-12-20 11:36:07 Epoch: 18, loss: 0.9424, lr: 0.00006841
2025-12-20 11:36:12 train acc=0.8513513513513513, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03063098804370777, 0.0, 0.45716981630067566, 0.45716981630067566, 1.111446896114865]
2025-12-20 11:36:12 Epoch: 19, loss: 0.9561, lr: 0.00006545
2025-12-20 11:36:17 train acc=0.847972972972973, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03161868533572635, 0.0, 0.44102354307432434, 0.44102354307432434, 1.1195893158783783]
2025-12-20 11:36:17 Epoch: 20, loss: 0.9249, lr: 0.00006243
2025-12-20 11:36:22 train acc=0.8547297297297297, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.034074525575380064, 0.0, 0.4333232157939189, 0.4333232157939189, 1.121238914695946]
2025-12-20 11:36:22 Epoch: 21, loss: 0.9120, lr: 0.00005937
2025-12-20 11:36:27 train acc=0.8597972972972973, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.034241547455658786, 0.0, 0.4305221970016892, 0.4305221970016892, 1.1169763513513513]
2025-12-20 11:36:27 Epoch: 22, loss: 0.9064, lr: 0.00005627
2025-12-20 11:36:32 train acc=0.8462837837837838, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03482591783678209, 0.0, 0.4419341216216216, 0.4419341216216216, 1.110892630912162]
2025-12-20 11:36:32 Epoch: 23, loss: 0.9299, lr: 0.00005314
2025-12-20 11:36:37 train acc=0.8581081081081081, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03663758973817568, 0.0, 0.4352169552364865, 0.4352169552364865, 1.1164088893581081]
2025-12-20 11:36:37 Epoch: 24, loss: 0.9183, lr: 0.00005000
2025-12-20 11:36:42 train acc=0.8733108108108109, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03735145362647804, 0.0, 0.41985259184966217, 0.41985259184966217, 1.1210013724662162]
2025-12-20 11:36:42 Epoch: 25, loss: 0.8882, lr: 0.00004686
2025-12-20 11:36:46 train acc=0.8597972972972973, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03792468921558277, 0.0, 0.4309016047297297, 0.4309016047297297, 1.1144557643581081]
2025-12-20 11:36:46 Epoch: 26, loss: 0.9110, lr: 0.00004373
2025-12-20 11:36:51 train acc=0.8631756756756757, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03873670423353041, 0.0, 0.4249482025971284, 0.4249482025971284, 1.1197212837837838]
2025-12-20 11:36:51 Epoch: 27, loss: 0.8999, lr: 0.00004063
2025-12-20 11:36:56 train acc=0.8597972972972973, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.040393313846072636, 0.0, 0.42092153188344594, 0.42092153188344594, 1.1220043285472974]
2025-12-20 11:36:56 Epoch: 28, loss: 0.8935, lr: 0.00003757
2025-12-20 11:37:01 train acc=0.8699324324324325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0405322925464527, 0.0, 0.41641977671030406, 0.41641977671030406, 1.120486697635135]
2025-12-20 11:37:01 Epoch: 29, loss: 0.8846, lr: 0.00003455
2025-12-20 11:37:06 train acc=0.8648648648648649, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0409801586254223, 0.0, 0.4150638064822635, 0.4150638064822635, 1.125607052364865]
2025-12-20 11:37:06 Epoch: 30, loss: 0.8824, lr: 0.00003159
2025-12-20 11:37:11 train acc=0.8716216216216216, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0408985034839527, 0.0, 0.4189700564822635, 0.4189700564822635, 1.1258841849662162]
2025-12-20 11:37:11 Epoch: 31, loss: 0.8901, lr: 0.00002871
2025-12-20 11:37:16 train acc=0.8665540540540541, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04232128246410473, 0.0, 0.4114033467060811, 0.4114033467060811, 1.1239310599662162]
2025-12-20 11:37:16 Epoch: 32, loss: 0.8764, lr: 0.00002591
2025-12-20 11:37:21 train acc=0.8682432432432432, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04191383155616554, 0.0, 0.41419281830658783, 0.41419281830658783, 1.1230732685810811]
2025-12-20 11:37:21 Epoch: 33, loss: 0.8815, lr: 0.00002321
2025-12-20 11:37:26 train acc=0.8547297297297297, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.042723784575591214, 0.0, 0.41441221494932434, 0.41441221494932434, 1.1292361697635136]
2025-12-20 11:37:26 Epoch: 34, loss: 0.8829, lr: 0.00002061
2025-12-20 11:37:31 train acc=0.8699324324324325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.043166289458403714, 0.0, 0.40894544446790543, 0.40894544446790543, 1.1299883868243243]
2025-12-20 11:37:31 Epoch: 35, loss: 0.8724, lr: 0.00001813
2025-12-20 11:37:35 train acc=0.8665540540540541, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.043294958166173986, 0.0, 0.4100473764780405, 0.4100473764780405, 1.1290118243243243]
2025-12-20 11:37:35 Epoch: 36, loss: 0.8746, lr: 0.00001577
2025-12-20 11:37:40 train acc=0.8716216216216216, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.043645910314611486, 0.0, 0.4079721811655405, 0.4079721811655405, 1.1242345861486487]
2025-12-20 11:37:40 Epoch: 37, loss: 0.8708, lr: 0.00001355
2025-12-20 11:37:45 train acc=0.8665540540540541, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04361374313766892, 0.0, 0.39645468222128377, 0.39645468222128377, 1.141548775337838]
2025-12-20 11:37:45 Epoch: 38, loss: 0.8479, lr: 0.00001147
2025-12-20 11:37:50 train acc=0.8699324324324325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04292421083192568, 0.0, 0.41015625, 0.41015625, 1.122994087837838]
2025-12-20 11:37:50 Epoch: 39, loss: 0.8745, lr: 0.00000955
2025-12-20 11:37:55 train acc=0.8614864864864865, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.044103673986486486, 0.0, 0.4073684279983108, 0.4073684279983108, 1.1227169552364864]
2025-12-20 11:37:55 Epoch: 40, loss: 0.8701, lr: 0.00000778
2025-12-20 11:38:00 train acc=0.8699324324324325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04372014226140203, 0.0, 0.4019775390625, 0.4019775390625, 1.13232421875]
2025-12-20 11:38:00 Epoch: 41, loss: 0.8590, lr: 0.00000618
2025-12-20 11:38:05 train acc=0.8766891891891891, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.043883452544341214, 0.0, 0.40251695787584457, 0.40251695787584457, 1.1249208192567568]
2025-12-20 11:38:05 Epoch: 42, loss: 0.8601, lr: 0.00000476
2025-12-20 11:38:10 train acc=0.8817567567567568, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.043911495724239864, 0.0, 0.39172693201013514, 0.39172693201013514, 1.1300411739864864]
2025-12-20 11:38:10 Epoch: 43, loss: 0.8386, lr: 0.00000351
2025-12-20 11:38:14 train acc=0.8631756756756757, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04356920396959459, 0.0, 0.39045179212415543, 0.39045179212415543, 1.1309253589527026]
2025-12-20 11:38:14 Epoch: 44, loss: 0.8358, lr: 0.00000245
2025-12-20 11:38:19 train acc=0.8699324324324325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04371931746199324, 0.0, 0.3993777713260135, 0.3993777713260135, 1.1302127322635136]
2025-12-20 11:38:19 Epoch: 45, loss: 0.8537, lr: 0.00000157
2025-12-20 11:38:24 train acc=0.8716216216216216, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0435741527660473, 0.0, 0.39057221283783783, 0.39057221283783783, 1.1294869087837838]
2025-12-20 11:38:24 Epoch: 46, loss: 0.8360, lr: 0.00000089
2025-12-20 11:38:29 train acc=0.8716216216216216, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04395850929054054, 0.0, 0.39616270323057434, 0.39616270323057434, 1.1275733741554055]
2025-12-20 11:38:29 Epoch: 47, loss: 0.8475, lr: 0.00000039
2025-12-20 11:38:34 train acc=0.875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04408552839949324, 0.0, 0.3961049672719595, 0.3961049672719595, 1.127269847972973]
2025-12-20 11:38:34 Epoch: 48, loss: 0.8475, lr: 0.00000010
2025-12-20 11:38:39 train acc=0.8699324324324325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04411192198057432, 0.0, 0.40240313555743246, 0.40240313555743246, 1.1292889569256757]
2025-12-20 11:38:39 Epoch: 49, loss: 0.8601, lr: 0.00000000
2025-12-20 11:39:01 {'name': 'oxford_pets', 'acc': [{'clip_logits': 89.04333605887163, 'cma_logits': 87.84409920959389, 'GLR_logits': 92.17770509675661, 'final_logits': 87.92586535840829, 'acc': 92.17770509675661}], 'detail': 'dataset_name=oxford_pets, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=37, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 11:39:01 Preparing ViT-B/16 model.
2025-12-20 11:39:05 Getting cached textual weights W ...
2025-12-20 11:39:07 Initializing CMA adapter learner...
2025-12-20 11:39:07 Initializing SKD distillation...
2025-12-20 11:39:07 Preparing sun397 dataset.
2025-12-20 11:41:31 train acc=0.6328715365239295, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008617000105399028, 0.0, 1.2816435768261965, 1.2816435768261965, 0.38902055946945846]
2025-12-20 11:41:31 Epoch: 0, loss: 2.5758, lr: 0.00009990
2025-12-20 11:43:23 train acc=0.6424748110831234, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.025854634397876653, 0.0, 1.2535729396253148, 1.2535729396253148, 0.3853369263617758]
2025-12-20 11:43:23 Epoch: 1, loss: 2.5369, lr: 0.00009961
2025-12-20 11:45:15 train acc=0.6582178841309824, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0549789159664279, 0.0, 1.2097149519836272, 1.2097149519836272, 0.38495072910107053]
2025-12-20 11:45:15 Epoch: 2, loss: 2.4783, lr: 0.00009911
2025-12-20 11:47:07 train acc=0.6697103274559194, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08540601754368703, 0.0, 1.1501231157509446, 1.1501231157509446, 0.3930989993309194]
2025-12-20 11:47:07 Epoch: 3, loss: 2.3896, lr: 0.00009843
2025-12-20 11:48:59 train acc=0.6865554156171285, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10890624385036209, 0.0, 1.091769816593199, 1.091769816593199, 0.4122748002597607]
2025-12-20 11:48:59 Epoch: 4, loss: 2.2965, lr: 0.00009755
2025-12-20 11:50:51 train acc=0.7052896725440806, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.12903277879998426, 0.0, 1.026754614688287, 1.026754614688287, 0.43975630214892947]
2025-12-20 11:50:51 Epoch: 5, loss: 2.1868, lr: 0.00009649
2025-12-20 11:52:43 train acc=0.7237090680100756, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.14478107904006612, 0.0, 0.9659353107289043, 0.9659353107289043, 0.4680870690333753]
2025-12-20 11:52:43 Epoch: 6, loss: 2.0813, lr: 0.00009524
2025-12-20 11:54:34 train acc=0.7484256926952141, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1648825542152078, 0.0, 0.8900251028219458, 0.8900251028219458, 0.509024593631927]
2025-12-20 11:54:34 Epoch: 7, loss: 1.9501, lr: 0.00009382
2025-12-20 11:56:26 train acc=0.7693639798488665, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1825520013381612, 0.0, 0.8235204586153967, 0.8235204586153967, 0.5522565481344458]
2025-12-20 11:56:26 Epoch: 8, loss: 1.8352, lr: 0.00009222
2025-12-20 11:58:18 train acc=0.7874685138539043, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20013996575881612, 0.0, 0.7576993466624685, 0.7576993466624685, 0.6029541630588791]
2025-12-20 11:58:18 Epoch: 9, loss: 1.7216, lr: 0.00009045
2025-12-20 12:00:10 train acc=0.8173803526448362, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21521149834697734, 0.0, 0.6923532942380353, 0.6923532942380353, 0.6520153593356424]
2025-12-20 12:00:10 Epoch: 10, loss: 1.6064, lr: 0.00008853
2025-12-20 12:02:02 train acc=0.8331234256926953, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22968528613035263, 0.0, 0.6339646346623111, 0.6339646346623111, 0.7056604957100125]
2025-12-20 12:02:02 Epoch: 11, loss: 1.5047, lr: 0.00008645
2025-12-20 12:03:53 train acc=0.8531171284634761, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2441080319190806, 0.0, 0.5738196384996851, 0.5738196384996851, 0.7629880352644837]
2025-12-20 12:03:53 Epoch: 12, loss: 1.3994, lr: 0.00008423
2025-12-20 12:05:45 train acc=0.8720088161209067, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2543825394560768, 0.0, 0.517171633934194, 0.517171633934194, 0.8174111008343828]
2025-12-20 12:05:45 Epoch: 13, loss: 1.2969, lr: 0.00008187
2025-12-20 12:07:37 train acc=0.888066750629723, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2671461129368703, 0.0, 0.4653806133894836, 0.4653806133894836, 0.8736138716152393]
2025-12-20 12:07:37 Epoch: 14, loss: 1.2066, lr: 0.00007939
2025-12-20 12:09:29 train acc=0.9077455919395466, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.27747166246851385, 0.0, 0.4157748666758501, 0.4157748666758501, 0.9324991144521411]
2025-12-20 12:09:29 Epoch: 15, loss: 1.1183, lr: 0.00007679
2025-12-20 12:11:21 train acc=0.9245906801007556, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2854372884524559, 0.0, 0.3703110548350913, 0.3703110548350913, 0.9914310945371536]
2025-12-20 12:11:21 Epoch: 16, loss: 1.0360, lr: 0.00007409
2025-12-20 12:13:13 train acc=0.930573047858942, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2923574759918136, 0.0, 0.3427483777255195, 0.3427483777255195, 1.0381154557619647]
2025-12-20 12:13:13 Epoch: 17, loss: 0.9882, lr: 0.00007129
2025-12-20 12:15:04 train acc=0.9406486146095718, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.29759081785264485, 0.0, 0.3066209461586902, 0.3066209461586902, 1.089191888381612]
2025-12-20 12:15:04 Epoch: 18, loss: 0.9217, lr: 0.00006841
2025-12-20 12:16:56 train acc=0.9534005037783375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3038449996064232, 0.0, 0.2724115097853038, 0.2724115097853038, 1.1430135193639799]
2025-12-20 12:16:56 Epoch: 19, loss: 0.8601, lr: 0.00006545
2025-12-20 12:18:48 train acc=0.96205919395466, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.307210081470403, 0.0, 0.24571024320588003, 0.24571024320588003, 1.1871888283217884]
2025-12-20 12:18:48 Epoch: 20, loss: 0.8105, lr: 0.00006243
2025-12-20 12:20:40 train acc=0.9667821158690176, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31073197910107053, 0.0, 0.22322109424197104, 0.22322109424197104, 1.235775887515743]
2025-12-20 12:20:40 Epoch: 21, loss: 0.7695, lr: 0.00005937
2025-12-20 12:22:31 train acc=0.9752833753148614, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31311188897197734, 0.0, 0.1996365410254644, 0.1996365410254644, 1.2732124232525188]
2025-12-20 12:22:31 Epoch: 22, loss: 0.7251, lr: 0.00005627
2025-12-20 12:24:23 train acc=0.9767002518891688, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3157623829108942, 0.0, 0.18536130967608627, 0.18536130967608627, 1.3128603687814862]
2025-12-20 12:24:23 Epoch: 23, loss: 0.6996, lr: 0.00005314
2025-12-20 12:26:15 train acc=0.9817380352644837, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.316315850322733, 0.0, 0.16838707911878148, 0.16838707911878148, 1.3447782194584383]
2025-12-20 12:26:15 Epoch: 24, loss: 0.6665, lr: 0.00005000
2025-12-20 12:28:06 train acc=0.9847292191435768, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3174117157981738, 0.0, 0.15663834963397355, 0.15663834963397355, 1.3742841821473553]
2025-12-20 12:28:06 Epoch: 25, loss: 0.6444, lr: 0.00004686
2025-12-20 12:29:58 train acc=0.9859886649874056, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3180654223079345, 0.0, 0.1461727420989452, 0.1461727420989452, 1.4049536563287153]
2025-12-20 12:29:58 Epoch: 26, loss: 0.6245, lr: 0.00004373
2025-12-20 12:31:50 train acc=0.9889798488664987, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31819333477644834, 0.0, 0.1350395913688602, 0.1350395913688602, 1.4431035500629723]
2025-12-20 12:31:50 Epoch: 27, loss: 0.6027, lr: 0.00004063
2025-12-20 12:33:42 train acc=0.9894521410579346, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31808940589578083, 0.0, 0.12817574988684666, 0.12817574988684666, 1.462238763381612]
2025-12-20 12:33:42 Epoch: 28, loss: 0.5891, lr: 0.00003757
2025-12-20 12:35:34 train acc=0.9914987405541562, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3173231610122796, 0.0, 0.11869531434489138, 0.11869531434489138, 1.4773890113350125]
2025-12-20 12:35:34 Epoch: 29, loss: 0.5695, lr: 0.00003455
2025-12-20 12:37:26 train acc=0.9921284634760705, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31700091998583124, 0.0, 0.11407524512456707, 0.11407524512456707, 1.5089268143891688]
2025-12-20 12:37:26 Epoch: 30, loss: 0.5602, lr: 0.00003159
2025-12-20 12:39:17 train acc=0.9941750629722922, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3160489560374685, 0.0, 0.10776556288865712, 0.10776556288865712, 1.5193885784005037]
2025-12-20 12:39:17 Epoch: 31, loss: 0.5468, lr: 0.00002871
2025-12-20 12:41:09 train acc=0.9946473551637279, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31537741557777077, 0.0, 0.10153102154095167, 0.10153102154095167, 1.5352841624685138]
2025-12-20 12:41:09 Epoch: 32, loss: 0.5338, lr: 0.00002591
2025-12-20 12:43:00 train acc=0.9954345088161209, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.315077313247796, 0.0, 0.09699796969704423, 0.09699796969704423, 1.5518808052581865]
2025-12-20 12:43:00 Epoch: 33, loss: 0.5246, lr: 0.00002321
2025-12-20 12:44:52 train acc=0.9949622166246851, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31326870473866497, 0.0, 0.09672261965965444, 0.09672261965965444, 1.5535166089420656]
2025-12-20 12:44:52 Epoch: 34, loss: 0.5222, lr: 0.00002061
2025-12-20 12:46:44 train acc=0.9952770780856424, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31287635784005036, 0.0, 0.09279711360595089, 0.09279711360595089, 1.5712177267002518]
2025-12-20 12:46:44 Epoch: 35, loss: 0.5142, lr: 0.00001813
2025-12-20 12:48:35 train acc=0.9963790931989924, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3121531604219144, 0.0, 0.09032088503128936, 0.09032088503128936, 1.5756897433879093]
2025-12-20 12:48:35 Epoch: 36, loss: 0.5085, lr: 0.00001577
2025-12-20 12:50:27 train acc=0.9970088161209067, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.31120857603904284, 0.0, 0.08818419333969615, 0.08818419333969615, 1.5796993073047858]
2025-12-20 12:50:27 Epoch: 37, loss: 0.5034, lr: 0.00001355
2025-12-20 12:52:19 train acc=0.9974811083123426, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3107067655856423, 0.0, 0.085814853158946, 0.085814853158946, 1.5902889837846348]
2025-12-20 12:52:19 Epoch: 38, loss: 0.4983, lr: 0.00001147
2025-12-20 12:54:11 train acc=0.9968513853904282, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.30991961193324935, 0.0, 0.08473328559164436, 0.08473328559164436, 1.598126082336272]
2025-12-20 12:54:11 Epoch: 39, loss: 0.4953, lr: 0.00000955
2025-12-20 12:56:02 train acc=0.9970088161209067, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.309425796009131, 0.0, 0.08304636304264405, 0.08304636304264405, 1.6047947496851385]
2025-12-20 12:56:02 Epoch: 40, loss: 0.4916, lr: 0.00000778
2025-12-20 12:57:54 train acc=0.9974811083123426, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.30841787035579343, 0.0, 0.08064066312775504, 0.08064066312775504, 1.6052842608627205]
2025-12-20 12:57:54 Epoch: 41, loss: 0.4858, lr: 0.00000618
2025-12-20 12:59:46 train acc=0.9976385390428212, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3080728756690806, 0.0, 0.08101263935079503, 0.08101263935079503, 1.6067577141057934]
2025-12-20 12:59:46 Epoch: 42, loss: 0.4862, lr: 0.00000476
2025-12-20 13:01:38 train acc=0.996536523929471, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.30777215837531485, 0.0, 0.08255777431074858, 0.08255777431074858, 1.604593041561713]
2025-12-20 13:01:38 Epoch: 43, loss: 0.4889, lr: 0.00000351
2025-12-20 13:03:30 train acc=0.9963790931989924, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3081356019757557, 0.0, 0.08069070580624213, 0.08069070580624213, 1.610885351070529]
2025-12-20 13:03:30 Epoch: 44, loss: 0.4856, lr: 0.00000245
2025-12-20 13:05:22 train acc=0.997323677581864, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3076651546756927, 0.0, 0.0774049542712925, 0.0774049542712925, 1.6205894796914357]
2025-12-20 13:05:22 Epoch: 45, loss: 0.4787, lr: 0.00000157
2025-12-20 13:07:13 train acc=0.9974811083123426, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3075618407588161, 0.0, 0.07967094209992916, 0.07967094209992916, 1.6137928998740554]
2025-12-20 13:07:13 Epoch: 46, loss: 0.4830, lr: 0.00000089
2025-12-20 13:09:05 train acc=0.9974811083123426, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.307662694820529, 0.0, 0.078945515438051, 0.078945515438051, 1.6175441789987406]
2025-12-20 13:09:05 Epoch: 47, loss: 0.4817, lr: 0.00000039
2025-12-20 13:10:57 train acc=0.9976385390428212, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.3073386089027078, 0.0, 0.07886195723295812, 0.07886195723295812, 1.6190004132556675]
2025-12-20 13:10:57 Epoch: 48, loss: 0.4813, lr: 0.00000010
2025-12-20 13:12:49 train acc=0.997323677581864, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.30742777865239296, 0.0, 0.08035770291345246, 0.08035770291345246, 1.6141446591624684]
2025-12-20 13:12:49 Epoch: 49, loss: 0.4843, lr: 0.00000000
2025-12-20 13:19:35 {'name': 'sun397', 'acc': [{'clip_logits': 62.59445843828715, 'cma_logits': 61.97984886649874, 'GLR_logits': 75.37027707808565, 'final_logits': 72.05541561712846, 'acc': 75.54659949622166}], 'detail': 'dataset_name=sun397, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=397, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 13:19:35 Preparing ViT-B/16 model.
2025-12-20 13:19:39 Getting cached textual weights W ...
2025-12-20 13:19:40 Initializing CMA adapter learner...
2025-12-20 13:19:40 Initializing SKD distillation...
2025-12-20 13:19:40 Preparing ucf101 dataset.
2025-12-20 13:19:57 train acc=0.6571782178217822, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00208800204909674, 0.0, 1.1074823058477723, 1.1074823058477723, 0.45224029238861385]
2025-12-20 13:19:57 Epoch: 0, loss: 2.2215, lr: 0.00009990
2025-12-20 13:20:12 train acc=0.6639851485148515, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.006926319386699412, 0.0, 1.086802869740099, 1.086802869740099, 0.45264880491955445]
2025-12-20 13:20:12 Epoch: 1, loss: 2.1851, lr: 0.00009961
2025-12-20 13:20:27 train acc=0.6627475247524752, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008769535782313582, 0.0, 1.0901978747679455, 1.0901978747679455, 0.4522064511138614]
2025-12-20 13:20:27 Epoch: 2, loss: 2.1937, lr: 0.00009911
2025-12-20 13:20:42 train acc=0.6540841584158416, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.012707020976755879, 0.0, 1.0992685450185644, 1.0992685450185644, 0.45041769801980197]
2025-12-20 13:20:42 Epoch: 3, loss: 2.2158, lr: 0.00009843
2025-12-20 13:20:58 train acc=0.6695544554455446, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.019006861318456063, 0.0, 1.0556108833539604, 1.0556108833539604, 0.45044670482673266]
2025-12-20 13:20:58 Epoch: 4, loss: 2.1346, lr: 0.00009755
2025-12-20 13:21:13 train acc=0.6658415841584159, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02977216361772896, 0.0, 1.0483736850247525, 1.0483736850247525, 0.44603283570544555]
2025-12-20 13:21:13 Epoch: 5, loss: 2.1309, lr: 0.00009649
2025-12-20 13:21:28 train acc=0.6813118811881188, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0417308240833849, 0.0, 1.0207108601485149, 1.0207108601485149, 0.45029200185643564]
2025-12-20 13:21:28 Epoch: 6, loss: 2.0877, lr: 0.00009524
2025-12-20 13:21:44 train acc=0.7004950495049505, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05661645266089109, 0.0, 0.9826225054146039, 0.9826225054146039, 0.45523041073638615]
2025-12-20 13:21:44 Epoch: 7, loss: 2.0264, lr: 0.00009382
2025-12-20 13:21:59 train acc=0.7073019801980198, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07067236569848391, 0.0, 0.9582253635519802, 0.9582253635519802, 0.4603960396039604]
2025-12-20 13:21:59 Epoch: 8, loss: 1.9917, lr: 0.00009222
2025-12-20 13:22:14 train acc=0.7165841584158416, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08390944074876237, 0.0, 0.9257498259591584, 0.9257498259591584, 0.46923586401608913]
2025-12-20 13:22:14 Epoch: 9, loss: 1.9400, lr: 0.00009045
2025-12-20 13:22:30 train acc=0.7277227722772277, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09818864576887376, 0.0, 0.8897572130259901, 0.8897572130259901, 0.4802439472462871]
2025-12-20 13:22:30 Epoch: 10, loss: 1.8825, lr: 0.00008853
2025-12-20 13:22:45 train acc=0.75, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10910910426980198, 0.0, 0.8783913791769802, 0.8783913791769802, 0.4932389967512376]
2025-12-20 13:22:45 Epoch: 11, loss: 1.8707, lr: 0.00008645
2025-12-20 13:23:00 train acc=0.7580445544554455, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.12081395517481436, 0.0, 0.8319829053217822, 0.8319829053217822, 0.5117791808477723]
2025-12-20 13:23:00 Epoch: 12, loss: 1.7899, lr: 0.00008423
2025-12-20 13:23:15 train acc=0.7512376237623762, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.12932684870049505, 0.0, 0.8049292233910891, 0.8049292233910891, 0.519729463180693]
2025-12-20 13:23:15 Epoch: 13, loss: 1.7444, lr: 0.00008187
2025-12-20 13:23:31 train acc=0.7623762376237624, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1387008818069307, 0.0, 0.7774646116955446, 0.7774646116955446, 0.5409890354269802]
2025-12-20 13:23:31 Epoch: 14, loss: 1.6991, lr: 0.00007939
2025-12-20 13:23:46 train acc=0.7858910891089109, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.14591028194616337, 0.0, 0.745494275990099, 0.745494275990099, 0.5558308516398515]
2025-12-20 13:23:46 Epoch: 15, loss: 1.6424, lr: 0.00007679
2025-12-20 13:24:01 train acc=0.7883663366336634, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1533892036664604, 0.0, 0.7336280747215347, 0.7336280747215347, 0.573063312190594]
2025-12-20 13:24:01 Epoch: 16, loss: 1.6264, lr: 0.00007409
2025-12-20 13:24:17 train acc=0.8056930693069307, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.16087779432240099, 0.0, 0.7046055557704208, 0.7046055557704208, 0.5861236270111386]
2025-12-20 13:24:17 Epoch: 17, loss: 1.5760, lr: 0.00007129
2025-12-20 13:24:32 train acc=0.8168316831683168, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1644685952970297, 0.0, 0.6604849938118812, 0.6604849938118812, 0.6003127900680693]
2025-12-20 13:24:32 Epoch: 18, loss: 1.4914, lr: 0.00006841
2025-12-20 13:24:47 train acc=0.8199257425742574, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.17158493193069307, 0.0, 0.6628659692141089, 0.6628659692141089, 0.6183453550433168]
2025-12-20 13:24:47 Epoch: 19, loss: 1.5035, lr: 0.00006545
2025-12-20 13:25:03 train acc=0.8378712871287128, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1768399984529703, 0.0, 0.6149660620358911, 0.6149660620358911, 0.6390320428527227]
2025-12-20 13:25:03 Epoch: 20, loss: 1.4132, lr: 0.00006243
2025-12-20 13:25:18 train acc=0.8428217821782178, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1818049969059406, 0.0, 0.5929233060024752, 0.5929233060024752, 0.6541131652227723]
2025-12-20 13:25:18 Epoch: 21, loss: 1.3741, lr: 0.00005937
2025-12-20 13:25:33 train acc=0.8508663366336634, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.18773205445544555, 0.0, 0.562399684792698, 0.562399684792698, 0.6745895536819307]
2025-12-20 13:25:33 Epoch: 22, loss: 1.3193, lr: 0.00005627
2025-12-20 13:25:49 train acc=0.8576732673267327, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19061339727722773, 0.0, 0.5569125638149752, 0.5569125638149752, 0.68505859375]
2025-12-20 13:25:49 Epoch: 23, loss: 1.3112, lr: 0.00005314
2025-12-20 13:26:04 train acc=0.8669554455445545, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19578386061262376, 0.0, 0.530582843440594, 0.530582843440594, 0.7057186919863861]
2025-12-20 13:26:04 Epoch: 24, loss: 1.2640, lr: 0.00005000
2025-12-20 13:26:19 train acc=0.8712871287128713, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.19951244392017325, 0.0, 0.5266512124845297, 0.5266512124845297, 0.7215177328279703]
2025-12-20 13:26:19 Epoch: 25, loss: 1.2600, lr: 0.00004686
2025-12-20 13:26:35 train acc=0.8712871287128713, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20315642404084158, 0.0, 0.5062956857209159, 0.5062956857209159, 0.7381942295792079]
2025-12-20 13:26:35 Epoch: 26, loss: 1.2231, lr: 0.00004373
2025-12-20 13:26:50 train acc=0.8824257425742574, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2057041885829208, 0.0, 0.48173900642017325, 0.48173900642017325, 0.7526831296410891]
2025-12-20 13:26:50 Epoch: 27, loss: 1.1766, lr: 0.00004063
2025-12-20 13:27:05 train acc=0.8892326732673267, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.20908952467512376, 0.0, 0.4688636099938119, 0.4688636099938119, 0.7624004099628713]
2025-12-20 13:27:05 Epoch: 28, loss: 1.1545, lr: 0.00003757
2025-12-20 13:27:21 train acc=0.8836633663366337, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21093870861695543, 0.0, 0.4534440748762376, 0.4534440748762376, 0.7844649211014851]
2025-12-20 13:27:21 Epoch: 29, loss: 1.1256, lr: 0.00003455
2025-12-20 13:27:36 train acc=0.8997524752475248, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2127129583075495, 0.0, 0.4455143390315594, 0.4455143390315594, 0.7833336556311881]
2025-12-20 13:27:36 Epoch: 30, loss: 1.1116, lr: 0.00003159
2025-12-20 13:27:51 train acc=0.9016089108910891, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21587107441212872, 0.0, 0.42816887279548266, 0.42816887279548266, 0.8021832456683168]
2025-12-20 13:27:51 Epoch: 31, loss: 1.0802, lr: 0.00002871
2025-12-20 13:28:07 train acc=0.9047029702970297, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21791363706683167, 0.0, 0.42775552579672027, 0.42775552579672027, 0.8149510751856436]
2025-12-20 13:28:07 Epoch: 32, loss: 1.0816, lr: 0.00002591
2025-12-20 13:28:23 train acc=0.900990099009901, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.21926245358910892, 0.0, 0.424654214689047, 0.424654214689047, 0.8232711943069307]
2025-12-20 13:28:23 Epoch: 33, loss: 1.0767, lr: 0.00002321
2025-12-20 13:28:38 train acc=0.9096534653465347, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2207828937190594, 0.0, 0.40897603554300743, 0.40897603554300743, 0.8307356126237624]
2025-12-20 13:28:38 Epoch: 34, loss: 1.0470, lr: 0.00002061
2025-12-20 13:28:53 train acc=0.9077970297029703, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22287863551980197, 0.0, 0.4046123240253713, 0.4046123240253713, 0.8493676516089109]
2025-12-20 13:28:53 Epoch: 35, loss: 1.0406, lr: 0.00001813
2025-12-20 13:29:09 train acc=0.9133663366336634, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22213533609220298, 0.0, 0.39268387898360146, 0.39268387898360146, 0.8452293471534653]
2025-12-20 13:29:09 Epoch: 36, loss: 1.0160, lr: 0.00001577
2025-12-20 13:29:24 train acc=0.9183168316831684, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22339471495977722, 0.0, 0.3818601098391089, 0.3818601098391089, 0.8509581915222773]
2025-12-20 13:29:24 Epoch: 37, loss: 0.9956, lr: 0.00001355
2025-12-20 13:29:40 train acc=0.9121287128712872, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22568504409034654, 0.0, 0.38313399211014854, 0.38313399211014854, 0.8626866104579208]
2025-12-20 13:29:40 Epoch: 38, loss: 1.0005, lr: 0.00001147
2025-12-20 13:29:55 train acc=0.9263613861386139, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22551342048267325, 0.0, 0.37604182781559403, 0.37604182781559403, 0.8647896039603961]
2025-12-20 13:29:55 Epoch: 39, loss: 0.9863, lr: 0.00000955
2025-12-20 13:30:10 train acc=0.926980198019802, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22597994662747525, 0.0, 0.37843065922803215, 0.37843065922803215, 0.8666073638613861]
2025-12-20 13:30:10 Epoch: 40, loss: 0.9916, lr: 0.00000778
2025-12-20 13:30:26 train acc=0.9288366336633663, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22651898978960397, 0.0, 0.37366326964727725, 0.37366326964727725, 0.8698706296410891]
2025-12-20 13:30:26 Epoch: 41, loss: 0.9825, lr: 0.00000618
2025-12-20 13:30:41 train acc=0.9257425742574258, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2272973391089109, 0.0, 0.3692203937190594, 0.3692203937190594, 0.8691793007425742]
2025-12-20 13:30:41 Epoch: 42, loss: 0.9745, lr: 0.00000476
2025-12-20 13:30:56 train acc=0.9133663366336634, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2268864093440594, 0.0, 0.3851312316290223, 0.3851312316290223, 0.8662061030321783]
2025-12-20 13:30:56 Epoch: 43, loss: 1.0059, lr: 0.00000351
2025-12-20 13:31:12 train acc=0.9183168316831684, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2271704343285891, 0.0, 0.3807463693146658, 0.3807463693146658, 0.876266630569307]
2025-12-20 13:31:12 Epoch: 44, loss: 0.9974, lr: 0.00000245
2025-12-20 13:31:27 train acc=0.9195544554455446, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22726108060024752, 0.0, 0.36860279045482675, 0.36860279045482675, 0.8725972694925742]
2025-12-20 13:31:27 Epoch: 45, loss: 0.9732, lr: 0.00000157
2025-12-20 13:31:42 train acc=0.931930693069307, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2279101079053218, 0.0, 0.3568755801361386, 0.3568755801361386, 0.8855391398514851]
2025-12-20 13:31:42 Epoch: 46, loss: 0.9506, lr: 0.00000089
2025-12-20 13:31:57 train acc=0.9300742574257426, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.2268912438118812, 0.0, 0.36810121441831684, 0.36810121441831684, 0.8784759823638614]
2025-12-20 13:31:57 Epoch: 47, loss: 0.9718, lr: 0.00000039
2025-12-20 13:32:13 train acc=0.9282178217821783, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22827027575804457, 0.0, 0.36797491394647275, 0.36797491394647275, 0.8704652691831684]
2025-12-20 13:32:13 Epoch: 48, loss: 0.9730, lr: 0.00000010
2025-12-20 13:32:28 train acc=0.9176980198019802, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.22757532100866337, 0.0, 0.3725900177908416, 0.3725900177908416, 0.8778378326113861]
2025-12-20 13:32:28 Epoch: 49, loss: 0.9815, lr: 0.00000000
2025-12-20 13:32:54 {'name': 'ucf101', 'acc': [{'clip_logits': 66.77240285487707, 'cma_logits': 58.815754692043356, 'GLR_logits': 82.18345228654506, 'final_logits': 75.44277028813111, 'acc': 82.18345228654506}], 'detail': 'dataset_name=ucf101, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=16, backbone=ViT-B/16, num_classes=101, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-20 13:32:54 avg clip_logits acc=65.09417676752176
2025-12-20 13:32:54 avg cma_logits acc=61.319171150839736
2025-12-20 13:32:54 avg GLR_logits acc=74.53507947137432
2025-12-20 13:32:54 avg final_logits acc=67.48666918130132
2025-12-20 13:32:54 avg acc acc=74.61675215978578
