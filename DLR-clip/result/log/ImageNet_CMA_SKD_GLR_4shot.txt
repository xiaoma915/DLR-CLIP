2025-12-16 09:54:10 Preparing ViT-B/16 model.
2025-12-16 09:54:13 Getting cached textual weights W ...
2025-12-16 09:54:13 Initializing CMA adapter learner...
2025-12-16 09:54:13 Initializing SKD distillation...
2025-12-16 09:54:13 Preparing imagenet dataset.
2025-12-16 09:56:36 train acc=0.69125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 1.6384124755859375e-06, 0.0, 1.1539921875, 1.148583984375, 0.562470703125]
2025-12-16 09:56:36 Epoch: 0, loss: 2.3082, lr: 0.00009990
2025-12-16 09:58:05 train acc=0.7075, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0008428540229797364, 0.0, 1.148234375, 1.05271875, 0.73119140625]
2025-12-16 09:58:05 Epoch: 1, loss: 2.2091, lr: 0.00009961
2025-12-16 09:59:33 train acc=0.725, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.002310577392578125, 0.0, 1.16015625, 0.99778125, 0.94316796875]
2025-12-16 09:59:33 Epoch: 2, loss: 2.1697, lr: 0.00009911
2025-12-16 10:01:01 train acc=0.7355, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0023684921264648436, 0.0, 1.1523125, 0.929216796875, 1.16888671875]
2025-12-16 10:01:01 Epoch: 3, loss: 2.0956, lr: 0.00009843
2025-12-16 10:02:28 train acc=0.75775, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0024441070556640624, 0.0, 1.14983984375, 0.8479755859375, 1.3910625]
2025-12-16 10:02:28 Epoch: 4, loss: 2.0142, lr: 0.00009755
2025-12-16 10:03:55 train acc=0.774, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0030880508422851563, 0.0, 1.1558359375, 0.7848203125, 1.780640625]
2025-12-16 10:03:55 Epoch: 5, loss: 1.9616, lr: 0.00009649
2025-12-16 10:05:23 train acc=0.79825, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0038578872680664063, 0.0, 1.14440234375, 0.703140625, 1.9794375]
2025-12-16 10:05:23 Epoch: 6, loss: 1.8712, lr: 0.00009524
2025-12-16 10:06:51 train acc=0.81725, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.004952056884765625, 0.0, 1.1397890625, 0.63308984375, 2.37703125]
2025-12-16 10:06:51 Epoch: 7, loss: 1.8015, lr: 0.00009382
2025-12-16 10:08:20 train acc=0.841, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.00652728271484375, 0.0, 1.13914453125, 0.572416015625, 2.617453125]
2025-12-16 10:08:20 Epoch: 8, loss: 1.7444, lr: 0.00009222
2025-12-16 10:09:49 train acc=0.8595, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.008466094970703124, 0.0, 1.14276953125, 0.51575390625, 2.891546875]
2025-12-16 10:09:49 Epoch: 9, loss: 1.6959, lr: 0.00009045
2025-12-16 10:11:18 train acc=0.874, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01094818115234375, 0.0, 1.13612890625, 0.466724609375, 3.30021875]
2025-12-16 10:11:18 Epoch: 10, loss: 1.6468, lr: 0.00008853
2025-12-16 10:12:47 train acc=0.884, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.01372857666015625, 0.0, 1.12591015625, 0.42044580078125, 3.53471875]
2025-12-16 10:12:47 Epoch: 11, loss: 1.5954, lr: 0.00008645
2025-12-16 10:14:16 train acc=0.90175, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0171588134765625, 0.0, 1.100787109375, 0.371712890625, 3.7916875]
2025-12-16 10:14:16 Epoch: 12, loss: 1.5276, lr: 0.00008423
2025-12-16 10:15:44 train acc=0.9085, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.02070263671875, 0.0, 1.109884765625, 0.3549111328125, 3.967875]
2025-12-16 10:15:44 Epoch: 13, loss: 1.5252, lr: 0.00008187
2025-12-16 10:17:13 train acc=0.92575, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0248111572265625, 0.0, 1.0770078125, 0.3174931640625, 4.150171875]
2025-12-16 10:17:13 Epoch: 14, loss: 1.4608, lr: 0.00007939
2025-12-16 10:18:42 train acc=0.9295, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.028898193359375, 0.0, 1.06145703125, 0.29900390625, 4.313375]
2025-12-16 10:18:42 Epoch: 15, loss: 1.4325, lr: 0.00007679
2025-12-16 10:20:09 train acc=0.93325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.03353955078125, 0.0, 1.05076953125, 0.28343896484375, 4.394703125]
2025-12-16 10:20:10 Epoch: 16, loss: 1.4117, lr: 0.00007409
2025-12-16 10:21:37 train acc=0.93925, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.037787109375, 0.0, 1.026328125, 0.25661669921875, 4.523484375]
2025-12-16 10:21:37 Epoch: 17, loss: 1.3659, lr: 0.00007129
2025-12-16 10:23:05 train acc=0.9495, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.04207080078125, 0.0, 1.000087890625, 0.239185546875, 4.575453125]
2025-12-16 10:23:05 Epoch: 18, loss: 1.3271, lr: 0.00006841
2025-12-16 10:24:32 train acc=0.95125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.046614990234375, 0.0, 0.97901953125, 0.227794921875, 4.6230625]
2025-12-16 10:24:32 Epoch: 19, loss: 1.2996, lr: 0.00006545
2025-12-16 10:26:00 train acc=0.95025, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.051132568359375, 0.0, 0.96030859375, 0.21958447265625, 4.757578125]
2025-12-16 10:26:00 Epoch: 20, loss: 1.2786, lr: 0.00006243
2025-12-16 10:27:28 train acc=0.957, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.05508984375, 0.0, 0.939484375, 0.2083955078125, 4.72903125]
2025-12-16 10:27:28 Epoch: 21, loss: 1.2502, lr: 0.00005937
2025-12-16 10:28:57 train acc=0.95875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.059515625, 0.0, 0.93076953125, 0.20776611328125, 4.763734375]
2025-12-16 10:28:57 Epoch: 22, loss: 1.2457, lr: 0.00005627
2025-12-16 10:30:26 train acc=0.964, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06354833984375, 0.0, 0.902880859375, 0.19243017578125, 4.7901875]
2025-12-16 10:30:26 Epoch: 23, loss: 1.2068, lr: 0.00005314
2025-12-16 10:31:55 train acc=0.96225, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.06714697265625, 0.0, 0.8771640625, 0.185721923828125, 4.802109375]
2025-12-16 10:31:55 Epoch: 24, loss: 1.1781, lr: 0.00005000
2025-12-16 10:33:24 train acc=0.96575, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07084716796875, 0.0, 0.8668125, 0.18562109375, 4.8115]
2025-12-16 10:33:24 Epoch: 25, loss: 1.1714, lr: 0.00004686
2025-12-16 10:34:53 train acc=0.971, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07404833984375, 0.0, 0.844015625, 0.1731513671875, 4.806375]
2025-12-16 10:34:53 Epoch: 26, loss: 1.1392, lr: 0.00004373
2025-12-16 10:36:21 train acc=0.97275, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.07713232421875, 0.0, 0.82001171875, 0.16548095703125, 4.8121875]
2025-12-16 10:36:21 Epoch: 27, loss: 1.1108, lr: 0.00004063
2025-12-16 10:37:50 train acc=0.97075, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08013720703125, 0.0, 0.805134765625, 0.162693115234375, 4.80709375]
2025-12-16 10:37:50 Epoch: 28, loss: 1.0960, lr: 0.00003757
2025-12-16 10:39:18 train acc=0.973, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0827392578125, 0.0, 0.790041015625, 0.1578046875, 4.820125]
2025-12-16 10:39:18 Epoch: 29, loss: 1.0788, lr: 0.00003455
2025-12-16 10:40:47 train acc=0.97275, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08524853515625, 0.0, 0.77606640625, 0.156052490234375, 4.82578125]
2025-12-16 10:40:47 Epoch: 30, loss: 1.0656, lr: 0.00003159
2025-12-16 10:42:14 train acc=0.97725, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.08737255859375, 0.0, 0.767576171875, 0.152947998046875, 4.816875]
2025-12-16 10:42:14 Epoch: 31, loss: 1.0561, lr: 0.00002871
2025-12-16 10:43:42 train acc=0.9745, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.089421875, 0.0, 0.7597021484375, 0.1559482421875, 4.80821875]
2025-12-16 10:43:42 Epoch: 32, loss: 1.0532, lr: 0.00002591
2025-12-16 10:45:09 train acc=0.9775, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0912197265625, 0.0, 0.740033203125, 0.146925537109375, 4.79740625]
2025-12-16 10:45:09 Epoch: 33, loss: 1.0261, lr: 0.00002321
2025-12-16 10:46:37 train acc=0.977, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09273828125, 0.0, 0.73397265625, 0.145439208984375, 4.780203125]
2025-12-16 10:46:37 Epoch: 34, loss: 1.0200, lr: 0.00002061
2025-12-16 10:48:06 train acc=0.977, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09409375, 0.0, 0.73227734375, 0.146142333984375, 4.776421875]
2025-12-16 10:48:06 Epoch: 35, loss: 1.0202, lr: 0.00001813
2025-12-16 10:49:35 train acc=0.98075, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09532666015625, 0.0, 0.7087529296875, 0.1391650390625, 4.771125]
2025-12-16 10:49:35 Epoch: 36, loss: 0.9909, lr: 0.00001577
2025-12-16 10:51:04 train acc=0.982, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09640673828125, 0.0, 0.7132607421875, 0.1385244140625, 4.72759375]
2025-12-16 10:51:04 Epoch: 37, loss: 0.9955, lr: 0.00001355
2025-12-16 10:52:33 train acc=0.97825, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09719384765625, 0.0, 0.7044921875, 0.14254248046875, 4.751390625]
2025-12-16 10:52:33 Epoch: 38, loss: 0.9917, lr: 0.00001147
2025-12-16 10:54:01 train acc=0.98025, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0978759765625, 0.0, 0.69893359375, 0.144412841796875, 4.76909375]
2025-12-16 10:54:01 Epoch: 39, loss: 0.9888, lr: 0.00000955
2025-12-16 10:55:30 train acc=0.97925, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09847216796875, 0.0, 0.6919501953125, 0.13426318359375, 4.754515625]
2025-12-16 10:55:30 Epoch: 40, loss: 0.9723, lr: 0.00000778
2025-12-16 10:56:59 train acc=0.97975, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.0990556640625, 0.0, 0.6928701171875, 0.1446103515625, 4.74325]
2025-12-16 10:56:59 Epoch: 41, loss: 0.9840, lr: 0.00000618
2025-12-16 10:58:28 train acc=0.98125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.09956494140625, 0.0, 0.6890205078125, 0.136118896484375, 4.7275625]
2025-12-16 10:58:28 Epoch: 42, loss: 0.9720, lr: 0.00000476
2025-12-16 10:59:56 train acc=0.98175, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.099759765625, 0.0, 0.685517578125, 0.13425244140625, 4.763703125]
2025-12-16 10:59:56 Epoch: 43, loss: 0.9671, lr: 0.00000351
2025-12-16 11:01:25 train acc=0.981, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10009521484375, 0.0, 0.6876396484375, 0.136289306640625, 4.75215625]
2025-12-16 11:01:25 Epoch: 44, loss: 0.9715, lr: 0.00000245
2025-12-16 11:02:52 train acc=0.982, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10015771484375, 0.0, 0.68818359375, 0.13503271484375, 4.736609375]
2025-12-16 11:02:52 Epoch: 45, loss: 0.9707, lr: 0.00000157
2025-12-16 11:04:20 train acc=0.98025, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1002412109375, 0.0, 0.683009765625, 0.138854248046875, 4.74296875]
2025-12-16 11:04:20 Epoch: 46, loss: 0.9696, lr: 0.00000089
2025-12-16 11:05:47 train acc=0.98025, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.1002978515625, 0.0, 0.685203125, 0.138995361328125, 4.7546875]
2025-12-16 11:05:47 Epoch: 47, loss: 0.9721, lr: 0.00000039
2025-12-16 11:07:15 train acc=0.98175, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10037841796875, 0.0, 0.67755078125, 0.133836669921875, 4.74790625]
2025-12-16 11:07:15 Epoch: 48, loss: 0.9593, lr: 0.00000010
2025-12-16 11:08:44 train acc=0.97775, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3, kd_loss] => [0.0, 0.10036279296875, 0.0, 0.674080078125, 0.137947509765625, 4.753625]
2025-12-16 11:08:44 Epoch: 49, loss: 0.9599, lr: 0.00000000
2025-12-16 11:40:15 {'name': 'imagenet', 'acc': [{'clip_logits': 68.77, 'cma_logits': 64.01599999999999, 'GLR_logits': 70.772, 'final_logits': 67.896, 'acc': 71.666}, {'clip_logits': 69.17999999999999, 'cma_logits': 63.92, 'GLR_logits': 71.21, 'final_logits': 67.57, 'acc': 71.58}, {'clip_logits': 48.383737153412326, 'cma_logits': 41.52763858594195, 'GLR_logits': 48.58220833578966, 'final_logits': 44.95470533907131, 'acc': 49.1481459647468}], 'detail': 'dataset_name=imagenet, shots=4, lr=0.001, seed=2024, train_epoch=50, batch_size=32, backbone=ViT-B/16, num_classes=1000, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-16 11:40:15 avg clip_logits acc=68.77
2025-12-16 11:40:15 avg cma_logits acc=64.01599999999999
2025-12-16 11:40:15 avg GLR_logits acc=70.772
2025-12-16 11:40:15 avg final_logits acc=67.896
2025-12-16 11:40:15 avg acc acc=71.666
