2025-12-16 23:13:00 Preparing ViT-B/16 model.
2025-12-16 23:13:02 Getting cached textual weights W ...
2025-12-16 23:13:02 Initializing CMA adapter learner...
2025-12-16 23:13:02 Preparing imagenet dataset.
2025-12-16 23:18:14 train acc=0.671625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.967119140625, 0.967119140625, 1.33012646484375, 1.33012646484375, 1.330125]
2025-12-16 23:18:14 Epoch: 0, loss: 5.9245, lr: 0.00009990
2025-12-16 23:23:12 train acc=0.68625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.8421552734375, 0.8421552734375, 1.23255810546875, 1.23255810546875, 1.232546875]
2025-12-16 23:23:12 Epoch: 1, loss: 5.3820, lr: 0.00009961
2025-12-16 23:28:09 train acc=0.697375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.8010458984375, 0.8010458984375, 1.17064794921875, 1.17064794921875, 1.17068701171875]
2025-12-16 23:28:09 Epoch: 2, loss: 5.1141, lr: 0.00009911
2025-12-16 23:33:03 train acc=0.7085625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7773857421875, 0.7773857421875, 1.11372265625, 1.11372265625, 1.1137392578125]
2025-12-16 23:33:03 Epoch: 3, loss: 4.8960, lr: 0.00009843
2025-12-16 23:37:56 train acc=0.712125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.763607421875, 0.763607421875, 1.06993603515625, 1.06993603515625, 1.0699609375]
2025-12-16 23:37:56 Epoch: 4, loss: 4.7370, lr: 0.00009755
2025-12-16 23:42:49 train acc=0.722625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7539267578125, 0.7539267578125, 1.033421875, 1.033421875, 1.033408203125]
2025-12-16 23:42:49 Epoch: 5, loss: 4.6082, lr: 0.00009649
2025-12-16 23:47:41 train acc=0.7310625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7486845703125, 0.7486845703125, 0.998302734375, 0.998302734375, 0.99822314453125]
2025-12-16 23:47:41 Epoch: 6, loss: 4.4923, lr: 0.00009524
2025-12-16 23:52:34 train acc=0.734125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.745228515625, 0.745228515625, 0.97021142578125, 0.97021142578125, 0.97029736328125]
2025-12-16 23:52:34 Epoch: 7, loss: 4.4012, lr: 0.00009382
2025-12-16 23:57:26 train acc=0.739375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.743423828125, 0.743423828125, 0.94443408203125, 0.94443408203125, 0.9444375]
2025-12-16 23:57:26 Epoch: 8, loss: 4.3202, lr: 0.00009222
2025-12-17 00:02:19 train acc=0.746875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7431962890625, 0.7431962890625, 0.91731298828125, 0.91731298828125, 0.91735546875]
2025-12-17 00:02:19 Epoch: 9, loss: 4.2383, lr: 0.00009045
2025-12-17 00:07:11 train acc=0.75275, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.741171875, 0.741171875, 0.898775390625, 0.898775390625, 0.8987802734375]
2025-12-17 00:07:11 Epoch: 10, loss: 4.1786, lr: 0.00008853
2025-12-17 00:12:04 train acc=0.754875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7404853515625, 0.7404853515625, 0.884994140625, 0.884994140625, 0.8850107421875]
2025-12-17 00:12:04 Epoch: 11, loss: 4.1360, lr: 0.00008645
2025-12-17 00:16:56 train acc=0.7586875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7419140625, 0.7419140625, 0.864439453125, 0.864439453125, 0.864455078125]
2025-12-17 00:16:56 Epoch: 12, loss: 4.0772, lr: 0.00008423
2025-12-17 00:21:49 train acc=0.7624375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74169921875, 0.74169921875, 0.850068359375, 0.850068359375, 0.85006103515625]
2025-12-17 00:21:49 Epoch: 13, loss: 4.0336, lr: 0.00008187
2025-12-17 00:26:41 train acc=0.766375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74220703125, 0.74220703125, 0.83612841796875, 0.83612841796875, 0.83619873046875]
2025-12-17 00:26:41 Epoch: 14, loss: 3.9928, lr: 0.00007939
2025-12-17 00:31:34 train acc=0.767375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7429677734375, 0.7429677734375, 0.82569775390625, 0.82569775390625, 0.82574658203125]
2025-12-17 00:31:34 Epoch: 15, loss: 3.9630, lr: 0.00007679
2025-12-17 00:36:27 train acc=0.7678125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7421845703125, 0.7421845703125, 0.82048193359375, 0.82048193359375, 0.82049462890625]
2025-12-17 00:36:27 Epoch: 16, loss: 3.9458, lr: 0.00007409
2025-12-17 00:41:19 train acc=0.77625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7432724609375, 0.7432724609375, 0.80546630859375, 0.80546630859375, 0.80542333984375]
2025-12-17 00:41:19 Epoch: 17, loss: 3.9029, lr: 0.00007129
2025-12-17 00:46:12 train acc=0.7751875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7432939453125, 0.7432939453125, 0.79982470703125, 0.79982470703125, 0.79986328125]
2025-12-17 00:46:12 Epoch: 18, loss: 3.8860, lr: 0.00006841
2025-12-17 00:51:04 train acc=0.778375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7445390625, 0.7445390625, 0.79272314453125, 0.79272314453125, 0.7927822265625]
2025-12-17 00:51:04 Epoch: 19, loss: 3.8674, lr: 0.00006545
2025-12-17 00:55:57 train acc=0.7795625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.743685546875, 0.743685546875, 0.7904150390625, 0.7904150390625, 0.79037841796875]
2025-12-17 00:55:57 Epoch: 20, loss: 3.8585, lr: 0.00006243
2025-12-17 01:00:49 train acc=0.7785, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7446318359375, 0.7446318359375, 0.786434814453125, 0.786434814453125, 0.7864384765625]
2025-12-17 01:00:49 Epoch: 21, loss: 3.8486, lr: 0.00005937
2025-12-17 01:05:42 train acc=0.784625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744912109375, 0.744912109375, 0.77773291015625, 0.77773291015625, 0.77770458984375]
2025-12-17 01:05:42 Epoch: 22, loss: 3.8230, lr: 0.00005627
2025-12-17 01:10:34 train acc=0.781625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74425390625, 0.74425390625, 0.7717890625, 0.7717890625, 0.77180908203125]
2025-12-17 01:10:34 Epoch: 23, loss: 3.8039, lr: 0.00005314
2025-12-17 01:15:27 train acc=0.7860625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74457421875, 0.74457421875, 0.76531201171875, 0.76531201171875, 0.7653525390625]
2025-12-17 01:15:27 Epoch: 24, loss: 3.7851, lr: 0.00005000
2025-12-17 01:20:19 train acc=0.7851875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744935546875, 0.744935546875, 0.7677509765625, 0.7677509765625, 0.76781494140625]
2025-12-17 01:20:19 Epoch: 25, loss: 3.7932, lr: 0.00004686
2025-12-17 01:25:12 train acc=0.7856875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7439892578125, 0.7439892578125, 0.76337841796875, 0.76337841796875, 0.76343798828125]
2025-12-17 01:25:12 Epoch: 26, loss: 3.7781, lr: 0.00004373
2025-12-17 01:30:04 train acc=0.787375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74408203125, 0.74408203125, 0.76019580078125, 0.76019580078125, 0.76021142578125]
2025-12-17 01:30:04 Epoch: 27, loss: 3.7688, lr: 0.00004063
2025-12-17 01:34:57 train acc=0.787875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744646484375, 0.744646484375, 0.75613232421875, 0.75613232421875, 0.75616455078125]
2025-12-17 01:34:57 Epoch: 28, loss: 3.7576, lr: 0.00003757
2025-12-17 01:39:50 train acc=0.7871875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.745021484375, 0.745021484375, 0.7555166015625, 0.7555166015625, 0.755532958984375]
2025-12-17 01:39:50 Epoch: 29, loss: 3.7566, lr: 0.00003455
2025-12-17 01:44:42 train acc=0.788875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.745779296875, 0.745779296875, 0.75505029296875, 0.75505029296875, 0.755046875]
2025-12-17 01:44:42 Epoch: 30, loss: 3.7567, lr: 0.00003159
2025-12-17 01:49:35 train acc=0.7895, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74486328125, 0.74486328125, 0.7510400390625, 0.7510400390625, 0.75108056640625]
2025-12-17 01:49:35 Epoch: 31, loss: 3.7428, lr: 0.00002871
2025-12-17 01:54:27 train acc=0.79025, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.745158203125, 0.745158203125, 0.7529169921875, 0.7529169921875, 0.75292626953125]
2025-12-17 01:54:27 Epoch: 32, loss: 3.7492, lr: 0.00002591
2025-12-17 01:59:20 train acc=0.788125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744986328125, 0.744986328125, 0.75132666015625, 0.75132666015625, 0.7513515625]
2025-12-17 01:59:20 Epoch: 33, loss: 3.7440, lr: 0.00002321
2025-12-17 02:04:12 train acc=0.7916875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7443896484375, 0.7443896484375, 0.74430029296875, 0.74430029296875, 0.74429150390625]
2025-12-17 02:04:12 Epoch: 34, loss: 3.7218, lr: 0.00002061
2025-12-17 02:09:05 train acc=0.7896875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7448984375, 0.7448984375, 0.75067919921875, 0.75067919921875, 0.7507041015625]
2025-12-17 02:09:05 Epoch: 35, loss: 3.7418, lr: 0.00001813
2025-12-17 02:13:57 train acc=0.788875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7450244140625, 0.7450244140625, 0.74601806640625, 0.74601806640625, 0.746052734375]
2025-12-17 02:13:57 Epoch: 36, loss: 3.7281, lr: 0.00001577
2025-12-17 02:18:49 train acc=0.791375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7440517578125, 0.7440517578125, 0.751544921875, 0.751544921875, 0.7515498046875]
2025-12-17 02:18:49 Epoch: 37, loss: 3.7428, lr: 0.00001355
2025-12-17 02:23:42 train acc=0.7898125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7451796875, 0.7451796875, 0.74740185546875, 0.74740185546875, 0.74744140625]
2025-12-17 02:23:42 Epoch: 38, loss: 3.7326, lr: 0.00001147
2025-12-17 02:28:34 train acc=0.7911875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7443427734375, 0.7443427734375, 0.7485439453125, 0.7485439453125, 0.74856494140625]
2025-12-17 02:28:34 Epoch: 39, loss: 3.7342, lr: 0.00000955
2025-12-17 02:33:27 train acc=0.7913125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7447333984375, 0.7447333984375, 0.7464716796875, 0.7464716796875, 0.74649609375]
2025-12-17 02:33:27 Epoch: 40, loss: 3.7289, lr: 0.00000778
2025-12-17 02:38:19 train acc=0.79325, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744486328125, 0.744486328125, 0.74695263671875, 0.74695263671875, 0.7469853515625]
2025-12-17 02:38:19 Epoch: 41, loss: 3.7299, lr: 0.00000618
2025-12-17 02:43:11 train acc=0.7910625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744390625, 0.744390625, 0.74972119140625, 0.74972119140625, 0.74967724609375]
2025-12-17 02:43:11 Epoch: 42, loss: 3.7379, lr: 0.00000476
2025-12-17 02:48:04 train acc=0.789125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744685546875, 0.744685546875, 0.746176513671875, 0.746176513671875, 0.74620556640625]
2025-12-17 02:48:04 Epoch: 43, loss: 3.7279, lr: 0.00000351
2025-12-17 02:52:56 train acc=0.7883125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7442626953125, 0.7442626953125, 0.74912158203125, 0.74912158203125, 0.74914697265625]
2025-12-17 02:52:56 Epoch: 44, loss: 3.7359, lr: 0.00000245
2025-12-17 02:57:48 train acc=0.7916875, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744830078125, 0.744830078125, 0.7456171875, 0.7456171875, 0.7456279296875]
2025-12-17 02:57:48 Epoch: 45, loss: 3.7264, lr: 0.00000157
2025-12-17 03:02:41 train acc=0.791625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.74476171875, 0.74476171875, 0.744615234375, 0.744615234375, 0.74455859375]
2025-12-17 03:02:41 Epoch: 46, loss: 3.7233, lr: 0.00000089
2025-12-17 03:07:33 train acc=0.792125, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744435546875, 0.744435546875, 0.746716796875, 0.746716796875, 0.7467392578125]
2025-12-17 03:07:33 Epoch: 47, loss: 3.7291, lr: 0.00000039
2025-12-17 03:12:25 train acc=0.7889375, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.7442216796875, 0.7442216796875, 0.74557421875, 0.74557421875, 0.7455380859375]
2025-12-17 03:12:25 Epoch: 48, loss: 3.7250, lr: 0.00000010
2025-12-17 03:17:18 train acc=0.7900625, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3] => [0.744310546875, 0.744310546875, 0.74401171875, 0.74401171875, 0.744052734375]
2025-12-17 03:17:18 Epoch: 49, loss: 3.7207, lr: 0.00000000
2025-12-17 03:30:48 {'name': 'imagenet', 'acc': [{'clip_logits': 68.77, 'cma_logits': 71.08, 'GLR_logits': 68.77, 'final_logits': 71.672, 'acc': 71.964}], 'detail': 'dataset_name=imagenet, shots=16, lr=0.001, seed=2024, train_epoch=50, batch_size=32, backbone=ViT-B/16, num_classes=1000, loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0], fuse_type=2'}
2025-12-17 03:30:48 avg clip_logits acc=68.77
2025-12-17 03:30:48 avg cma_logits acc=71.08
2025-12-17 03:30:48 avg GLR_logits acc=68.77
2025-12-17 03:30:48 avg final_logits acc=71.672
2025-12-17 03:30:48 avg acc acc=71.964
